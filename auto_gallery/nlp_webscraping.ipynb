{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Web Scraping\n\nSource: [Web Scraping With Python \u2013 Step-By-Step Guide](https://brightdata.com/blog/how-tos/web-scraping-with-python)\n\nPrerequisites\n\n**Requests** library allows you to perform HTTP requests in Python, Install:\n\n::\n\n    conda install requests\n\n**Beautiful Soup** library makes scraping information\nfrom web pages easier. In particular, Beautiful Soup works with any HTML or XML \nparser and provides everything you need to iterate, search, and modify the parse tree.\n\n::\n\n    conda install beautifulsoup4\n\nWe will scrape [quotes](https://quotes.toscrape.com) \nEach quote is a bloc of <div> </div>, that look like:\n\n::\n\n    <div class=\"quote\">\n        <span class=\"text\" itemprop=\"text\">\u201cThe world as ...\u201d</span>\n        <span>by <small class=\"author\" itemprop=\"author\">Albert Einstein</small>\n        </span>\n        <div class=\"tags\">\n            Tags:\n            <a class=\"tag\" href=\"/tag/change/page/1/\">change</a>  \n            <a class=\"tag\" href=\"/tag/deep-thoughts/page/1/\">deep-thoughts</a>\n        </div>\n    </div>\n    <div class=\"quote\">\n        <span class=\"text\" itemprop=\"text\">\u201cIt is our choices, ...\u201d</span>\n        <span>by <small class=\"author\" itemprop=\"author\">J.K. Rowling</small>\n        </span>\n        <div class=\"tags\">\n            Tags:\n            <a class=\"tag\" href=\"/tag/abilities/page/1/\">abilities</a>\n            <a class=\"tag\" href=\"/tag/choices/page/1/\">choices</a>\n        </div>\n    </div>\n    ...\n       \nAnd will return CSV file:\n\n::\n\n                   Text              Author                        Tags\n   0   \u201cThe world as...     Albert Einstein       change, deep-thoughts\n   1   \u201cIt is our ch...        J.K. Rowling       abilities, choices\n   2   \u201cThere are on...     Albert Einstein       inspirational, life\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import requests\nfrom bs4 import BeautifulSoup\nimport pandas as pd\n\ndef scrape_page(soup):\n\n    quotes = list()\n    \n    # retrieving all the quote <div> HTML element on the page\n    # Right / view page source to understand the structure of the HTML page\n    # The <div> tag defines a division or a section in an HTML document.\n    quote_elements = soup.find_all('div', class_='quote')\n\n    # iterating over the list of quote elements\n    # to extract the data of interest and store it\n    # in quotes\n    for quote_element in quote_elements:\n        # DEBUG: quote_element = quote_elements[0]\n        # extracting the text of the quote\n        # The quote text in a <span> HTML element: <span class=\"text\"> ...\n        # The author of the quote in a <small> HTML element\n        # A list of tags in a <div> element, each contained in <a> HTML element\n\n        text = quote_element.find('span', class_='text').text\n        # extracting the author of the quote\n        author = quote_element.find('small', class_='author').text\n\n        # extracting the tag <a> HTML elements related to the quote\n        tag_elements = \\\n            quote_element.find('div', class_='tags').find_all('a', class_='tag')\n\n        # storing the list of tag strings in a list\n        tags = [tag_element.text for tag_element in tag_elements]\n\n        # appending a dictionary containing the quote data\n        # in a new format in the quote list\n        quotes.append([text, author, ', '.join(tags)])\n\n    return quotes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Url of the home page of the target website\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_url = 'https://quotes.toscrape.com'\n\n# defining the User-Agent header to use in the GET request below\nheaders = {\n    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36'\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Retrieving the target web page.\n`page.text` will contain the HTML document returned by the server in string format\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "page = requests.get(base_url, headers=headers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Parsing the target web page with Beautiful Soup\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "soup = BeautifulSoup(page.text, 'html.parser')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "scraping the home page\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "quotes = scrape_page(soup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "getting the \"Next\" HTML element\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "next_li_element = soup.find('li', class_='next')\n\n# if there is a next page to scrape\nwhile next_li_element is not None:\n    next_page_relative_url = next_li_element.find('a', href=True)['href']\n\n    # getting the new page\n    page = requests.get(base_url + next_page_relative_url, headers=headers)\n\n    # parsing the new page\n    soup = BeautifulSoup(page.text, 'html.parser')\n\n    # scraping the new page and append to the quotes\n    quotes += scrape_page(soup)\n\n    # looking for the \"Next \u2192\" HTML element in the new page\n    next_li_element = soup.find('li', class_='next')\n\n\n# Write csv file\ndf = pd.DataFrame(quotes,\n                  columns=['Text', 'Author', 'Tags'])\n\ndf.to_csv('quotes.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}