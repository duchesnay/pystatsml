<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Manifold learning: non-linear dimension reduction &#8212; Statistics and Machine Learning in Python 0.8 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script src="../_static/documentation_options.js?v=a0e24af7"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.8 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Clustering" href="clustering.html" />
    <link rel="prev" title="Linear Dimensionality Reduction and Feature Extraction" href="linear_dimensionality_reduction.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="manifold-learning-non-linear-dimension-reduction">
<h1>Manifold learning: non-linear dimension reduction<a class="headerlink" href="#manifold-learning-non-linear-dimension-reduction" title="Link to this heading">¶</a></h1>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/modules/manifold.html">Scikit-learn
documentation</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Isomap">Wikipedia</a></p></li>
</ul>
<p>Nonlinear dimensionality reduction or <strong>manifold learning</strong> cover
unsupervised methods that attempt to identify low-dimensional manifolds
within the original <span class="math notranslate nohighlight">\(P\)</span>-dimensional space that represent high data
density. Then those methods provide a mapping from the high-dimensional
space to the low-dimensional embedding.</p>
<section id="multi-dimensional-scaling-mds">
<h2>Multi-dimensional Scaling (MDS)<a class="headerlink" href="#multi-dimensional-scaling-mds" title="Link to this heading">¶</a></h2>
<p>Resources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Multidimensional_scaling">wikipedia</a></p></li>
<li><p>Hastie, Tibshirani and Friedman (2009). <em>The Elements of Statistical
Learning: Data Mining, Inference, and Prediction.</em> New York: Springer,
Second Edition.</p></li>
</ul>
<p>The purpose of MDS is to find a low-dimensional projection of the data
in which the pairwise distances between data points is preserved, as
closely as possible (in a least-squares sense).</p>
<ul class="simple">
<li><p>Let <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> be the <span class="math notranslate nohighlight">\((N \times N)\)</span> pairwise distance
matrix where <span class="math notranslate nohighlight">\(d_{ij}\)</span> is <em>a distance</em> between points <span class="math notranslate nohighlight">\(i\)</span>
and <span class="math notranslate nohighlight">\(j\)</span>.</p></li>
<li><p>The MDS concept can be extended to a wide variety of data types
specified in terms of a similarity matrix.</p></li>
</ul>
<p>Given the dissimilarity (distance) matrix
<span class="math notranslate nohighlight">\(\mathbf{D}_{N \times N}=[d_{ij}]\)</span>, MDS attempts to find
<span class="math notranslate nohighlight">\(K\)</span>-dimensional projections of the <span class="math notranslate nohighlight">\(N\)</span> points
<span class="math notranslate nohighlight">\(\mathbf{x}_1, \ldots, \mathbf{x}_N \in \mathbb{R}^K\)</span>,
concatenated in an <span class="math notranslate nohighlight">\(\mathbf{X}_{N \times K}\)</span> matrix, so that
<span class="math notranslate nohighlight">\(d_{ij} \approx \|\mathbf{x}_i - \mathbf{x}_j\|\)</span> are as close as
possible. This can be obtained by the minimization of a loss function
called the <strong>stress function</strong></p>
<div class="math notranslate nohighlight">
\[\mathrm{stress}(\mathbf{X}) = \sum_{i \neq j}\left(d_{ij} -  \|\mathbf{x}_i - \mathbf{x}_j\|\right)^2.\]</div>
<p>This loss function is known as <em>least-squares</em> or <em>Kruskal-Shepard</em>
scaling.</p>
<p>A modification of <em>least-squares</em> scaling is the <em>Sammon mapping</em></p>
<div class="math notranslate nohighlight">
\[\mathrm{stress}_{\mathrm{Sammon}}(\mathbf{X}) = \sum_{i \neq j} \frac{(d_{ij} -  \|\mathbf{x}_i - \mathbf{x}_j\|)^2}{d_{ij}}.\]</div>
<p>The Sammon mapping performs better at preserving small distances
compared to the <em>least-squares</em> scaling.</p>
<section id="classical-multidimensional-scaling">
<h3>Classical multidimensional scaling<a class="headerlink" href="#classical-multidimensional-scaling" title="Link to this heading">¶</a></h3>
<p>Also known as <em>principal coordinates analysis</em>, PCoA.</p>
<ul class="simple">
<li><p>The distance matrix, <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>, is transformed to a
<em>similarity matrix</em>, <span class="math notranslate nohighlight">\(\mathbf{B}\)</span>, often using centered inner
products.</p></li>
<li><p>The loss function becomes</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\mathrm{stress}_{\mathrm{classical}}(\mathbf{X}) = \sum_{i \neq j} \big(b_{ij} -  \langle\mathbf{x}_i, \mathbf{x}_j\rangle\big)^2.\]</div>
<ul class="simple">
<li><p>The stress function in classical MDS is sometimes called <em>strain</em>.</p></li>
<li><p>The solution for the classical MDS problems can be found from the
eigenvectors of the similarity matrix.</p></li>
<li><p>If the distances in <span class="math notranslate nohighlight">\(\mathbf{D}\)</span> are Euclidean and double
centered inner products are used, the results are equivalent to PCA.</p></li>
</ul>
</section>
<section id="example">
<h3>Example<a class="headerlink" href="#example" title="Link to this heading">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">eurodist</span></code> datset provides the road distances (in kilometers)
between 21 cities in Europe. Given this matrix of pairwise
(non-Euclidean) distances <span class="math notranslate nohighlight">\(\mathbf{D}=[d_{ij}]\)</span>, MDS can be used
to recover the coordinates of the cities in <em>some</em> Euclidean referential
whose orientation is arbitrary.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="c1"># Plot</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pystatsml.plot_utils</span>

<span class="c1"># Plot parameters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-whitegrid&#39;</span><span class="p">)</span>
<span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">*</span> <span class="mf">.5</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Pairwise distance between European cities</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;../datasets/eurodist.csv&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/duchesnay/pystatsml/raw/master/datasets/eurodist.csv&#39;</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">city</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;city&quot;</span><span class="p">]</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:])</span>  <span class="c1"># Distance matrix</span>

<span class="c1"># Arbitrary choice of K=2 components</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.manifold</span><span class="w"> </span><span class="kn">import</span> <span class="n">MDS</span>
<span class="n">mds</span> <span class="o">=</span> <span class="n">MDS</span><span class="p">(</span><span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">mds</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">D</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>        <span class="n">city</span>  <span class="n">Athens</span>  <span class="n">Barcelona</span>  <span class="n">Brussels</span>  <span class="n">Calais</span>
<span class="mi">0</span>     <span class="n">Athens</span>       <span class="mi">0</span>       <span class="mi">3313</span>      <span class="mi">2963</span>    <span class="mi">3175</span>
<span class="mi">1</span>  <span class="n">Barcelona</span>    <span class="mi">3313</span>          <span class="mi">0</span>      <span class="mi">1318</span>    <span class="mi">1326</span>
<span class="mi">2</span>   <span class="n">Brussels</span>    <span class="mi">2963</span>       <span class="mi">1318</span>         <span class="mi">0</span>     <span class="mi">204</span>
<span class="mi">3</span>     <span class="n">Calais</span>    <span class="mi">3175</span>       <span class="mi">1326</span>       <span class="mi">204</span>       <span class="mi">0</span>
<span class="mi">4</span>  <span class="n">Cherbourg</span>    <span class="mi">3339</span>       <span class="mi">1294</span>       <span class="mi">583</span>     <span class="mi">460</span>
</pre></div>
</div>
<p>Recover coordinates of the cities in Euclidean referential whose
orientation is arbitrary:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">metrics</span>
<span class="n">Deuclidean</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">pairwise</span><span class="o">.</span><span class="n">pairwise_distances</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">Deuclidean</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span>   <span class="mf">0.</span> <span class="mf">3116.</span> <span class="mf">2994.</span> <span class="mf">3181.</span> <span class="mf">3428.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3116.</span>    <span class="mf">0.</span> <span class="mf">1317.</span> <span class="mf">1289.</span> <span class="mf">1128.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">2994.</span> <span class="mf">1317.</span>    <span class="mf">0.</span>  <span class="mf">198.</span>  <span class="mf">538.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3181.</span> <span class="mf">1289.</span>  <span class="mf">198.</span>    <span class="mf">0.</span>  <span class="mf">358.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">3428.</span> <span class="mf">1128.</span>  <span class="mf">538.</span>  <span class="mf">358.</span>    <span class="mf">0.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Plot the results:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot: apply some rotation and flip</span>
<span class="n">theta</span> <span class="o">=</span> <span class="mi">80</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">/</span> <span class="mf">180.</span>
<span class="n">rot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">)],</span>
                <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span>  <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta</span><span class="p">)]])</span>
<span class="n">Xr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">rot</span><span class="p">)</span>
<span class="c1"># flip x</span>
<span class="n">Xr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">*=</span> <span class="o">-</span><span class="mi">1</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">Xr</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xr</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">city</span><span class="p">)):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">Xr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xr</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">city</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;equal&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="o">-</span><span class="mf">1894.091917806915</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2914.3554370871243</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="o">-</span><span class="mf">1712.973369719749</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2145.4370687880146</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/manifold_learning_5_1.png" src="../_images/manifold_learning_5_1.png" />
</section>
<section id="determining-the-number-of-components">
<h3>Determining the number of components<a class="headerlink" href="#determining-the-number-of-components" title="Link to this heading">¶</a></h3>
<p>We must choose <span class="math notranslate nohighlight">\(K^* \in \{1, \ldots,  K\}\)</span> the number of required
components. Plotting the values of the stress function, obtained using
<span class="math notranslate nohighlight">\(k \leq N-1\)</span> components. In general, start with
<span class="math notranslate nohighlight">\(1, \ldots K \leq 4\)</span>. Choose <span class="math notranslate nohighlight">\(K^*\)</span> where you can clearly
distinguish an <em>elbow</em> in the stress curve.</p>
<p>Thus, in the plot below, we choose to retain information accounted for
by the first <em>two</em> components, since this is where the <em>elbow</em> is in the
stress curve.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">D</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
<span class="n">stress</span> <span class="o">=</span> <span class="p">[</span><span class="n">MDS</span><span class="p">(</span><span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="n">k</span><span class="p">,</span>
           <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">D</span><span class="p">)</span><span class="o">.</span><span class="n">stress_</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">stress</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span> <span class="n">stress</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;stress&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">48644495.28571428</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">3356497.365752386</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2858455.495887962</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2756310.6376280114</span><span class="p">)]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;stress&#39;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/manifold_learning_7_2.png" src="../_images/manifold_learning_7_2.png" />
</section>
<section id="exercises">
<h3>Exercises<a class="headerlink" href="#exercises" title="Link to this heading">¶</a></h3>
<p>Apply MDS from <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> on the <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset available at:</p>
<p><a class="reference external" href="https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv">https://github.com/duchesnay/pystatsml/raw/master/datasets/iris.csv</a></p>
<ul class="simple">
<li><p>Center and scale the dataset.</p></li>
<li><p>Compute Euclidean pairwise distances matrix.</p></li>
<li><p>Select the number of components.</p></li>
<li><p>Show that classical MDS on Euclidean pairwise distances matrix is
equivalent to PCA.</p></li>
</ul>
<p>Manifold learning</p>
<p>Dataset S curve:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">mpl_toolkits.mplot3d</span><span class="w"> </span><span class="kn">import</span> <span class="n">Axes3D</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn</span><span class="w"> </span><span class="kn">import</span> <span class="n">manifold</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_s_curve</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="isomap">
<h2>Isomap<a class="headerlink" href="#isomap" title="Link to this heading">¶</a></h2>
<p>Isomap is a nonlinear dimensionality reduction method that combines a
procedure to compute the distance matrix with MDS. The distances
calculation is based on geodesic distances evaluated on neighborhood
graph:</p>
<ol class="arabic simple">
<li><p>Determine the neighbors of each point. All points in some fixed
radius or K nearest neighbors.</p></li>
<li><p>Construct a neighborhood graph. Each point is connected to other if
it is a K nearest neighbor. Edge length equal to Euclidean distance.</p></li>
<li><p>Compute shortest path between pairwise of points <span class="math notranslate nohighlight">\(d_{ij}\)</span> to
build the distance matrix <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>.</p></li>
<li><p>Apply MDS on <span class="math notranslate nohighlight">\(\mathbf{D}\)</span>.</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">isomap</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">Isomap</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">X_isomap</span> <span class="o">=</span> <span class="n">isomap</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="t-sne">
<h2>t-SNE<a class="headerlink" href="#t-sne" title="Link to this heading">¶</a></h2>
<p>Sources:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding">Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne">scikit-learn</a></p></li>
</ul>
<p>Principles</p>
<ol class="arabic simple">
<li><p>Construct a (Gaussian) probability distribution between pairs of
object in input (high-dimensional) space.</p></li>
<li><p>Construct a (student) probability distribution between pairs of
object in embedded (low-dimensional) space.</p></li>
<li><p>Minimize the Kullback–Leibler divergence (KL divergence) between the
two distributions.</p></li>
</ol>
<p>Features</p>
<ul class="simple">
<li><p>Isomap, LLE and variants are best suited to unfold a single continuous
low dimensional manifold</p></li>
<li><p>t-SNE will focus on the <strong>local structure</strong> of the data and will tend
to extract clustered <strong>local groups</strong> of samples</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tsne</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">&#39;pca&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_tsne</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Manifold Learning&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">131</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">&#39;3d&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mi">72</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;2D &quot;S shape&quot; manifold in 3D&#39;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">132</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_isomap</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_isomap</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Isomap&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;First component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Second component&quot;</span><span class="p">)</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">133</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_tsne</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;t-SNE&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;First component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Second component&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;tight&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="o">-</span><span class="mf">68.37603721618652</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">64.30499229431152</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="o">-</span><span class="mf">14.287820672988891</span><span class="p">),</span>
 <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">17.26294598579407</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/manifold_learning_15_1.png" src="../_images/manifold_learning_15_1.png" />
</section>
<section id="id1">
<h2>Exercises<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h2>
<p>Run <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html">Manifold learning on handwritten digits: Locally Linear Embedding,
Isomap with
scikit-learn</a></p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Manifold learning: non-linear dimension reduction</a><ul>
<li><a class="reference internal" href="#multi-dimensional-scaling-mds">Multi-dimensional Scaling (MDS)</a><ul>
<li><a class="reference internal" href="#classical-multidimensional-scaling">Classical multidimensional scaling</a></li>
<li><a class="reference internal" href="#example">Example</a></li>
<li><a class="reference internal" href="#determining-the-number-of-components">Determining the number of components</a></li>
<li><a class="reference internal" href="#exercises">Exercises</a></li>
</ul>
</li>
<li><a class="reference internal" href="#isomap">Isomap</a></li>
<li><a class="reference internal" href="#t-sne">t-SNE</a></li>
<li><a class="reference internal" href="#id1">Exercises</a></li>
</ul>
</li>
</ul>

  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/ml_unsupervised/manifold_learning.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/ml_unsupervised/manifold_learning.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>