{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/timeseries.html)\n",
    "- [Pandas user guide](https://pandas.pydata.org/pandas-docs/stable/timeseries.html)\n",
    "- [Time Series analysis (TSA) from statsmodels](http://www.statsmodels.org/devel/tsa.html)\n",
    "\n",
    "References:\n",
    "\n",
    "- [Basic](https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/)\n",
    "- [Detailed](https://otexts.com/fpp2/classical-decomposition.html)\n",
    "- [PennState Time Series course](https://online.stat.psu.edu/stat510/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Adjust default figure size\n",
    "fig_w, fig_h = plt.rcParams.get('figure.figsize')\n",
    "plt.rcParams['figure.figsize'] = (fig_w, fig_h * .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(\"2018-01-01\", periods=5, freq=\"YS\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition Methods: Periodic Patterns (Trend/Seasonal) and Autocorrelation\n",
    "\n",
    "Stationarity\n",
    "\n",
    "A TS is said to be stationary if its statistical properties such as mean, variance remain constant over time.\n",
    "\n",
    "- constant mean\n",
    "- constant variance\n",
    "- an autocovariance that does not depend on time.\n",
    "\n",
    "what is making a TS non-stationary. There are 2 major reasons behind non-stationary of a TS:\n",
    "\n",
    "1. Trend - varying mean over time. For eg, in this case we saw that on average, the number of passengers was growing over time.\n",
    "\n",
    "2. Seasonality - variations at specific time-frames. eg people might have a tendency to buy cars in a particular month because of pay increment or festivals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Time series analysis of Google trends](https://www.datacamp.com/community/tutorials/time-series-analysis-tutorial)\n",
    "\n",
    "Get Google Trends data of keywords such as 'diet' and 'gym' and see how they vary over time while learning about trends and seasonality in time series data.\n",
    "\n",
    "In the Facebook Live code along session on the 4th of January, we checked out Google trends data of keywords 'diet', 'gym' and 'finance' to see how they vary over time. We asked ourselves if there could be more searches for these terms in January when we're all trying to turn over a new leaf?\n",
    "\n",
    "In this tutorial, you'll go through the code that we put together during the session step by step. You're not going to do much mathematics but you are going to do the following:\n",
    "\n",
    "- Read data\n",
    "- Recode data\n",
    "- Exploratory Data Analysis\n",
    "\n",
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    url = \"https://github.com/datacamp/datacamp_facebook_live_ny_resolution/raw/master/data/multiTimeline.csv\"\n",
    "    df = pd.read_csv(url, skiprows=2)\n",
    "except:\n",
    "    df = pd.read_csv(\"../datasets/multiTimeline.csv\", skiprows=2)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['month', 'diet', 'gym', 'finance']\n",
    "\n",
    "# Describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode data\n",
    "\n",
    "Next, you'll turn the 'month' column into a DateTime data type and make it the index of the DataFrame.\n",
    "\n",
    "Note that you do this because you saw in the result of the .info() method that the 'Month' column was actually an of data type object. Now, that generic data type encapsulates everything from strings to integers, etc. That's not exactly what you want when you want to be looking at time series data. That's why you'll use .to_datetime() to convert the 'month' column in your DataFrame to a DateTime.\n",
    "\n",
    "Be careful! Make sure to include the in place argument when you're setting the index of the DataFrame df so that you actually alter the original index and set it to the 'month' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.month = pd.to_datetime(df.month)\n",
    "df.set_index('month', inplace=True)\n",
    "\n",
    "df = df[[\"diet\", \"gym\"]]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis\n",
    "\n",
    "You can use a built-in pandas visualization method .plot() to plot your\n",
    "data as 3 line plots on a single figure (one for each column, namely, 'diet', 'gym', and 'finance')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.xlabel('Year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this data is relative. As you can read on Google trends:\n",
    "\n",
    "Numbers represent search interest relative to the highest point on the chart\n",
    "for the given region and time.\n",
    "A value of 100 is the peak popularity for the term.\n",
    "A value of 50 means that the term is half as popular.\n",
    "Likewise a score of 0 means the term was less than 1% as popular as the peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Trends : Resampling, Rolling average, (Smoothing, Windowing) \n",
    "\n",
    "Identify trends or remove seasonality\n",
    "\n",
    "1. Subsampling at year frequency\n",
    "\n",
    "2. Rolling average (Smoothing, Windowing), for each time point, take the average of the points on either side of it. Note that the number of points is specified by a window size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet = df['diet']\n",
    "\n",
    "diet_resamp_yr = diet.resample('YE').mean()\n",
    "diet_roll_yr = diet.rolling(12).mean()\n",
    "\n",
    "ax = diet.plot(alpha=0.5, style='-') # store axis (ax) for latter plots\n",
    "diet_resamp_yr.plot(style=':', label='Resample at year frequency', ax=ax)\n",
    "diet_roll_yr.plot(style='--', label='Rolling average (smooth), window size=12',\n",
    "                  ax=ax)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling average (smoothing) with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(df[['diet']])\n",
    "win = 12\n",
    "win_half = int(win / 2)\n",
    "\n",
    "diet_smooth = np.array([x[(idx-win_half):(idx+win_half)].mean()\n",
    "                        for idx in np.arange(win_half, len(x))])\n",
    "_ = plt.plot(diet_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trends: Plot Diet and Gym using rolling average\n",
    "\n",
    "Build a new DataFrame which is the concatenation diet and gym smoothed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend = pd.concat([df['diet'].rolling(12).mean(), df['gym'].rolling(12).mean()], axis=1)\n",
    "df_trend.plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality by detrending (remove average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtrend = df[[\"diet\", \"gym\"]] - df_trend\n",
    "df_dtrend.plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality by First-order Differencing\n",
    "\n",
    "First-order approximation using `diff` method which compute original - shifted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude first term for some implementation details\n",
    "assert np.all((diet.diff() == diet - diet.shift())[1:])\n",
    "\n",
    "df.diff().plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodicity and Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'diet' and 'gym' are negatively correlated! Remember that you have a seasonal and a trend component. The correlation is actually capturing both of those. Decomposing into separate components provides a better insight of the data:\n",
    "\n",
    "Trends components that are negatively correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Seasonal components (Detrended or First-order Differencing) are positively correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dtrend.corr())\n",
    "print(df.diff().corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Seasonal_decompose` function of [statsmodels](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html). \"The results are obtained by first estimating the trend by applying a using moving averages or a convolution filter to the data. The trend is then removed from the series and the average of this de-trended series for each period is the returned seasonal component.\"\n",
    "\n",
    "We use additive (linear) model, i.e., TS = Level + Trend + Seasonality + Noise\n",
    "\n",
    "- Level: The average value in the series.\n",
    "- Trend: The increasing or decreasing value in the series.\n",
    "- Seasonality: The repeating short-term cycle in the series.\n",
    "- Noise: The random variation in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "x = df.gym.astype(float) # force float\n",
    "decomposition = seasonal_decompose(x)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(4, 1, figsize=(fig_w, fig_h))\n",
    "\n",
    "axis[0].plot(x, label='Original')\n",
    "axis[0].legend(loc='best')\n",
    "\n",
    "axis[1].plot(trend, label='Trend')\n",
    "axis[1].legend(loc='best')\n",
    "\n",
    "axis[2].plot(seasonal,label='Seasonality')\n",
    "axis[2].legend(loc='best')\n",
    "\n",
    "axis[3].plot(residual, label='Residuals')\n",
    "axis[3].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation function (ACF)\n",
    "\n",
    "A time series is periodic if it repeats itself at equally spaced intervals, say, every 12 months.\n",
    "Autocorrelation Function (ACF): It is a measure of the correlation between the TS with a\n",
    "lagged version of itself. For instance at lag 5, ACF would compare series at time instant $t$ with series at instant $t-h$.\n",
    "\n",
    "- The autocorrelation measures the linear relationship between an observation and its previous observations at different lags ($h$).\n",
    "- Represents the overall correlation structure of the time series.\n",
    "- Used to identify the order of a moving average (MA) process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# We could have considered the first order differences to capture the seasonality\n",
    "# x = df[\"gym\"].astype(float).diff().dropna()\n",
    "\n",
    "# Bu we use the detrended signal\n",
    "x = df_dtrend.gym.dropna()\n",
    "\n",
    "plt.plot(x)\n",
    "plt.show()\n",
    "\n",
    "plot_acf(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial autocorrelation function (PACF)\n",
    "\n",
    "- Partial autocorrelation measures the direct linear relationship between an observation and its previous observations at a specific offset, excluding contributions from intermediate offsets.\n",
    "- Highlights direct relationships between observations at specific lags.\n",
    "- Used to identify the order of an autoregressive (AR) process. The partial autocorrelation of an AR(p) process equals zero at lags larger than p, so the appropriate maximum lag p is the one after which the partial autocorrelations are all zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACF peaks every 12 months, i.e., the signal is correlated with itself shifted by 12 months. Its, then slowly decrease is due to the trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series forecasting using Autoregressive AR(p) models\n",
    "\n",
    "Sources:\n",
    "\n",
    "- [Simple modeling with AutoReg](https://www.kaggle.com/code/eugeniyosetrov/simple-modeling-with-autoreg)\n",
    "\n",
    "The autoregressive orders. In general, we can define an AR(p) model with $p$ autoregressive terms as follows:\n",
    "\n",
    "$$\n",
    "x_t = \\sum_i^p a_i x_{t-i} + \\varepsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from statsmodels.tsa.api import AutoReg\n",
    "\n",
    "# We set the frequency for the time series to “MS” (month-start) to avoid warnings when using AutoReg.\n",
    "x = df_dtrend.gym.dropna().asfreq(\"MS\")\n",
    "ar1 = AutoReg(x, lags=1).fit()\n",
    "print(ar1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial autocorrelation function (PACF) peaks at $p=12$, try AR(12):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar12 = AutoReg(x, lags=12).fit()\n",
    "\n",
    "fig, axis = plt.subplots(2, 1, figsize=(fig_w, fig_h))\n",
    "\n",
    "axis[0].plot(x, label='Original')\n",
    "axis[0].plot(ar1.predict(), label='AR(1)')\n",
    "axis[0].legend(loc='best')\n",
    "\n",
    "axis[1].plot(x, label='Original')\n",
    "axis[1].plot(ar12.predict(), label='AR(12)')\n",
    "_ = axis[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = lambda y_true, y_pred : (y_true - y_pred).dropna().abs().mean()\n",
    "print(\"MAE: AR(1) %.3f\" % mae(x, ar1.predict()),\n",
    "      \"AR(12) %.3f\" % mae(x, ar12.predict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic model selection using Akaike information criterion ([AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion)). AIC drops at $p=12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aics = [AutoReg(x, lags=p).fit().aic for p in range(1, 50)]\n",
    "_ = plt.plot(range(1, len(aics)+1), aics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
