{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools:\n",
    "\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/timeseries.html)\n",
    "- [Pandas user guide](https://pandas.pydata.org/pandas-docs/stable/timeseries.html)\n",
    "- [Time Series analysis (TSA) from statsmodels](http://www.statsmodels.org/devel/tsa.html)\n",
    "\n",
    "References:\n",
    "\n",
    "- [Basic](https://machinelearningmastery.com/decompose-time-series-data-trend-seasonality/)\n",
    "- [Detailed](https://otexts.com/fpp2/classical-decomposition.html)\n",
    "- [PennState Time Series course](https://online.stat.psu.edu/stat510/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plot parameters\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig_w, fig_h = plt.rcParams.get('figure.figsize')\n",
    "plt.rcParams['figure.figsize'] = (fig_w, fig_h * .5)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time series with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.date_range(\"2018-01-01\", periods=5, freq=\"YS\")\n",
    "ts = pd.Series(range(len(idx)), index=idx)\n",
    "print(ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposition Methods: Periodic Patterns (Trend/Seasonal) and Autocorrelation\n",
    "\n",
    "Stationarity\n",
    "\n",
    "A TS is said to be stationary if its statistical properties such as mean, variance remain constant over time.\n",
    "\n",
    "- constant mean\n",
    "- constant variance\n",
    "- an autocovariance that does not depend on time.\n",
    "\n",
    "what is making a TS non-stationary. There are 2 major reasons behind non-stationary of a TS:\n",
    "\n",
    "1. Trend - varying mean over time. For eg, in this case we saw that on average, the number of passengers was growing over time.\n",
    "\n",
    "2. Seasonality - variations at specific time-frames. eg people might have a tendency to buy cars in a particular month because of pay increment or festivals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Time series analysis of Google trends](https://www.datacamp.com/community/tutorials/time-series-analysis-tutorial)\n",
    "\n",
    "Get Google Trends data of keywords such as 'diet' and 'gym' and see how they vary over time while learning about trends and seasonality in time series data.\n",
    "\n",
    "In the Facebook Live code along session on the 4th of January, we checked out Google trends data of keywords 'diet', 'gym' and 'finance' to see how they vary over time. We asked ourselves if there could be more searches for these terms in January when we're all trying to turn over a new leaf?\n",
    "\n",
    "In this tutorial, you'll go through the code that we put together during the session step by step. You're not going to do much mathematics but you are going to do the following:\n",
    "\n",
    "- Read data\n",
    "- Recode data\n",
    "- Exploratory Data Analysis\n",
    "\n",
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    url = \"https://github.com/datacamp/datacamp_facebook_live_ny_resolution/raw/master/data/multiTimeline.csv\"\n",
    "    df = pd.read_csv(url, skiprows=2)\n",
    "except:\n",
    "    df = pd.read_csv(\"../datasets/multiTimeline.csv\", skiprows=2)\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Rename columns\n",
    "df.columns = ['month', 'diet', 'gym', 'finance']\n",
    "\n",
    "# Describe\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode data\n",
    "\n",
    "Next, you'll turn the 'month' column into a DateTime data type and make it the index of the DataFrame.\n",
    "\n",
    "Note that you do this because you saw in the result of the .info() method that the 'Month' column was actually an of data type object. Now, that generic data type encapsulates everything from strings to integers, etc. That's not exactly what you want when you want to be looking at time series data. That's why you'll use .to_datetime() to convert the 'month' column in your DataFrame to a DateTime.\n",
    "\n",
    "Be careful! Make sure to include the in place argument when you're setting the index of the DataFrame df so that you actually alter the original index and set it to the 'month' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.month = pd.to_datetime(df.month)\n",
    "df.set_index('month', inplace=True)\n",
    "\n",
    "df = df[[\"diet\", \"gym\"]]\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory data analysis\n",
    "\n",
    "You can use a built-in pandas visualization method .plot() to plot your\n",
    "data as 3 line plots on a single figure (one for each column, namely, 'diet', 'gym', and 'finance')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot()\n",
    "plt.xlabel('Year');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this data is relative. As you can read on Google trends:\n",
    "\n",
    "Numbers represent search interest relative to the highest point on the chart\n",
    "for the given region and time.\n",
    "A value of 100 is the peak popularity for the term.\n",
    "A value of 50 means that the term is half as popular.\n",
    "Likewise a score of 0 means the term was less than 1% as popular as the peak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Trends : Resampling, Rolling average, (Smoothing, Windowing) \n",
    "\n",
    "Identify trends or remove seasonality\n",
    "\n",
    "1. Subsampling at year frequency\n",
    "\n",
    "2. Rolling average (Smoothing, Windowing), for each time point, take the average of the points on either side of it. Note that the number of points is specified by a window size.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diet = df['diet']\n",
    "\n",
    "diet_resamp_yr = diet.resample('YE').mean()\n",
    "diet_roll_yr = diet.rolling(12).mean()\n",
    "\n",
    "ax = diet.plot(alpha=0.5, style='-') # store axis (ax) for latter plots\n",
    "diet_resamp_yr.plot(style=':', label='Resample at year frequency', ax=ax)\n",
    "diet_roll_yr.plot(style='--', label='Rolling average (smooth), window size=12',\n",
    "                  ax=ax)\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling average (smoothing) with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(df[['diet']])\n",
    "win = 12\n",
    "win_half = int(win / 2)\n",
    "\n",
    "diet_smooth = np.array([x[(idx-win_half):(idx+win_half)].mean()\n",
    "                        for idx in np.arange(win_half, len(x))])\n",
    "_ = plt.plot(diet_smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trends: Plot Diet and Gym using rolling average\n",
    "\n",
    "Build a new DataFrame which is the concatenation diet and gym smoothed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend = pd.concat([df['diet'].rolling(12).mean(), df['gym'].rolling(12).mean()], axis=1)\n",
    "df_trend.plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality by detrending (remove average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dtrend = df[[\"diet\", \"gym\"]] - df_trend\n",
    "df_dtrend.plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonality by First-order Differencing\n",
    "\n",
    "First-order approximation using `diff` method which compute original - shifted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude first term for some implementation details\n",
    "assert np.all((diet.diff() == diet - diet.shift())[1:])\n",
    "\n",
    "df.diff().plot()\n",
    "plt.xlabel('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Periodicity and Autocorrelation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'diet' and 'gym' are negatively correlated! Remember that you have a seasonal and a trend component. The correlation is actually capturing both of those. Decomposing into separate components provides a better insight of the data:\n",
    "\n",
    "Trends components that are negatively correlated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Seasonal components (Detrended or First-order Differencing) are positively correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dtrend.corr())\n",
    "print(df.diff().corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Seasonal_decompose` function of [statsmodels](https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html). \"The results are obtained by first estimating the trend by applying a using moving averages or a convolution filter to the data. The trend is then removed from the series and the average of this de-trended series for each period is the returned seasonal component.\"\n",
    "\n",
    "We use additive (linear) model, i.e., TS = Level + Trend + Seasonality + Noise\n",
    "\n",
    "- Level: The average value in the series.\n",
    "- Trend: The increasing or decreasing value in the series.\n",
    "- Seasonality: The repeating short-term cycle in the series.\n",
    "- Noise: The random variation in the series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "x = df.gym.astype(float) # force float\n",
    "decomposition = seasonal_decompose(x)\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "residual = decomposition.resid\n",
    "\n",
    "\n",
    "fig, axis = plt.subplots(4, 1, figsize=(fig_w, fig_h))\n",
    "\n",
    "axis[0].plot(x, label='Original')\n",
    "axis[0].legend(loc='best')\n",
    "\n",
    "axis[1].plot(trend, label='Trend')\n",
    "axis[1].legend(loc='best')\n",
    "\n",
    "axis[2].plot(seasonal,label='Seasonality')\n",
    "axis[2].legend(loc='best')\n",
    "\n",
    "axis[3].plot(residual, label='Residuals')\n",
    "axis[3].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocorrelation function (ACF)\n",
    "\n",
    "A time series is periodic if it repeats itself at equally spaced intervals, say, every 12 months.\n",
    "Autocorrelation Function (ACF): It is a measure of the correlation between the TS with a\n",
    "lagged version of itself. For instance at lag 5, ACF would compare series at time instant $t$ with series at instant $t-h$.\n",
    "\n",
    "- The autocorrelation measures the linear relationship between an observation and its previous observations at different lags ($h$).\n",
    "- Represents the overall correlation structure of the time series.\n",
    "- Used to identify the order of a moving average (MA) process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "# from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# We could have considered the first order differences to capture the seasonality\n",
    "# x = df[\"gym\"].astype(float).diff().dropna()\n",
    "\n",
    "# Bu we use the detrended signal\n",
    "x = df_dtrend.gym.dropna()\n",
    "\n",
    "plt.plot(x)\n",
    "plt.show()\n",
    "\n",
    "plot_acf(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial autocorrelation function (PACF)\n",
    "\n",
    "- Partial autocorrelation measures the direct linear relationship between an observation and its previous observations at a specific offset, excluding contributions from intermediate offsets.\n",
    "- Highlights direct relationships between observations at specific lags.\n",
    "- Used to identify the order of an autoregressive (AR) process. The partial autocorrelation of an AR(p) process equals zero at lags larger than p, so the appropriate maximum lag p is the one after which the partial autocorrelations are all zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pacf(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PACF peaks every 12 months, i.e., the signal is correlated with itself shifted by 12 months. Its, then slowly decrease is due to the trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series forecasting using Autoregressive AR(p) models\n",
    "\n",
    "Sources:\n",
    "\n",
    "- [Simple modeling with AutoReg](https://www.kaggle.com/code/eugeniyosetrov/simple-modeling-with-autoreg)\n",
    "\n",
    "The autoregressive orders. In general, we can define an AR(p) model with $p$ autoregressive terms as follows:\n",
    "\n",
    "$$\n",
    "x_t = \\sum_i^p a_i x_{t-i} + \\varepsilon_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from statsmodels.tsa.api import AutoReg\n",
    "\n",
    "# We set the frequency for the time series to “MS” (month-start) to avoid warnings when using AutoReg.\n",
    "x = df_dtrend.gym.dropna().asfreq(\"MS\")\n",
    "ar1 = AutoReg(x, lags=1).fit()\n",
    "print(ar1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partial autocorrelation function (PACF) peaks at $p=12$, try AR(12):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar12 = AutoReg(x, lags=12).fit()\n",
    "\n",
    "fig, axis = plt.subplots(2, 1, figsize=(fig_w, fig_h))\n",
    "\n",
    "axis[0].plot(x, label='Original')\n",
    "axis[0].plot(ar1.predict(), label='AR(1)')\n",
    "axis[0].legend(loc='best')\n",
    "\n",
    "axis[1].plot(x, label='Original')\n",
    "axis[1].plot(ar12.predict(), label='AR(12)')\n",
    "_ = axis[1].legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = lambda y_true, y_pred : (y_true - y_pred).dropna().abs().mean()\n",
    "print(\"MAE: AR(1) %.3f\" % mae(x, ar1.predict()),\n",
    "      \"AR(12) %.3f\" % mae(x, ar12.predict()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automatic model selection using Akaike information criterion ([AIC](https://en.wikipedia.org/wiki/Akaike_information_criterion)). AIC drops at $p=12$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aics = [AutoReg(x, lags=p).fit().aic for p in range(1, 50)]\n",
    "_ = plt.plot(range(1, len(aics)+1), aics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Fourier Transform (DFT)\n",
    "\n",
    "![Discrete Fourier Transform](./images/time_series_fft.png)\n",
    "\n",
    "[Fourier Analysis](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.00-Fourier-Transforms.html)\n",
    "\n",
    "- Fourier analysis is a mathematical method used to decompose functions or signals into their constituent frequencies, known as sine and cosine components, that form a orthogonal basis. \n",
    "- It transforms a time-domain signal into a frequency-domain representation, making it useful for analyzing periodic or non-periodic signals.\n",
    "- This technique is widely applied in fields like signal processing, image analysis, and solving differential equations.\n",
    "\n",
    "[Discrete Fourier Transform (DFT)](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.02-Discrete-Fourier-Transform.html)\n",
    "\n",
    "- The Discrete Fourier Transform (DFT) is a specific form of Fourier analysis applied to discrete signals, transforming a finite sequence of equally spaced samples into a frequency-domain representation.\n",
    "- It breaks down a discrete signal into a sum of sine and cosine waves, each with specific amplitudes and frequencies.\n",
    "- The DFT is widely used in digital signal processing for tasks like filtering and spectral analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The Basics of Waves](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.01-The-Basics-of-waves.html)\n",
    "\n",
    "A cosine wave can be represented by the following equation:\n",
    "\n",
    "$$\n",
    "y(t) = A \\cos(2\\pi f t + \\phi)\n",
    "$$\n",
    "\n",
    "- $\\phi$ is the phase of the signal.\n",
    "- $T = 1/f$ is the period of the wave, \n",
    "- $f$ is the frequency of the wave\n",
    "- $A$ is the amplitude of the signal\n",
    "\n",
    "To generate sample we need to define the sampling rate which is the number of sample per second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine(A=1, f=10, phase=0, duration=1.0, sr=100.0):\n",
    "    # sampling interval\n",
    "    ts = 1.0 / sr\n",
    "    t = np.arange(0, duration, ts)\n",
    "    return t, A * np.sin(2 * np.pi * f * t + phase)\n",
    "\n",
    "def cosine(A=1, f=10, phase=0, duration=1.0, sr=100.0):\n",
    "    # sampling interval\n",
    "    ts = 1.0 / sr\n",
    "    t = np.arange(0, duration, ts)\n",
    "    return t, A * np.cos(2 * np.pi * f * t + phase)\n",
    "\n",
    "sr = 200\n",
    "\n",
    "t, sine_1hz = cosine(A=3, f=1, sr=sr, duration=2)\n",
    "#t, sine_1hz = sine(A=2, f=10, sr=sr, duration=2)\n",
    "t, sine_10hz = cosine(A=1, f=10, sr=sr, duration=2)\n",
    "t, sine_50hz = cosine(A=.5, f=50, sr=sr, duration=2)\n",
    "#t, sine_20hz = sine(A=.5, f=10, sr=sr, duration=2)\n",
    "\n",
    "y = sine_1hz + sine_10hz + sine_50hz\n",
    "\n",
    "# Plot the signal\n",
    "plt.plot(t, y, c=colors[0])\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Sum of three signals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Discrete Cosine Transform DCT](https://en.wikipedia.org/wiki/Discrete_cosine_transform)\n",
    "\n",
    "- A discrete cosine transform (DCT) expresses a finite sequence of data points in terms of a sum of cosine functions oscillating at different frequencies.\n",
    "- A DCT is a Fourier-related transform similar to the discrete Fourier transform (DFT), but using only real numbers.\n",
    "- See also [Discrete Sine Transform DST](https://en.wikipedia.org/wiki/Discrete_sine_transform)\n",
    "\n",
    "There are several definitions of the DCT, see [DCT with Scipy](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.dct.html) for details. For educational purpose, we use a simplified modified version:\n",
    "$$\n",
    "X_k = \\sum_{n=0}^{N-1} x_n \\cos(\\frac{2\\pi k n}{N}),\n",
    "$$\n",
    "where\n",
    "\n",
    "- N is the number of samples\n",
    "- n ie the current sample\n",
    "- k ie the current frequency, where $k\\in [0,N-1]$\n",
    "- $x_n$ is the sine value at sample $n$\n",
    "- $X_k$ are the **(frequency terms or DCT)** which include information of  amplitude. It is called the **spectrum of the signal**.\n",
    "\n",
    "Relation between \n",
    "\n",
    "- $f_s$ : Sampling rate or Frequency of Sampling, where \n",
    "- $T$ : Duration\n",
    "\n",
    "$$\n",
    "f_s = \\frac{N}{T}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Signal, as an addition of three cosines at different frequencies: 1 Hz, 10 Hz, and 50 Hz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2. # duration\n",
    "fs = 100 # Sampling rate/frequency: number of samples per second\n",
    "ts = 1.0 / fs # sampling interval\n",
    "t = np.arange(0, T, ts) # time axis\n",
    "N = len(t)\n",
    "\n",
    "# Generate Signal\n",
    "\n",
    "x = 0\n",
    "x += 3.0 * np.cos(2 * np.pi * 1.00 * t)\n",
    "x += 1.0 * np.cos(2 * np.pi * 10.0 * t)\n",
    "x += 1.0 * np.cos(2 * np.pi * 50.0 * t)\n",
    "\n",
    "# Plot\n",
    "\n",
    "plt.figure()#figsize = (8, 6))\n",
    "plt.plot(t, x)\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosines Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(x)\n",
    "n = np.arange(N)\n",
    "k = n.reshape((N, 1))\n",
    "cosines = np.cos(2 * np.pi * k * n / N)\n",
    "\n",
    "# Plot\n",
    "\n",
    "plt.imshow(cosines[:100, :])\n",
    "plt.xlabel('Time [s]')\n",
    "plt.ylabel('Freq. [Hz]')\n",
    "plt.title('Cosines Basis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decompose signal on cosine basis (dot product), i.e., DCT without signal normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dot(cosines, x)\n",
    "\n",
    "# Frequencies = N / T\n",
    "freqs =  np.arange(N) / T \n",
    "\n",
    "# Examine Spectrum, look for frequencies below N / 2\n",
    "\n",
    "res = pd.DataFrame(dict(freq=freqs, val=X))\n",
    "res = res[:(N // 2 + 1)]\n",
    "res = res.iloc[np.where(res.val > 0.01)]\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Discrete Fourier Transform (DFT)](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.02-Discrete-Fourier-Transform.html)\n",
    "\n",
    "- The Fourier Transform (FT) decompose any signal into a sum of simple sine and cosine waves that we can easily measure the frequency, amplitude and phase.\n",
    "- FT can be applied to continuous or discrete waves, in this chapter, we will only talk about the **Discrete Fourier Transform (DFT)**.\"\n",
    "\n",
    "$$\n",
    "X_k = \\sum_{n=0}^{N-1} x_n e^{-i2\\pi k n/N} =  \\sum_{n=0}^{N-1} x_n [\\cos(2\\pi k n/N) - i \\sin(2\\pi k n/N)],\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "- $X_k$ are the **(frequency terms or DFT)** which include information of both amplitude and phase. It is called the **spectrum of the signal**.\n",
    "\n",
    "\n",
    "If the input signal is a real-valued sequence the negative frequency terms are just the complex conjugates of the corresponding positive-frequency terms, and the negative-frequency terms are therefore redundant. The DFT spectrum will be symmetric. Therefore, usually we only plot the DFT corresponding to the positive frequencies and divide by $N/2$  to get the amplitude corresponding to the time domain signal.\n",
    "\n",
    "The amplitude is the and phase of the signal can be calculated as:\n",
    "\n",
    "TODO\n",
    "[FFT](https://pythonnumericalmethods.studentorg.berkeley.edu/notebooks/chapter24.04-FFT-in-Python.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100 # sampling rate/frequency: number of samples per second\n",
    "ts = 1.0 / fs # sampling interval\n",
    "T = 1 # duration\n",
    "t = np.arange(0, T, ts)\n",
    "\n",
    "x = 3 * np.sin(2 * np.pi * 1 * t)\n",
    "x += np.sin(2 * np.pi * 4 * t)\n",
    "x += 0.5* np.sin(2 * np.pi * 7 * t)\n",
    "\n",
    "plt.figure()#figsize = (8, 6))\n",
    "plt.plot(t, x)\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.fft import fft, ifft\n",
    "\n",
    "X = fft(x)\n",
    "\n",
    "# Frequencies\n",
    "\n",
    "N = len(X) # number of frequencies = number of samples\n",
    "T = N / fs # duration\n",
    "freqs =  np.arange(N) / T # Frequencies = N / T\n",
    "\n",
    "# Examine Spectrum, look for frequencies below N / 2\n",
    "\n",
    "res = pd.DataFrame(dict(freq=freqs, val=abs(X)))\n",
    "res = res[:(N // 2 + 1)]\n",
    "res = res.iloc[np.where(res.val > 0.01)]\n",
    "print(res)\n",
    "\n",
    "def plot_fft(X, freqs, t, xlim):\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.stem(freqs, np.abs(X), 'b', \\\n",
    "            markerfmt=\" \", basefmt=\"-b\")\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.ylabel('FFT Amplitude |X(freq)|')\n",
    "    plt.xlim(0, xlim)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(t, ifft(X), 'r')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_fft(X, freqs, t, xlim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['diet']\n",
    "x -= x.mean()\n",
    "x.plot()\n",
    "\n",
    "fs = 12 # sampling frequency 12 sample / year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fft(x)\n",
    "\n",
    "# Frequencies\n",
    "\n",
    "N = len(X) # number of frequencies = number of samples\n",
    "T = N / fs # duration\n",
    "freqs =  np.arange(N) / T # Frequencies = N / T\n",
    "\n",
    "# Examine Spectrum, look for frequencies below N / 2\n",
    "\n",
    "Xn = abs(X)\n",
    "print(pd.Series(Xn, index=freqs).describe())\n",
    "\n",
    "res = pd.DataFrame(dict(freq_year=freqs, freq_month=12 / freqs, val=Xn))\n",
    "res = res[:(N // 2 + 1)]\n",
    "res = res.iloc[np.where(res.val > 200)]\n",
    "print(res)\n",
    "\n",
    "# plot_fft(X, freqs, t, xlim=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
