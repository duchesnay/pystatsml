{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import pystatsml.plot_utils\n",
    "\n",
    "# Plot parameters\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig_w, fig_h = plt.rcParams.get('figure.figsize')\n",
    "plt.rcParams['figure.figsize'] = (fig_w, fig_h * .5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "- [Patrick Walls course](https://patrickwalls.github.io/mathematicalpython/differentiation/differentiation/) of Dept of Mathematics, University of British Columbia.\n",
    "- [Wikipedia](https://en.wikipedia.org/wiki/Numerical_differentiation)\n",
    "\n",
    "The derivative of a function  at is the limit\n",
    "\n",
    "$$\n",
    "f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n",
    "$$\n",
    "\n",
    "For a fixed step size $h$, the previous formula provides the slope of the function using the forward difference approximation of the derivative. Equivalently, the slope could be estimated using backward approximation with positions $x - h$ and $x$.\n",
    "\n",
    "The most efficient numerical derivative use the central difference formula with step size is the average of the forward and backward approximation (known as symmetric difference quotient):\n",
    "\n",
    "$$\n",
    "f'(a) \\approx \\frac{1}{2} \\left( \\frac{f(a + h) - f(a)}{h} + \\frac{f(a) - f(a - h)}{h} \\right) = \\frac{f(a + h) - f(a - h)}{2h}\n",
    "$$\n",
    "\n",
    "Chose the step size depends of two issues\n",
    "\n",
    "\n",
    "1. Numerical precision: if $h$ is chosen too small, the subtraction will yield a large rounding error due to cancellation will produce a value of zero. For basic central differences, the optimal (Sauer, Timothy (2012). Numerical Analysis. Pearson. p.248.) step is the cube-root of machine epsilon ($2.2*10^{-16}$ for double precision), i.e.: $h\\approx 10^{-5}$:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = np.finfo(np.float64).eps\n",
    "print(\"Machine epsilon: {:e}, Min step size: {:e}\".format(eps, np.cbrt(eps)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The error of the central difference approximation is upper bounded by a function in $\\mathcal{O}(h^2)$. I.e., large step size $h=10^{-2}$  leads to large error of $10^{-4}$. Small step size e.g., $h=10^{-4}$ provide accurate slope estimation in $10^{-8}$.\n",
    "\n",
    "Those two points argue for a step size $h \\in [10^{-3}, 10^{-6}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy [gradient](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html) function for unmerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = [-3, 3]\n",
    "dx = 1e-3\n",
    "n = int((range_[1] - range_[0]) / dx)\n",
    "x = np.linspace(range_[0], range_[1], n)\n",
    "f = lambda x: 3*np.exp(x) / (x**2 + x + 1)\n",
    "\n",
    "y = f(x)\n",
    "dydx = np.gradient(y, dx)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.plot(x[1:-1], dydx[1:-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Numerical differenciation of the function\n",
    " \n",
    "$$\n",
    "f(x) = \\frac{7x^3-5x+1}{2x^4+x^2+1} \\ , \\ x \\in [-5,5]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_ = [-5, 5]\n",
    "dx = 1e-3\n",
    "n = int((range_[1] - range_[0]) / dx) \n",
    "x = np.linspace(range_[0], range_[1], n)\n",
    "f = lambda x:  (7 * x ** 3  - 5 * x + 1) / (2 * x ** 4 + x ** 2 + 1)\n",
    "\n",
    "y = f(x)\n",
    "dydx = np.gradient(y, dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Symbolic Differentiation with sympy to compute true derivative $f'$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "from sympy import lambdify\n",
    "x_s  = sp.symbols('x', real=True) # defining the variables\n",
    "\n",
    "f_sym = (7 * x_s ** 3  - 5 * x_s + 1) / (2 * x_s ** 4 + x_s ** 2 + 1)\n",
    "df_sym =  sp.simplify(sp.diff(f_sym))\n",
    "print(\"f =\", f_sym)\n",
    "print(\"f'=\", df_sym)\n",
    "df_sym = lambdify(x_s, df_sym,  \"numpy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(x, y, label=\"f\")\n",
    "plt.plot(x[1:-1], dydx[1:-1], lw=4, label=\"f' Num. Approx.\")\n",
    "plt.plot(x, df_sym(x), \"--\", label=\"f'\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced numerical differenciation with [numdifftools](https://github.com/pbrod/numdifftools)\n",
    "\n",
    "The numdifftools library addresses numerical differentiation with one or more variables:\n",
    "\n",
    "- Derivative: Compute the derivatives of order 1 through 10 on any scalar function.\n",
    "- directionaldiff: Compute directional derivative of a function of n variables\n",
    "- Gradient: Compute the gradient vector of a scalar function of one or more variables.\n",
    "- Jacobian: Compute the Jacobian matrix of a vector valued function of one or more variables.\n",
    "- Hessian: Compute the Hessian matrix of all 2nd partial derivatives of a scalar function of one or more variables.\n",
    "- Hessdiag: Compute only the diagonal elements of the Hessian matrix\n",
    "\n",
    "To be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Integration\n",
    "\n",
    "- Principles [Patrick Walls course](https://patrickwalls.github.io/mathematicalpython/integration/).\n",
    "- Library: [Scipy integrate](https://docs.scipy.org/doc/scipy/tutorial/integrate.html) package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import pystatsml.plot_utils\n",
    "\n",
    "# Plot parameters\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig_w, fig_h = plt.rcParams.get('figure.figsize')\n",
    "plt.rcParams['figure.figsize'] = (fig_w, fig_h * .5)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods based on sums of patches over intervals\n",
    "\n",
    "Methods for integrating functions given fixed samples: $[(x_1, f(x_1)), ..., (x_i, f(x_i)), ...(x_N, f(x_N)]$.\n",
    "\n",
    "[Riemann sums of rectangles](https://patrickwalls.github.io/mathematicalpython/integration/riemann-sums/) to approximate the area.\n",
    "$$\n",
    "\\sum_{i=1}^N f(x_i^ * ) (x_i - x_{i-1}) \\ \\ , \\ x_i^* \\in [x_{i-1},x_i]\n",
    "$$\n",
    "The error is in $\\mathcal{O}(\\frac{1}{N})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x : 1 / (1 + x ** 2)\n",
    "a, b, N = 0, 5, 10\n",
    "dx = (b - a) / N\n",
    "\n",
    "x = np.linspace(a, b, N+1)\n",
    "y = f(x)\n",
    "\n",
    "x_ = np.linspace(a,b, 10*N+1) # 10 * N points to plot the function smoothly\n",
    "plt.plot(x_, f(x_), 'b')\n",
    "x_left = x[:-1] # Left endpoints\n",
    "y_left = y[:-1]\n",
    "plt.plot(x_left,y_left,'b.',markersize=10)\n",
    "plt.bar(x_left,y_left,width=dx, alpha=0.2,align='edge',edgecolor='b')\n",
    "plt.title('Left Riemann Sum, N = {}'.format(N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Riemann sums with 100 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, N = 0, 5, 50\n",
    "dx = (b - a) / N\n",
    "x = np.linspace(a, b, N+1)\n",
    "\n",
    "y = f(x)\n",
    "print(\"Integral:\", np.sum(f(x[:-1]) * np.diff(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Trapezoid Rule](https://patrickwalls.github.io/mathematicalpython/integration/trapezoid-rule/)** sum the trapezoids connecting the points. The error is in $\\mathcal{O}(\\frac{1}{N^2})$. Use\n",
    "[scipy.integrate.trapezoid](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.trapezoid.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "integrate.trapezoid(f(x[:-1]), dx=dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Simpson's rule](https://patrickwalls.github.io/mathematicalpython/integration/simpsons-rule/)** uses a quadratic polynomial on each subinterval of a partition to approximate the function and to compute the definite integral. The error is in $\\mathcal{O}(\\frac{1}{N^4})$.\n",
    "Use\n",
    "[scipy.integrate.simpson](https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.simpson.html#scipy.integrate.simpson) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "integrate.simpson(f(x[:-1]), dx=dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Gauss-Legendre Quadrature](https://en.wikipedia.org/wiki/Gauss%E2%80%93Legendre_quadrature)** approximate the integral of a function as a weighted sum of Legendre polynomials.\n",
    "\n",
    "Methods for Integrating functions given function object $f()$ that could be evaluated for any value $x$ in a range $[a, b]$.\n",
    "\n",
    "Use\n",
    "[scipy.integrate.quad](https://docs.scipy.org/doc/scipy/tutorial/integrate.html#general-integration-quad) function. The first argument to `quad` is a “callable” Python object (i.e., a function, method, or class instance). Notice the use of a lambda- function in this case as the argument. The next two arguments are the limits of integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "integrate.quad(f, a=a, b=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return values are the estimated of the integral and the estimate of the absolute integration error. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystatsml_teacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
