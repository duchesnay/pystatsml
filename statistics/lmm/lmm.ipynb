{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Linear Mixed Models\n",
    "\n",
    "**Acknowledgements**: Firstly, it's right to pay thanks to the blogs and sources I have used in writing this tutorial. Many parts of the text are quoted from the brillant book from  Brady T. West, Kathleen B. Welch and Andrzej T. Galecki, see [Brady et al. 2014] in the references section below.\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "_Quoted from [Brady et al. 2014]_:A linear mixed model (LMM) is a parametric linear model for **clustered, longitudinal, or repeated-measures** data that quantifies the relationships between a continuous dependent variable and various predictor variables. An LMM may include both **fixed-effect** parameters associated with one or more continuous or categorical covariates and **random effects** associated with one or more random factors. The mix of fixed and random effects gives the linear mixed model its name. Whereas fixed-effect parameters describe the relationships of the covariates to the dependent variable for an entire population, random effects are specific to clusters or subjects within a population. LMM is closely related with hierarchical linear model (HLM).\n",
    "\n",
    "### Clustered/structured datasets\n",
    "\n",
    "_Quoted from [Bruin 2006]_: Random effects, are used when there is non independence in the data, such as arises from a hierarchical structure with clustered data. For example, students could be sampled from within classrooms, or patients from within doctors. When there are multiple levels, such as patients seen by the same doctor, the variability in the outcome can be thought of as being either within group or between group. Patient level observations are not independent, as within a given doctor patients are more similar. Units sampled at the highest level (in our example, doctors) are independent.\n",
    "\n",
    "The continuous outcome variables is **structured or clustered** into **units** within **observations are not independents**. Types of clustered data:\n",
    "\n",
    "1. studies with clustered data, such as students in classrooms, or experimental designs with random blocks, such as batches of raw material for an industrial process\n",
    "2. **longitudinal or repeated-measures** studies, in which subjects are measured repeatedly over time or under different conditions.\n",
    "\n",
    "\n",
    "\n",
    "### Mixed effects = fixed + random effects\n",
    "\n",
    "\n",
    "**Fixed effects** may be associated with continuous covariates, such as weight, baseline test score, or socioeconomic status, which take on values from a continuous (or sometimes a multivalued ordinal) range, or with factors, such as gender or treatment group, which are categorical. Fixed effects are unknown constant parameters associated with either continuous covariates or the levels of categorical factors in an LMM. Estimation of these parameters in LMMs is generally of intrinsic interest, because they indicate the relationships of the covariates with the continuous outcome variable.\n",
    "\n",
    "Example: Suppose we want to study the relationship between the height of individuals and their gender. We will: sample individuals in a population (first source of randomness), measure their height (second source of randomness), and consider their gender (fixed for a given individual). Finally, these measures are modeled in the following linear model:\n",
    "\n",
    "$$\n",
    "\\text{height}_i = \\beta_0 + \\beta_1 \\text{gender}_i + \\varepsilon_i\n",
    "$$\n",
    "\n",
    "- height: is the quantitative dependant (outcome, prediction) variable, \n",
    "- gender: is an independant factor. It is known for a given individual. It is assumed that is has the same effect on all sampled individuals.\n",
    "- $\\varepsilon$ is the noise. The sampling and measurement hazards are confounded at the individual level in this random variable. It is a random effect at the individual level.\n",
    "\n",
    "**Random effect** When the levels of a factor can be thought of as having been sampled from a sample space, such that each particular level is not of intrinsic interest (e.g., classrooms or clinics that are randomly sampled from a larger population of classrooms or clinics), the effects associated with the levels of those factors can be modeled as random effects in an LMM. In contrast to fixed effects, which are represented by constant parameters in an LMM, random effects are represented by (unobserved) random variables, which are usually assumed to follow a normal distribution.\n",
    "\n",
    "Example: Suppose now that we want to study the same effect on a global scale but by randomly sampling countries ($j$) and then individuals ($i$) in these countries. The model will be the following:\n",
    "\n",
    "$$\n",
    "\\text{height}_{ij} = \\beta_0 + \\beta_1 \\text{gender}_{ij} + u_j \\text{country}_{ij} + \\varepsilon_{ij}\n",
    "$$\n",
    "\n",
    "- $\\text{country}_{ij} =$ {$1$ if individual $i$ belongs to country $j$, $0$ otherwise}, is an independant random factor which has three important properties:\n",
    "\n",
    "1. has been **sampled** (third source of randomness)\n",
    "2. **is not of interest**\n",
    "3. creates **clusters** of indivuduals within the same country whose heights is likely to be **correlated**. $u_j$ will be the random effect associated to country $j$. It can be modeled as a random country-specific shift in height, a.k.a. a random intercept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Random intercept\n",
    "\n",
    "The `score_parentedu_byclass` dataset measure a `score` obtained by 60 students, indexed by $i$, within 3 `classroom` (with different teacher), indexed by $j$, given the education level `edu` of their parents. We want to study the link between `score` and `edu`. Observations, `score` are strutured by the sampling of classroom, see Fig below. `score` from the same classroom are are not indendant from each other: they shifted upward or backward thanks to a classroom or teacher effect. There is an **intercept** for each classroom. But this effect is not known given a student (unlike the age or the sex), it is a consequence of a random sampling of the classrooms. It is called a **random intercept**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from stat_lmm_utils import rmse_coef_tstat_pval\n",
    "from stat_lmm_utils import plot_lm_diagnosis\n",
    "from stat_lmm_utils import plot_ancova_oneslope_grpintercept\n",
    "from stat_lmm_utils import plot_lmm_oneslope_randintercept\n",
    "from stat_lmm_utils import plot_ancova_fullmodel\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"RMSE\", \"Coef\", \"Stat\", \"Pval\"])\n",
    "\n",
    "df = pd.read_csv('datasets/score_parentedu_byclass.csv')\n",
    "print(df.head())\n",
    "_ = sns.scatterplot(x=\"edu\", y=\"score\", hue=\"classroom\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Global fixed effect\n",
    "\n",
    "**Global effect** regresses the the independant variable $y=$ `score` on the dependant variable $x=$ `edu` without considering the any classroom effect. For each individual $i$ the model is:\n",
    "\n",
    "$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + \\varepsilon_{ij},$$\n",
    "\n",
    "where, $\\beta_0$ is the global intercept, $\\beta_1$ is the slope associated with `edu` and $\\varepsilon_{ij}$ is the random error at the individual level. Note that the classeroom, $j$ index is not taken into account by the model and could be removed from the equation.\n",
    "\n",
    "The general R formula is: `y ~ x` which in this case is `score ~ edu`.\n",
    "This model is:\n",
    "\n",
    "- **Not sensitive** since it does not model the classroom effect (high standard error).\n",
    "- **Wrong** because, residuals are not normals, and it considers samples from the same classroom to be indenpendant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_glob = smf.ols('score ~ edu', df).fit()\n",
    "\n",
    "#print(lm_glob.summary())\n",
    "print(lm_glob.t_test('edu'))\n",
    "print(\"MSE=%.3f\" % lm_glob.mse_resid)\n",
    "results.loc[len(results)] = [\"LM-Global (biased)\"] +\\\n",
    "    list(rmse_coef_tstat_pval(mod=lm_glob, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(x=\"edu\", y=\"score\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Model diagnosis: plot the normality of the residuals and residuals vs prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lm_diagnosis(residual=lm_glob.resid,\n",
    "                  prediction=lm_glob.predict(df), group=df.classroom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Model a classroom intercept as a fixed effect: ANCOVA\n",
    "\n",
    "Remember ANCOVA = ANOVA with covariates. Model the classroom $z=$ `classroom` (as a fixed effect), ie a vertical shift for each classroom. The slope is the same for all classrooms. For each individual $i$ and each classroom $j$ the model is:\n",
    "\n",
    "$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + u_j z_{ij} + \\varepsilon_{ij},$$\n",
    "\n",
    "where, $u_j$ is the coefficient (an intercept, or a shift) associated with classroom $j$ and $z_{ij} = 1$ if subject $i$ belongs to classroom $j$ else $z_{ij} = 0$.\n",
    "\n",
    "The general R formula is: `y ~ x + z` which in this case is `score ~ edu + classroom`.\n",
    "\n",
    "This model is:\n",
    "\n",
    "- **Sensitive** since it does not model the classroom effect (lower standard error). But,\n",
    "- **questionable** because it considers the classroom to have a fixed constant effect without any uncertainty. However, those classrooms have been sampled from a larger samples of classrooms within the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancova_inter = smf.ols('score ~ edu + classroom', df).fit()\n",
    "# print(sm.stats.anova_lm(ancova_inter, typ=3))\n",
    "# print(ancova_inter.summary())\n",
    "print(ancova_inter.t_test('edu'))\n",
    "\n",
    "print(\"MSE=%.3f\" % ancova_inter.mse_resid)\n",
    "results.loc[len(results)] = [\"ANCOVA-Inter (biased)\"] +\\\n",
    "    list(rmse_coef_tstat_pval(mod=ancova_inter, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ancova_oneslope_grpintercept(x=\"edu\", y=\"score\",\n",
    "                                  group=\"classroom\", model=ancova_inter, df=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Explore the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ancova_inter\n",
    "\n",
    "print(\"## Design matrix (independant variables):\")\n",
    "print(mod.model.exog_names)\n",
    "print(mod.model.exog[:10])\n",
    "\n",
    "print(\"## Outcome (dependant variable):\")\n",
    "print(mod.model.endog_names)\n",
    "print(mod.model.endog[:10])\n",
    "\n",
    "print(\"## Fitted model:\")\n",
    "print(mod.params)\n",
    "sse_ = np.sum(mod.resid ** 2)\n",
    "df_ = mod.df_resid\n",
    "mod.df_model\n",
    "print(\"MSE %f\" % (sse_ / df_), \"or\", mod.mse_resid)\n",
    "\n",
    "print(\"## Statistics:\")\n",
    "print(mod.tvalues, mod.pvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Normality of the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lm_diagnosis(residual=ancova_inter.resid,\n",
    "                  prediction=ancova_inter.predict(df), group=df.classroom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "**Fixed effect** is the coeficient or parameter ($\\beta_1$ in the model) that is associated with a continuous covariates (age, education level, etc.) or (categorical) factor (sex, etc.) that is known without uncertainty once a subject is sampled.\n",
    "\n",
    "**Random effect**, in contrast, is the coeficient or parameter ($u_j$ in the model below) that is associated with a continuous covariates or factor (classroom, individual, etc.) that is not known without uncertainty once a subject is sampled. It generally conrespond to some random sampling. Here the classroom effect depends on the teacher which has been sampled from a larger samples of classrooms within the country. Measures are structured by units or a clustering structure that is possibly hierarchical. Measures within units are not independant. Measures between top  level units are independant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "There are multiple ways to deal with structured data with random effect. One simple approach is to aggregate. \n",
    "\n",
    "### Aggregation of data into independent units\n",
    "\n",
    "Aggregation of measure at classroom level: average all values within classrooms to perform statistical analysis between classroom.\n",
    "1. **Level 1 (within unit)**: Average by classrom:\n",
    "$$\n",
    "x_j = \\text{mean}_i(x_{ij}), y_j = \\text{mean}_i(y_{ij}), \\text{for}~j \\in \\{1, 2, 3\\}.\n",
    "$$\n",
    "\n",
    "2. **Level 2 (between independant units)** Regress averaged `score` on a averaged `edu`:\n",
    "$$y_j = \\beta_0 + \\beta_1 x_j + \\varepsilon_j$$.\n",
    "The general R formula is: `y ~ x` which in this case is `score ~ edu`.\n",
    "\n",
    "\n",
    "This model is:\n",
    "\n",
    "- **Correct** because the aggregated data are independent.\n",
    "- **Not sensitive** since all the within classroom association between edu and is lost.  Moreover, at the aggregate level, there would only be three data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "agregate = df.groupby('classroom').mean()\n",
    "lm_agregate = smf.ols('score ~ edu', agregate).fit()\n",
    "#print(lm_agregate.summary())\n",
    "print(lm_agregate.t_test('edu'))\n",
    "\n",
    "print(\"MSE=%.3f\" % lm_agregate.mse_resid)\n",
    "results.loc[len(results)] = [\"Aggregation\"] +\\\n",
    "    list(rmse_coef_tstat_pval(mod=lm_agregate, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agregate = agregate.reset_index()\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 3), sharex=True, sharey=True)\n",
    "sns.scatterplot(x='edu', y='score', hue='classroom', \n",
    "                data=df, ax=axes[0], s=20, legend=False)\n",
    "sns.scatterplot(x='edu', y='score', hue='classroom',\n",
    "                data=agregate, ax=axes[0], s=150)\n",
    "axes[0].set_title(\"Level 1: Average within classroom\")\n",
    "\n",
    "sns.regplot(x=\"edu\", y=\"score\", data=agregate, ax=axes[1])\n",
    "sns.scatterplot(x='edu', y='score', hue='classroom',\n",
    "                data=agregate, ax=axes[1], s=150)\n",
    "axes[1].set_title(\"Level 2: Test between classroom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Hierarchical/multilevel modeling\n",
    "\n",
    "Another approach to hierarchical data is analyzing data from one unit at a time. Thus, we run three separate linear regressions - one for each classroom in the sample leading to three estimated parameters of the `score` vs `edu` association. Then the paramteres are tested across the classrooms:\n",
    "\n",
    "1. Run three separate linear regressions - one for each classroom \n",
    "$$y_{ij} = \\beta_{0j} + \\beta_{1j} x_{ij} + \\varepsilon_{ij}, \\text{for}~j \\in \\{1, 2, 3\\}$$\n",
    "The general R formula is: `y ~ x` which in this case is `score ~ edu` within classrooms.\n",
    "\n",
    "2. Test across the classrooms if is the $\\text{mean}_j(\\beta_{1j}) = \\beta_0 \\neq 0$ :\n",
    "$$\\beta_{1j} = \\beta_0 + \\varepsilon_j$$\n",
    "The general R formula is: `y ~ 1` which in this case is `beta_edu ~ 1`.\n",
    "\n",
    "This model is:\n",
    "\n",
    "- **Correct** because the invidividual estimated parameters are independent. \n",
    "- **sensitive** since it allows to model differents slope for each classroom (see fixed interaction or random slope below). But it is but **not optimally designed** since there are many models, and each one does not take advantage of the information in data from other classroom. This can also make the results “noisy” in that the estimates from each model are not based on very much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 1 model within classes\n",
    "x, y, group = 'edu', 'score', 'classroom'\n",
    "\n",
    "lv1 = [[group_lab, smf.ols('%s ~ %s' % (y, x), group_df).fit().params[x]]\n",
    "       for group_lab, group_df in df.groupby(group)]\n",
    "\n",
    "lv1 = pd.DataFrame(lv1, columns=[group, 'beta'])\n",
    "print(lv1)\n",
    "\n",
    "# Level 2 model test beta_edu != 0\n",
    "lm_hm = smf.ols('beta ~ 1', lv1).fit()\n",
    "print(lm_hm.t_test('Intercept'))\n",
    "print(\"MSE=%.3f\" % lm_hm.mse_resid)\n",
    "\n",
    "results.loc[len(results)] = [\"Hierarchical\"] + \\\n",
    "    list(rmse_coef_tstat_pval(mod=lm_hm, var='Intercept'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(9, 6))\n",
    "for group_lab, group_df in df.groupby(group):\n",
    "    sns.regplot(x=x, y=y, data=group_df, ax=axes[0])\n",
    "\n",
    "axes[0].set_title(\"Level 1: Regressions within %s\" % group)\n",
    "\n",
    "_ = sns.barplot(x=group, y=\"beta\", hue=group, data=lv1, ax=axes[1])\n",
    "axes[1].axhline(0, ls='--')\n",
    "axes[1].text(0, 0, \"Null slope\")\n",
    "axes[1].set_ylim(-.1, 0.2)\n",
    "_ = axes[1].set_title(\"Level 2: Test Slopes between classrooms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Model the classroom random intercept: linear mixed model\n",
    "\n",
    "Linear mixed models (also called multilevel models) can be thought of as a trade off between these two alternatives. The individual regressions has many estimates and lots of data, but is noisy. The aggregate is less noisy, but may lose important differences by averaging all samples within each classroom. LMMs are somewhere in between.\n",
    "\n",
    "Model the classroom $z=$ `classroom` (as a random effect). For each individual $i$ and each classroom $j$ the model is:\n",
    "\n",
    "$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + u_j z_{ij} + \\varepsilon_{ij},$$\n",
    "\n",
    "where, $u_j$ is a **random intercept** following a normal distribution associated with classroom $j$.\n",
    "\n",
    "The general R formula is: `y ~ x + (1|z)` which in this case it is `score ~ edu + (1|classroom)`. For python statmodels, the grouping factor `|classroom` is omited an provided as `groups` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_inter = smf.mixedlm(\"score ~ edu\", df, groups=df[\"classroom\"],\n",
    "                        re_formula=\"~1\").fit()\n",
    "# But since the default use a random intercept for each group, the following\n",
    "# formula would have provide the same result:\n",
    "# lmm_inter = smf.mixedlm(\"score ~ edu\", df, groups=df[\"classroom\"]).fit()\n",
    "print(lmm_inter.summary())\n",
    "\n",
    "results.loc[len(results)] = [\"LMM-Inter\"] + \\\n",
    "    list(rmse_coef_tstat_pval(mod=lmm_inter, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Explore model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fixed effect:\")\n",
    "print(lmm_inter.params)\n",
    "\n",
    "print(\"Random effect:\")\n",
    "print(lmm_inter.random_effects)\n",
    "\n",
    "intercept = lmm_inter.params['Intercept']\n",
    "var = lmm_inter.params[\"Group Var\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmm_oneslope_randintercept(x='edu', y='score',\n",
    "                                group='classroom', df=df, model=lmm_inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Random slope\n",
    "\n",
    "Now suppose that the classroom random effect is not just a vertical shift (random intercept) but that some teachers \"compensate\" or \"amplify\" educational disparity. The slope of the linear relation between score and edu for teachers that amplify will be larger. In the contrary, it will be smaller for teachers that compensate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Model the classroom intercept and slope as a fixed effect: ANCOVA with interactions\n",
    "\n",
    "1. Model the global association between `edu` and `score`:  $y_{ij} = \\beta_0 + \\beta_1 x_{ij}$, in R: `score ~ edu`.\n",
    "2. Model the classroom $z_j=$ `classroom` (as a fixed effect) as a vertical shift (intercept,  $u^1_j$) for each classroom $j$ indicated by $z_{ij}$:  $y_{ij} = u^1_j z_{ij}$, in R: `score ~ classroom`.\n",
    "3. Model the classroom (as a fixed effect) specitic slope ($u^\\alpha_j$):  $y_i = u^\\alpha_j x_i z_j$ `score ~ edu:classroom`. The $x_i z_j$ forms 3 new columns with values of $x_i$ for each `edu` level, ie.: for  $z_j$ ` classroom` 1, 2 and 3.\n",
    "4. Put everything together:\n",
    "$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + u^1_j z_{ij} + u^\\alpha_j z_{ij} x_{ij} + \\varepsilon_{ij},$$\n",
    "in R: `score ~ edu + classroom edu:classroom` or mor simply `score ~ edu * classroom` that denotes the full model with the additive contribution of each regressor and all their interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancova_full = smf.ols('score ~ edu + classroom + edu:classroom', df).fit()\n",
    "# Full model (including interaction) can use this notation:\n",
    "# ancova_full = smf.ols('score ~ edu * classroom', df).fit()\n",
    "\n",
    "# print(sm.stats.anova_lm(lm_fx, typ=3))\n",
    "# print(lm_fx.summary())\n",
    "print(ancova_full.t_test('edu'))\n",
    "print(\"MSE=%.3f\" % ancova_full.mse_resid)\n",
    "results.loc[len(results)] = [\"ANCOVA-Full (biased)\"] + \\\n",
    "    list(rmse_coef_tstat_pval(mod=ancova_full, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The graphical representation of the model would be the same than the one provided for \"Model a classroom intercept as a fixed effect: ANCOVA\". The same slope (associated to `edu`) with different interpcept, depicted as dashed black lines. Moreover we added, as solid lines, the model's prediction that account different slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model parameters:\")\n",
    "print(ancova_full.params)\n",
    "\n",
    "plot_ancova_fullmodel(x='edu', y='score',\n",
    "                      group='classroom', df=df, model=ancova_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "### Model the classroom random intercept and slope with LMM\n",
    "\n",
    "The model looks similar to the ANCOVA with interactions:\n",
    "$$y_{ij} = \\beta_0 + \\beta_1 x_{ij} + u^1_j z_{ij} + u^\\alpha_j z_{ij} x_{ij} + \\varepsilon_{ij},$$\n",
    "\n",
    "but:\n",
    "\n",
    "- $u^1_j$ is a **random intercept** associated with classroom $j$ following the same normal distribution for all classroom, $u^1_j \\sim \\mathcal{N}(\\mathbf{0, \\sigma^1})$.\n",
    "- $u^\\alpha_j$ is a **random slope** associated with classroom $j$ following the same normal distribution for all classroom, $u^\\alpha_j \\sim \\mathcal{N}(\\mathbf{0, \\sigma^\\alpha})$.\n",
    "\n",
    "Note the difference with linear model: the variances parameters ($\\sigma^1, \\sigma^\\alpha$) should be estimated together with fixed effect ($\\beta_0 + \\beta_1$) and random effect ($u^1, u^\\alpha_j$, one pair of random intercept/slope per classroom). The R notation is: `score ~ edu + (edu | classroom)`. or `score ~ 1 + edu + (1 + edu | classroom)`, remember that intercepts are implicit. In statmodels, the notation is `~1+edu` or `~edu` since the groups is provided by the `groups` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_full = smf.mixedlm(\"score ~ edu\", df, groups=df[\"classroom\"],\n",
    "                       re_formula=\"~1+edu\").fit()\n",
    "print(lmm_full.summary())\n",
    "results.loc[len(results)] = [\"LMM-Full (biased)\"] + \\\n",
    "    list(rmse_coef_tstat_pval(mod=lmm_full, var='edu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "The warning results in a singular fit (correlation estimated at 1) caused by too little variance among the random slopes. It indicates that we should considere to remove random slopes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Conclusion on modeling random effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "**Random intercepts**\n",
    "\n",
    "1. LM-Global is wrong (consider residuals to be independent) and has a large error (RMSE, Root Mean Square Error) since it does not adjust for classroom effect.\n",
    "2. ANCOVA-Inter is \"wrong\" (consider residuals to be independent) but it has a small error since it adjusts for classroom effect.\n",
    "3. Aggregation is ok (units average are independent) but it looses a lot of degrees of freedom (df = 2 = 3 classroom - 1 intercept) and a lot of informations.\n",
    "4. Hierarchical model is ok (unit average are independent) and it has a reasonable error (look at the statistic, not the RMSE).\n",
    "4. LMM-Inter (with random intercept) is ok (it models residuals non-independence) and it has a small error.\n",
    "5. ANCOVA-Inter, Hierarchical model and LMM provide similar coefficients for the fixed effect. So if statistical significance is not the key issue, the \"biased\" ANCOVA is a reasonable choice.\n",
    "6. Hierarchical and LMM with random intercept are the best options (unbiased and sensitive), with an advantage to LMM.\n",
    "\n",
    "**Random slopes**\n",
    "\n",
    "Modeling individual slopes in both ANCOVA-Full and LMM-Full decreased the statistics, suggesting that the supplementary regressors (one per classroom) do not significantly improve the fit of the model (see errors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Theory of Linear Mixed Models\n",
    "\n",
    "If we consider only 6 samples ($i \\in \\{1, 6\\}$, two sample for each classroom $j \\in$ {c0, c1, c2}) and the random intercept model. Stacking the 6 observations, the equation $y_{ij} = \\beta_0 + \\beta_1 x_{ij} + u_j z_j + \\varepsilon_{ij}$ gives :\n",
    "\n",
    "$$\n",
    "\\begin{split}\\begin{bmatrix}\n",
    "\\text{score}\\\\\n",
    "7.2 \\\\ 7.9  \\\\ 9.1 \\\\ 11.1 \\\\ 14.6 \\\\ 14.0 \\end{bmatrix}\n",
    "  =\n",
    "  \\begin{bmatrix}\n",
    "  \\text{Inter} & \\text{Edu}\\\\\n",
    "  1 & 2 \\\\\n",
    "  1 & 10 \\\\\n",
    "  1 & 1 \\\\\n",
    "  1 & 9 \\\\\n",
    "  1 & 8 \\\\\n",
    "  1 & 5 \\\\\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix} \\text{Fix} \\\\ \\beta_0 \\\\ \\beta_1 \\end{bmatrix}\n",
    "  +\n",
    "  \\begin{bmatrix}\n",
    "  \\text{c1} & \\text{c2} & \\text{c3}\\\\\n",
    "  1 & 0 & 0 \\\\\n",
    "  1 & 0 & 0 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  0 & 1 & 0 \\\\\n",
    "  0 & 0 & 1 \\\\\n",
    "  0 & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix} \\text{Rand} \\\\ u_{1} \\\\ u_{2} \\\\ u_{3} \\end{bmatrix}\n",
    "  +\n",
    "  \\begin{bmatrix}\\text{Err}\\\\ \\epsilon_1 \\\\ \\epsilon_2 \\\\ \\epsilon_3 \\\\ \\epsilon_4 \\\\ \\epsilon_5 \\\\ \\epsilon_6\\end{bmatrix}\\end{split}\n",
    "$$\n",
    "where $\\mathbf{u_1} = u_{1}, u_{2}, u_{3}$ are the 3 parameters associated with the 3 level of the single random factor `classroom`.\n",
    "\n",
    "This can be re-written in a more general form as:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\mathbf{X}\\mathbf{\\beta} + \\mathbf{Z}\\mathbf{u} + \\mathbf{\\varepsilon},\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{y}$ is the $N \\times 1$ vector of the $N$ observations.\n",
    "- $\\mathbf{X}$ is the $N \\times P$ design matrix, which represents the known values of the $P$ covariates for the $N$ observations.\n",
    "- $\\mathbf{\\beta}$ is a $P \\times 1$ vector unknown regression coefficients (or fixed-effect parameters) associated with the $P$ covariates.\n",
    "- $\\mathbf{\\varepsilon}$ is a $N \\times 1$ vector of residuals $\\mathbf{\\epsilon} \\sim \\mathcal{N}(\\mathbf{0, R})$, where $\\mathbf{R}$ is a $N \\times N$ matrix.\n",
    "- $\\mathbf{Z}$ is a $N \\times Q$ design matrix of random factors and covariates. In an LMM in which only the intercepts are assumed to vary randomly from $Q$ units, the $\\mathbf{Z}$  matrix would simply be $Q$ columns of indicators 1 (if subject belong to unit q) or 0 otherwise.\n",
    "- $\\mathbf{u}$ is a $Q \\times 1$ vector of $Q$ random effects associated with the $Q$ covariates in the $\\mathbf{Z}$  matrix. Note that one random factor of 3 levels will be coded by 3 coefficients in $\\mathbf{u}$ and 3 columns $\\mathbf{Z}$. $\\mathbf{u} \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{D})$ where $\\mathbf{D}$ is plays a central role of the covariance structures associated with the mixed effect.\n",
    "\n",
    "**Covariance structures of the residuals covariance matrix: $\\mathbf{R}$**\n",
    "\n",
    "Many different covariance structures are possible for the $\\mathbf{R}$ matrix. The simplest covariance matrix for $\\mathbf{R}$ is the diagonal structure, in which the residuals associated with observations on the same subject are assumed to be uncorrelated and to have equal variance: $\\mathbf{R} = \\sigma \\mathbf{I}_N$. Note that in this case, the correlation between observation within unit stem from mixed effects, and will be encoded in the $\\mathbf{D}$ below. However, other model exists: popular models are the compound symmetry and first-order autoregressive structure, denoted by AR(1).\n",
    "\n",
    "**Covariance structures associated with the random effect**\n",
    "\n",
    "Many different covariance structures are possible for the $\\mathbf{D}$ matrix. The usual prartice associate a single variance parameter (a scalar, $\\sigma_k$) to each random-effects factor $k$ (eg. `classroom`). Hence $\\mathbf{D}$ is simply parametrized by a set of scalars $\\sigma_k, k \\in \\{1, K\\}$ for the $K$ random factors such the sum of levels of the $K$ factors equals $Q$. In our case $K=1$ with 3 levels ($Q = 3$), thus $\\mathbf{D} = \\sigma_k \\mathbf{I}_Q$. Factors $k$ define $k$ **variance components** whose parameters $\\sigma_k$ should be estimated addition to the variance of the model errors $\\sigma$. The $\\sigma_k$ and $\\sigma$ will define the overall covariance structure: $\\mathbf{V}$, as define below.\n",
    "\n",
    "In this model, the effect of a particular level (eg. classroom 0 `c0`) of a random factor is supposed to be sampled from a normal distritution of variance $\\sigma_k$. This is a crucial aspect of LMM which is related to $\\ell_2$-regularization or Bayes Baussian prior. Indeed, the estimator of associated to each level $u_i$ of a random effect is shrinked toward 0 since $u_i \\sim \\mathcal{N}(0, \\sigma_k)$. Thus it tends to be smaller than the estimated effects would be if they were computed by treating a random factor as if it were fixed.\n",
    "\n",
    "\n",
    "**Overall covariance structure as variance components $\\mathbf{V}$**\n",
    "\n",
    "The overall covariance structure can be obtained by:\n",
    "$$\n",
    "\\mathbf{V} = \\sum_k \\sigma_k \\mathbf{ZZ}' + \\mathbf{R}.\n",
    "$$\n",
    "The $\\sum_k \\sigma_k \\mathbf{ZZ}'$ define the $N \\times N$ variance structure, using $k$ variance components, modeling the non-independance between the observations. In our case with only one component we get:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{V} &=\n",
    "\\begin{bmatrix}\n",
    "\\sigma_k& \\sigma_k & 0 & 0 & 0 & 0\\\\\n",
    "\\sigma_k& \\sigma_k & 0 & 0 & 0 & 0\\\\\n",
    "0& 0 & \\sigma_k & \\sigma_k & 0 & 0\\\\\n",
    "0& 0 & \\sigma_k & \\sigma_k & 0 & 0\\\\\n",
    "0& 0 & 0 & 0 & \\sigma_k & \\sigma_k\\\\\n",
    "0& 0 & 0 & 0 & \\sigma_k & \\sigma_k\\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "\\sigma& 0 & 0 & 0 & 0 & 0\\\\\n",
    "0& \\sigma & 0 & 0 & 0 & 0\\\\\n",
    "0& 0 & \\sigma & 0 & 0 & 0\\\\\n",
    "0& 0 & 0 & \\sigma & 0 & 0\\\\\n",
    "0& 0 & 0 & 0 & \\sigma & 0\\\\\n",
    "0& 0 & 0 & 0 & 0 & \\sigma\\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&=\n",
    "\\begin{bmatrix}\n",
    "\\sigma_k+\\sigma& \\sigma_k & 0 & 0 & 0 & 0\\\\\n",
    "\\sigma_k& \\sigma_k+\\sigma & 0 & 0 & 0 & 0\\\\\n",
    "0& 0 & \\sigma_k+\\sigma & \\sigma_k & 0 & 0\\\\\n",
    "0& 0 & \\sigma_k & \\sigma_k+\\sigma & 0 & 0\\\\\n",
    "0& 0 & 0 & 0 & \\sigma_k+\\sigma & \\sigma_k\\\\\n",
    "0& 0 & 0 & 0 & \\sigma_k & \\sigma_k+\\sigma\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "**The model to be minimized**\n",
    "\n",
    "Here $\\sigma_k$ and $\\sigma$ are called variance components of the model. Solving the problem constist in the estimation the fixed effect $\\mathbf{\\beta}$ and the parameters $\\sigma, \\sigma_k$ of the variance-covariance structure. This is obtained by minizing the The likelihood of the sample:\n",
    "$$\n",
    "l(\\mathbf{y}, \\mathbf{\\beta}, \\sigma, \\sigma_k) = \\frac{1}{2\\pi^{n/2}\\det(\\mathbf{V})^{1/2}}\\exp -\\frac{1}{2}(\\mathbf{y - X\\beta}) \\mathbf{V}^{-1}(\\mathbf{y - X\\beta})\n",
    "$$\n",
    "\n",
    "LMM introduces the variance-covariance matrix $\\mathbf{V}$ to reweigtht the residuals according to the non-independance between observations. If $\\mathbf{V}$ is known, of. The optimal value of be can be obtained analytically using generalized least squares (GLS, minimisation of mean squared error associated with Mahalanobis metric):\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{\\beta}} = \\mathbf{X'\\hat{V}^{-1}X^{-1}X'\\hat{V}^{-1}y}\n",
    "$$\n",
    "\n",
    "In the general case, $\\mathbf{V}$ is unknown, therefore iterative solvers should be use to estimate the fixed effect $\\mathbf{\\beta}$ and the parameters ($\\sigma, \\sigma_k, \\ldots$) of variance-covariance matrix $\\mathbf{V}$. The ML Maximum Likelihood estimates provide biased solution for $\\mathbf{V}$ because they do not take into account the loss of degrees of freedom that results from estimating the fixed-effect parameters in $\\mathbf{\\beta}$. For this reason, REML (restricted (or residual, or reduced) maximum likelihood) is often preferred to ML estimation.\n",
    "\n",
    "**Tests for Fixed-Effect Parameters**\n",
    "\n",
    "Quoted from [Brady et al. 2014]: \"The approximate methods that apply to both t-tests and F-tests take into account the presence of random effects and correlated residuals in an LMM. Several of these approximate methods (e.g., the **Satterthwaite** method, or the “between-within” method) involve different choices for the degrees of freedom used in\" the approximate t-tests and F-tests\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "## Checking model assumptions (Diagnostics)\n",
    "\n",
    "Residuals plotted against predicted values represents a random pattern or not.\n",
    "\n",
    "These residual vs. fitted plots are used to verify model assumptions and to detect outliers and potentially influential observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Brady et al. 2014: Brady T. West, Kathleen B. Welch, Andrzej T. Galecki, [Linear Mixed Models: A Practical Guide Using Statistical Software (2nd Edition)](http://www-personal.umich.edu/~bwest/almmussp.html), 2014\n",
    "\n",
    "- Bruin 2006: [Introduction to Linear Mixed Models](https://stats.idre.ucla.edu/other/mult-pkg/introduction-to-linear-mixed-models), UCLA, Statistical Consulting Group.\n",
    "\n",
    "- [Statsmodel: Linear Mixed Effects Models](https://www.statsmodels.org/stable/mixed_linear.html)\n",
    "\n",
    "- [Comparing R lmer to statsmodels MixedLM](https://www.statsmodels.org/stable/examples/notebooks/generated/mixed_lm_example.html)\n",
    "\n",
    "- [Statsmoels: Variance Component Analysis with nested groups](https://github.com/statsmodels/statsmodels/blob/main/examples/notebooks/variance_components.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
