<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Univariate Statistics &#8212; Statistics and Machine Learning in Python 0.8 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/basic.css?v=b08954a9" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css?v=27fed22d" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-binder.css?v=f4aeca0c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-dataframe.css?v=2082cf3c" />
    <link rel="stylesheet" type="text/css" href="../_static/sg_gallery-rendered-html.css?v=1277b6f3" />
    <script src="../_static/documentation_options.js?v=a0e24af7"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="search" type="application/opensearchdescription+xml"
          title="Search within Statistics and Machine Learning in Python 0.8 documentation"
          href="../_static/opensearch.xml"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Hands-On: Brain volumes study" href="../auto_gallery/stat_univ_lab_brain-volume.html" />
    <link rel="prev" title="Optimization (Minimization) by Gradient Descent" href="../numerical_methods/optim_gradient_descent.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="univariate-statistics">
<h1>Univariate Statistics<a class="headerlink" href="#univariate-statistics" title="Link to this heading">¶</a></h1>
<p>Basics univariate statistics are required to explore dataset:</p>
<ul class="simple">
<li><p>Discover associations between a variable of interest and potential
predictors. It is strongly recommended to start with simple univariate
methods before moving to complex multivariate predictors.</p></li>
<li><p>Assess the prediction performances of machine learning predictors.</p></li>
<li><p>Most of the univariate statistics are based on the linear model which
is one of the main model in machine learning.</p></li>
</ul>
<section id="libraries">
<h2>Libraries<a class="headerlink" href="#libraries" title="Link to this heading">¶</a></h2>
<p><strong>Statistics</strong></p>
<ul class="simple">
<li><p>Descriptive statistics and distributions:
<a class="reference external" href="https://numpy.org/doc/stable/reference/routines.statistics.html">Numpy</a></p></li>
<li><p>Distributions and tests:
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html">scipy.stats</a></p></li>
<li><p>Advanced statistics (linear models, tests, time series):
<a class="reference external" href="https://www.statsmodels.org/">Statsmodels</a>, see also <a class="reference external" href="https://www.statsmodels.org/stable/api.html">Statsmodels
API</a>:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">statsmodels.api</span></code>: Imported using
<code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">statsmodels.api</span> <span class="pre">as</span> <span class="pre">sm</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">statsmodels.formula.api</span></code>: A convenience interface for specifying
models using formula strings and DataFrames. Canonically imported
using <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">statsmodels.formula.api</span> <span class="pre">as</span> <span class="pre">smf</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">statsmodels.tsa.api</span></code>: Time-series models and methods. Canonically
imported using <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">statsmodels.tsa.api</span> <span class="pre">as</span> <span class="pre">tsa</span></code>.</p></li>
</ul>
</li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Manipulate data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>

<span class="c1"># Statistics</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sm</span>
<span class="c1">#import statsmodels.stats.api as sms</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.formula.api</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">smf</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">statsmodels.stats.stattools</span><span class="w"> </span><span class="kn">import</span> <span class="n">jarque_bera</span>
</pre></div>
</div>
<p><strong>Plots</strong></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pystatsml.plot_utils</span>

<span class="c1"># Plot parameters</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-v0_8-whitegrid&#39;</span><span class="p">)</span>
<span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;figure.figsize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">fig_w</span><span class="p">,</span> <span class="n">fig_h</span> <span class="o">*</span> <span class="mf">.5</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Datasets</strong></p>
<p>Salary</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">salary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../datasets/salary_table.csv&quot;</span><span class="p">)</span>
<span class="k">except</span><span class="p">:</span>
    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/duchesnay/pystatsml/raw/master/datasets/salary_table.csv&#39;</span>
    <span class="n">salary</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</pre></div>
</div>
<p>Iris</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load iris datset</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">get_rdataset</span><span class="p">(</span><span class="s2">&quot;iris&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">data</span>
<span class="n">iris</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">iris</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
<span class="n">iris</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Index</span><span class="p">([</span><span class="s1">&#39;SepalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;SepalWidth&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalWidth&#39;</span><span class="p">,</span> <span class="s1">&#39;Species&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="descriptive-statistics">
<h2>Descriptive Statistics<a class="headerlink" href="#descriptive-statistics" title="Link to this heading">¶</a></h2>
<section id="mean">
<h3>Mean<a class="headerlink" href="#mean" title="Link to this heading">¶</a></h3>
<p>Properties of the expected value operator
<span class="math notranslate nohighlight">\(\operatorname{E}(\cdot)\)</span> of a random variable <span class="math notranslate nohighlight">\(X\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}E(X + c) &amp;= E(X) + c \\
E(X + Y) &amp;= E(X) + E(Y) \\
E(aX)    &amp;= a E(X)\end{split}\]</div>
<p>The estimator <span class="math notranslate nohighlight">\(\bar{x}\)</span> on a sample of size <span class="math notranslate nohighlight">\(n\)</span>:
<span class="math notranslate nohighlight">\(x = x_1, ..., x_n\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\boxed{\bar{x} = \frac{1}{n} \sum_i x_i}\]</div>
<p><span class="math notranslate nohighlight">\(\bar{x}\)</span> is itself a random variable with properties:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(\bar{x}) = \bar{x}\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(\operatorname{Var}(\bar{x}) = \frac{\operatorname{Var}(X)}{n}\)</span>.</p></li>
</ul>
</section>
<section id="variance">
<h3>Variance<a class="headerlink" href="#variance" title="Link to this heading">¶</a></h3>
<div class="math notranslate nohighlight">
\[\operatorname{Var}(X) = E((X - E(X))^2) =  E(X^2) - (E(X))^2\]</div>
<p>The estimator is</p>
<div class="math notranslate nohighlight">
\[\boxed{\sigma_x^2 = \frac{1}{n-1} \sum_i (x_i - \bar{x})^2}\]</div>
<p>Note here the subtracted 1 degree of freedom (df) in the divisor. In
standard statistical practice, <span class="math notranslate nohighlight">\(df=1\)</span> provides an unbiased
estimator of the variance of a hypothetical infinite population. With
<span class="math notranslate nohighlight">\(df=0\)</span> it instead provides a maximum likelihood estimate of the
variance for normally distributed variables.</p>
</section>
<section id="standard-deviation">
<h3>Standard deviation<a class="headerlink" href="#standard-deviation" title="Link to this heading">¶</a></h3>
<div class="math notranslate nohighlight">
\[\operatorname{Std}(X) = \sqrt{\operatorname{Var}(X)}\]</div>
<p>The estimator is simply <span class="math notranslate nohighlight">\(\sigma_x = \sqrt{\sigma_x^2}\)</span>.</p>
</section>
<section id="covariance">
<h3>Covariance<a class="headerlink" href="#covariance" title="Link to this heading">¶</a></h3>
<div class="math notranslate nohighlight">
\[\operatorname{Cov}(X, Y) = E((X - E(X))(Y - E(Y))) =  E(XY) - E(X)E(Y).\]</div>
<p>Properties:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\operatorname{Cov}(X, X) &amp;= \operatorname{Var}(X)\\
\operatorname{Cov}(X, Y) &amp;= \operatorname{Cov}(Y, X)\\
\operatorname{Cov}(cX, Y) &amp;= c \operatorname{Cov}(X, Y)\\
\operatorname{Cov}(X+c, Y) &amp;= \operatorname{Cov}(X, Y)\\\end{split}\]</div>
<p>The estimator with <span class="math notranslate nohighlight">\(df=1\)</span> is</p>
<div class="math notranslate nohighlight">
\[\sigma_{xy} = \frac{1}{n-1} \sum_i (x_i - \bar{x}) (y_i - \bar{y}).\]</div>
</section>
<section id="correlation">
<h3>Correlation<a class="headerlink" href="#correlation" title="Link to this heading">¶</a></h3>
<div class="math notranslate nohighlight">
\[\operatorname{Cor}(X, Y) = \frac{\operatorname{Cov}(X, Y)}{\operatorname{Std}(X)\operatorname{Std}(Y)}\]</div>
<p>The estimator is</p>
<div class="math notranslate nohighlight">
\[\rho_{xy} = \frac{\sigma_{xy}}{\sigma_{x} \sigma_{y}}.\]</div>
</section>
<section id="standard-error-se">
<h3>Standard Error (SE)<a class="headerlink" href="#standard-error-se" title="Link to this heading">¶</a></h3>
<p>The standard error (SE) is the standard deviation (of the sampling
distribution) of a statistic. It is most commonly considered for the
estimator of the mean (<span class="math notranslate nohighlight">\(\bar{x}\)</span>) whose estimator
<span class="math notranslate nohighlight">\(\sigma_{\bar{x}}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[\boxed{\sigma_{\bar{x}} = \frac{\sigma_x}{\sqrt{n}}}\]</div>
</section>
<section id="descriptive-statistics-with-numpy">
<h3>Descriptive statistics with Numpy<a class="headerlink" href="#descriptive-statistics-with-numpy" title="Link to this heading">¶</a></h3>
<ul class="simple">
<li><p>Generate 2 random samples: <span class="math notranslate nohighlight">\(x \sim N(1.78, 0.1)\)</span> and
<span class="math notranslate nohighlight">\(y \sim N(1.66, 0.1)\)</span>, both of size 10.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(\bar{x}, \sigma_x, \sigma_{xy}\)</span> (<code class="docutils literal notranslate"><span class="pre">xbar,</span> <span class="pre">xvar,</span> <span class="pre">xycov</span></code>)
using only the <code class="docutils literal notranslate"><span class="pre">np.sum()</span></code> operation.</p></li>
</ul>
<p>Explore the <code class="docutils literal notranslate"><span class="pre">np.</span></code> module to find out which Numpy functions performs
the same computations and compare them (using <code class="docutils literal notranslate"><span class="pre">assert</span></code>) with your
previous results.</p>
<p>Caution! By default <code class="docutils literal notranslate"><span class="pre">np.var()</span></code> used the biased estimator (with
ddof=0). Set ddof=1 to use unbiased estimator.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># make the example reproducible</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">1.78</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">1.66</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xbar</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">xvar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">xvar</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">xbar</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Covariance</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xycov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">xycov</span><span class="p">)</span>

<span class="n">ybar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">xycov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">x</span> <span class="o">-</span> <span class="n">xbar</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">ybar</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">xycov</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xvar</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">xycov</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">0.00522741</span> <span class="o">-</span><span class="mf">0.00060351</span><span class="p">]</span>
 <span class="p">[</span><span class="o">-</span><span class="mf">0.00060351</span>  <span class="mf">0.00570515</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<section id="descriptives-statistics-on-iris-dataset">
<h3>Descriptives Statistics on Iris Dataset<a class="headerlink" href="#descriptives-statistics-on-iris-dataset" title="Link to this heading">¶</a></h3>
<p><strong>With Pandas</strong></p>
<p>Columns’ means</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span><span class="p">[[</span><span class="s1">&#39;SepalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;SepalWidth&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalWidth&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SepalLength</span>    <span class="mf">5.843333</span>
<span class="n">SepalWidth</span>     <span class="mf">3.057333</span>
<span class="n">PetalLength</span>    <span class="mf">3.758000</span>
<span class="n">PetalWidth</span>     <span class="mf">1.199333</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
<p>Columns’ std-dev. Pandas normalizes by N-1 by default.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span><span class="p">[[</span><span class="s1">&#39;SepalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;SepalWidth&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalWidth&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SepalLength</span>    <span class="mf">0.828066</span>
<span class="n">SepalWidth</span>     <span class="mf">0.435866</span>
<span class="n">PetalLength</span>    <span class="mf">1.765298</span>
<span class="n">PetalWidth</span>     <span class="mf">0.762238</span>
<span class="n">dtype</span><span class="p">:</span> <span class="n">float64</span>
</pre></div>
</div>
<p><strong>With Numpy</strong></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">iris</span><span class="p">[[</span><span class="s1">&#39;SepalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;SepalWidth&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalLength&#39;</span><span class="p">,</span> <span class="s1">&#39;PetalWidth&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">values</span>
<span class="n">X</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">5.84333333</span><span class="p">,</span> <span class="mf">3.05733333</span><span class="p">,</span> <span class="mf">3.758</span>     <span class="p">,</span> <span class="mf">1.19933333</span><span class="p">])</span>
</pre></div>
</div>
<p>Columns’ std-dev. Numpy normalizes by N by default. Set ddof=1 to
normalize by N-1 to get the unbiased estimator.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">array</span><span class="p">([</span><span class="mf">0.82806613</span><span class="p">,</span> <span class="mf">0.43586628</span><span class="p">,</span> <span class="mf">1.76529823</span><span class="p">,</span> <span class="mf">0.76223767</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="probability-distributions">
<h2>Probability Distributions<a class="headerlink" href="#probability-distributions" title="Link to this heading">¶</a></h2>
<ul class="simple">
<li><p>Probabilities of occurrence of possible outcomes</p></li>
<li><p>Description of a random phenomenon in terms of its sample space</p></li>
</ul>
<p>Terminology:</p>
<ul class="simple">
<li><p>Random variable, RV: <span class="math notranslate nohighlight">\(X\)</span>: takes values from a sample space.</p></li>
<li><p><strong>Probability Density Function</strong>
<a class="reference external" href="https://en.wikipedia.org/wiki/Probability_density_function">PDF</a>:
<span class="math notranslate nohighlight">\(P(X) \in [0, 1]\)</span> for <span class="math notranslate nohighlight">\(X \in \mathbb{R}\)</span> or <strong>Probability
mass function</strong>
<a class="reference external" href="https://en.wikipedia.org/wiki/Probability_mass_function">PMF</a> if
<span class="math notranslate nohighlight">\(X\)</span> is a discrete RV.</p></li>
<li><p><strong>Cumulative Distribution Function</strong>
<a class="reference external" href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a>
<span class="math notranslate nohighlight">\(P(X \leq x)\)</span>.</p></li>
<li><p><strong>Percent Point Function</strong> or <a class="reference external" href="https://en.wikipedia.org/wiki/Quantile_function">Quantile
Function</a> (inverse
of CDF), i.e., values of <span class="math notranslate nohighlight">\(x\)</span> such <span class="math notranslate nohighlight">\(P(X \leq x)=\)</span> a given
quantile.</p></li>
</ul>
<section id="histogram-as-probability-density-function-estimator">
<h3>Histogram as probability <a class="reference external" href="https://en.wikipedia.org/wiki/Density_estimation">density function estimator</a><a class="headerlink" href="#histogram-as-probability-density-function-estimator" title="Link to this heading">¶</a></h3>
<p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.histogram.html#numpy.histogram">numpy.histogram</a>
can be used to probability density function at the each histogram bin,
setting <code class="docutils literal notranslate"><span class="pre">density=True</span></code> parameter. Warning, <a class="reference external" href="https://stackoverflow.com/questions/21532667/numpy-histogram-cumulative-density-does-not-sum-to-1">histogram doesn’t sum to
1</a>.
Histogram as PDF estimator should be multiplied by dx’s to sum to 1.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">50000</span><span class="p">)</span>
<span class="n">hist</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">dx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sum(Hist)=&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hist</span><span class="p">),</span> <span class="s2">&quot;Sum(Hist * dx)=&quot;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">hist</span> <span class="o">*</span> <span class="n">dx</span><span class="p">))</span>

<span class="n">pdf</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">bins</span><span class="p">)</span> <span class="c1"># True probability density function</span>

<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">sharex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">hist</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dx</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Estimation&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bins</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;True Norm.&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="p">(</span><span class="n">hist</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(),</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">dx</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Sum</span><span class="p">(</span><span class="n">Hist</span><span class="p">)</span><span class="o">=</span> <span class="mf">5.589909828006291</span> <span class="n">Sum</span><span class="p">(</span><span class="n">Hist</span> <span class="o">*</span> <span class="n">dx</span><span class="p">)</span><span class="o">=</span> <span class="mf">1.0</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_23_1.png" src="../_images/stat_univ_23_1.png" />
</section>
<section id="kernel-density-estimation-kde">
<h3><a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_density_estimation">Kernel Density Estimation (KDE)</a><a class="headerlink" href="#kernel-density-estimation-kde" title="Link to this heading">¶</a></h3>
<p>TODO</p>
</section>
<section id="normal-distribution">
<h3>Normal distribution<a class="headerlink" href="#normal-distribution" title="Link to this heading">¶</a></h3>
<p>The normal distribution, noted <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma)\)</span> with
parameters: <span class="math notranslate nohighlight">\(\mu\)</span> mean (location) and <span class="math notranslate nohighlight">\(\sigma&gt;0\)</span> std-dev.
Estimators: <span class="math notranslate nohighlight">\(\bar{x}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{x}\)</span>.</p>
<p>The normal distribution, noted <span class="math notranslate nohighlight">\(\mathcal{N}\)</span>, is useful because of
the central limit theorem (CLT) which states that: given certain
conditions, the arithmetic mean of a sufficiently large number of
iterates of independent random variables, each with a well-defined
expected value and well-defined variance, will be approximately normally
distributed, regardless of the underlying distribution.</p>
<p>Documentation:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html">numpy.random.normal</a></p></li>
<li><p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html#scipy.stats.norm">scipy.stats.norm</a></p></li>
</ul>
<p>Random number generator using Numpy</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># using numpy:</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
<p>Distribution using Scipy</p>
<ul class="simple">
<li><p>Random number generator <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu,\,\sigma^{2})\)</span>:
<code class="docutils literal notranslate"><span class="pre">norm.rvs(loc=mean,</span> <span class="pre">scale=sd,</span> <span class="pre">size=n)</span></code></p></li>
<li><p><strong>Probability Density Function (PDF)</strong>: <span class="math notranslate nohighlight">\(P(X) \in [0, 1]\)</span> for
<span class="math notranslate nohighlight">\(X \in \mathbb{R}\)</span>: <code class="docutils literal notranslate"><span class="pre">norm.pdf(values,</span> <span class="pre">loc=mean,</span> <span class="pre">scale=sd)</span></code></p></li>
<li><p><strong>Cumulative Distribution Function (CDF)</strong> <span class="math notranslate nohighlight">\(P(X \leq x)\)</span> :
<code class="docutils literal notranslate"><span class="pre">norm.cdf(x,</span> <span class="pre">loc=mean,</span> <span class="pre">scale=sd)</span></code></p></li>
<li><p>Percent Point Function (inverse of CDF), i.e., values of <span class="math notranslate nohighlight">\(x\)</span>
such <span class="math notranslate nohighlight">\(P(X &lt; x)=\)</span> a given percentiles :
<code class="docutils literal notranslate"><span class="pre">norm.ppf(q,</span> <span class="pre">loc=0,</span> <span class="pre">scale=1)</span></code></p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span>

<span class="c1"># Random number generator</span>
<span class="n">x_rv</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="c1"># PDF: P(values)</span>
<span class="n">pdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># CDF: P(X &lt; values)</span>
<span class="n">cdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="c1"># PPF: Values such P(X &lt; values) = percentiles</span>
<span class="n">percentiles_of_cdf</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.025</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span> <span class="mf">0.975</span><span class="p">]</span>
<span class="n">x_for_percentiles_of_cdf</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">percentiles_of_cdf</span><span class="p">,</span>
                                                <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="c1"># Percentiles of CDF = CDF(x values for CDF percentiles)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">percentiles_of_cdf</span><span class="p">,</span>
                   <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x_for_percentiles_of_cdf</span><span class="p">))</span>

<span class="c1"># Values for percentiles of CDF</span>
<span class="p">[</span><span class="s2">&quot;P(X&lt;</span><span class="si">{:.02f}</span><span class="s2">)=</span><span class="si">{:.1%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">ppf</span><span class="p">)</span> <span class="k">for</span>
 <span class="n">ppf</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">percentiles_of_cdf</span><span class="p">,</span>
                 <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">percentiles_of_cdf</span><span class="p">,</span>
                                      <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">))]</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;P(X&lt;-1.96)=2.5%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;-1.28)=10.0%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;-0.67)=25.0%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;0.00)=50.0%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;0.67)=75.0%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;1.28)=90.0%&#39;</span><span class="p">,</span>
 <span class="s1">&#39;P(X&lt;1.96)=97.5%&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p>Plot histogram, true distribution (PDF), and area of CDF</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">x_rv</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Histogram (Estimator)&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">pdf_x_range</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;PDF: P(X)&quot;</span><span class="p">)</span>

<span class="c1"># PPF: Values such P(X &lt; values) = 2.5%</span>
<span class="n">percentile_of_cdf</span> <span class="o">=</span> <span class="mf">0.025</span>
<span class="n">x_for_percentile_of_cdf</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">percentile_of_cdf</span><span class="p">,</span>
                                               <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>
<span class="n">pdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
<span class="n">pdf_x_range</span><span class="p">[</span><span class="n">x_range</span> <span class="o">&gt;</span> <span class="n">x_for_percentile_of_cdf</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span> <span class="n">y1</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pdf_x_range</span><span class="p">)),</span> <span class="n">y2</span><span class="o">=</span><span class="n">pdf_x_range</span><span class="p">,</span>
                     <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span>
                     <span class="n">label</span><span class="o">=</span><span class="s2">&quot;CDF=P(X&lt;</span><span class="si">{:.02f}</span><span class="s2">)=</span><span class="si">{:.01%}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x_for_percentile_of_cdf</span><span class="p">,</span>
                                                             <span class="n">percentile_of_cdf</span><span class="p">),</span>
                     <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_32_0.png" src="../_images/stat_univ_32_0.png" />
</section>
<section id="the-chi-square-distribution">
<h3>The Chi-Square Distribution<a class="headerlink" href="#the-chi-square-distribution" title="Link to this heading">¶</a></h3>
<p>The chi-square or <span class="math notranslate nohighlight">\(\chi_n^2\)</span> distribution with <span class="math notranslate nohighlight">\(n\)</span> degrees
of freedom (df) is the distribution of a sum of the squares of <span class="math notranslate nohighlight">\(n\)</span>
independent standard normal random variables <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>.
Let <span class="math notranslate nohighlight">\(X \sim \mathcal{N}(\mu, \sigma^2)\)</span>, then,
<span class="math notranslate nohighlight">\(Z=(X - \mu)/\sigma \sim \mathcal{N}(0, 1)\)</span>, then:</p>
<ul class="simple">
<li><p>The squared standard <span class="math notranslate nohighlight">\(Z^2 \sim \chi_1^2\)</span> (one df).</p></li>
<li><p><strong>The distribution of sum of squares</strong> of <span class="math notranslate nohighlight">\(n\)</span> normal random
variables: <span class="math notranslate nohighlight">\(\sum_i^n Z_i^2 \sim \chi_n^2\)</span></p></li>
</ul>
<p>The sum of two <span class="math notranslate nohighlight">\(\chi^2\)</span> RV with <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span> df is a
<span class="math notranslate nohighlight">\(\chi^2\)</span> RV with <span class="math notranslate nohighlight">\(p+q\)</span> df. This is useful when
summing/subtracting sum of squares.</p>
<p>The <span class="math notranslate nohighlight">\(\chi^2\)</span>-distribution is used to model <strong>errors</strong> measured as
<strong>sum of squares</strong> or the distribution of the sample <strong>variance</strong>.</p>
<p>The chi-squared distribution is a special case of the gamma
distribution, with gamma parameters a = df/2, loc = 0 and scale = 2.</p>
<p>Documentation: -
<a class="reference external" href="https://numpy.org/doc/stable/reference/random/generated/numpy.random.chisquare.html">numpy.random.chisquare</a>
-
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html#scipy.stats.chi2">scipy.stats.chi2</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span>
<span class="n">x_rv</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">prob_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
<span class="n">cdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span> <span class="p">,</span><span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="the-fishers-f-distribution">
<h3>The Fisher’s F-Distribution<a class="headerlink" href="#the-fishers-f-distribution" title="Link to this heading">¶</a></h3>
<p>The <span class="math notranslate nohighlight">\(F\)</span>-distribution, <span class="math notranslate nohighlight">\(F_{n, p}\)</span>, with <span class="math notranslate nohighlight">\(n\)</span> and
<span class="math notranslate nohighlight">\(p\)</span> degrees of freedom is the ratio of two independent
<span class="math notranslate nohighlight">\(\chi^2\)</span> variables. Let <span class="math notranslate nohighlight">\(X \sim \chi_n^2\)</span> and
<span class="math notranslate nohighlight">\(Y \sim \chi_p^2\)</span> then:</p>
<div class="math notranslate nohighlight">
\[F_{n, p} = \frac{X/n}{Y/p}\]</div>
<p>The <span class="math notranslate nohighlight">\(F\)</span>-distribution plays a central role in hypothesis testing
answering the question: <strong>Are two variances equals?, is the ratio or two
errors significantly large ?</strong>.</p>
<p>Documentation: -
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f.html#scipy.stats.f">scipy.stats.f</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dfn</span><span class="p">,</span> <span class="n">dfd</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span>
<span class="n">x_rv</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">dfn</span><span class="o">=</span><span class="n">dfn</span><span class="p">,</span> <span class="n">dfd</span><span class="o">=</span><span class="n">dfd</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">prob_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">dfn</span><span class="o">=</span><span class="n">dfn</span><span class="p">,</span> <span class="n">dfd</span><span class="o">=</span><span class="n">dfd</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
<span class="n">cdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">dfn</span><span class="o">=</span><span class="n">dfn</span><span class="p">,</span> <span class="n">dfd</span><span class="o">=</span><span class="n">dfd</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="n">fvalues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">.1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="c1"># pdf(x, df1, df2): Probability density function at x of F.</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fvalues</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">fvalues</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;F(1, 30)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fvalues</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">f</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">fvalues</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;F(5, 30)&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_36_0.png" src="../_images/stat_univ_36_0.png" />
</section>
<section id="the-students-t-distribution">
<h3>The Student’s <span class="math notranslate nohighlight">\(t\)</span>-Distribution<a class="headerlink" href="#the-students-t-distribution" title="Link to this heading">¶</a></h3>
<p>Let <span class="math notranslate nohighlight">\(M \sim \mathcal{N}(0, 1)\)</span> and <span class="math notranslate nohighlight">\(V \sim \chi_n^2\)</span>. The
<span class="math notranslate nohighlight">\(t\)</span>-distribution, <span class="math notranslate nohighlight">\(T_n\)</span>, with <span class="math notranslate nohighlight">\(n\)</span> degrees of freedom
is the ratio:</p>
<div class="math notranslate nohighlight">
\[T_n = \frac{M}{\sqrt{V/n}}\]</div>
<p>The distribution of the difference between an estimated parameter and
its true (or assumed) value divided by the standard deviation of the
estimated parameter (standard error) follow a <span class="math notranslate nohighlight">\(t\)</span>-distribution.</p>
<p>Documentation:
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#scipy.stats.t">scipy.stats.t</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">,</span> <span class="n">mean</span><span class="p">,</span> <span class="n">sd</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10000</span>
<span class="n">x_rv</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mean</span><span class="o">-</span><span class="mi">5</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="n">mean</span><span class="o">+</span><span class="mi">5</span><span class="o">*</span><span class="n">sd</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">prob_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>
<span class="n">cdf_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;T(30, 0, 1)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;T(2, 0, 1)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mean</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sd</span><span class="p">),</span> <span class="s1">&#39;g--&#39;</span><span class="p">,</span>
         <span class="n">label</span><span class="o">=</span><span class="s2">&quot;N(0, 1)&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_38_0.png" src="../_images/stat_univ_38_0.png" />
</section>
</section>
<section id="central-limit-theorem-clt">
<h2>Central Limit Theorem (CLT)<a class="headerlink" href="#central-limit-theorem-clt" title="Link to this heading">¶</a></h2>
<p>See <a class="reference external" href="https://www.youtube.com/watch?v=zeJD6dqJ5lo">3Blue1Brown: But what is the Central Limit
Theorem?</a>.</p>
<p>Let <span class="math notranslate nohighlight">\(\{X_1, ..., X_i,..., X_n\}\)</span> be a sequence of independent and
identically distributed (i.i.d.) (<span class="math notranslate nohighlight">\(\sim X\)</span>) random variables (RV)
with parameters:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E[X_i] = \mu_X\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(Var[X_i] = \sigma_X^2 &lt; \ \infty\)</span> (finite variance).</p></li>
</ul>
<section id="distribution-of-the-sum-of-samples">
<h3>Distribution of the Sum of Samples<a class="headerlink" href="#distribution-of-the-sum-of-samples" title="Link to this heading">¶</a></h3>
<p>Let <span class="math notranslate nohighlight">\(S_n = \sum^n_i X_i\)</span> the sum of those RV. Then, the sum of RV
converge in distribution to a normal distribution:</p>
<div class="math notranslate nohighlight">
\[S_n = \sum^n_i X_i \rightarrow \mathcal{N}(n \mu_X, \sqrt{n}\sigma_X)\]</div>
<p>Note that the centered and scaled sum converge in distribution to a
normal distribution of parameters <span class="math notranslate nohighlight">\(0, 1\)</span>:
<span class="math notranslate nohighlight">\(\frac{\sum^n_i X_i -n\mu}{\sqrt{n}\sigma_X}\rightarrow\mathcal{N}(0, 1)\)</span></p>
</section>
<section id="the-distribution-of-the-sample-mean">
<h3>The Distribution of the Sample Mean<a class="headerlink" href="#the-distribution-of-the-sample-mean" title="Link to this heading">¶</a></h3>
<p>Central Limit Theorem also apply for the sample mean: Let i.i.d. samples
<span class="math notranslate nohighlight">\(X_i\)</span> from from <em>almost any</em> distribution of parameters
<span class="math notranslate nohighlight">\(\mu_X, \sigma_X\)</span>. Then the sample mean <span class="math notranslate nohighlight">\(\bar{X}\)</span>, for
samples of size 30 or more, is approximately normally distributed:</p>
<div class="math notranslate nohighlight">
\[\bar{X} = \frac{\sum^n_i X_i}{n} \rightarrow \mathcal{N}(\mu_X, \frac{\sigma_X}{\sqrt{n}})\]</div>
<p>Simple but useful demonstrations:</p>
<div class="math notranslate nohighlight">
\[\begin{split}E[\bar{X}_n] =  E[\frac{1}{n}\sum^n_i X_i] =\frac{1}{n} \sum^n_i E[X_i],\\
\text{since}~X_i~\text{are i.i.d., i.e., }~E[X_i] = \mu_X \forall i~\text{then} \\
=\frac{1}{n}  n \mu_X = \mu_X\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}Var[\bar{X}_n] = Var[\frac{1}{n}\sum^n_i X_i] = (\frac{1}{n})^2  \sum^2_X Var[X_i],\\
\text{since}~X_i~\text{are i.i.d., i.e., }~Var[X_i] = \sigma^2_X \forall i~\text{then}\\
= (\frac{1}{n})^2  n \sigma^2_X = \sigma_X^2/n\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[Sd[\bar{X}_n] = \sigma_X/\sqrt{n}\]</div>
<p>Note that the <strong>standard deviation of the sample mean is the standard
deviation of the parent RV scaled by</strong> <span class="math notranslate nohighlight">\(\sqrt{n}\)</span>. The larger the
sample size, the better the approximation.</p>
<p>The Central Limit Theorem is illustrated for several common population
distributions in <a class="reference external" href="https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Introductory_Statistics_(Shafer_and_Zhang)/06%3A_Sampling_Distributions/6.02%3A_The_Sampling_Distribution_of_the_Sample_Mean">The Sampling Distribution of the Sample
Mean</a>.</p>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Link to this heading">¶</a></h3>
<p><strong>Distribution of the sum of samples from the uniform distribution</strong></p>
<p>See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html">Scipy Uniform
Distribution</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_repeat</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Distribution parameters, true mean and standard deviation</span>
<span class="n">a</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span>
<span class="n">mu_unif</span><span class="p">,</span> <span class="n">sd_unif</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">12</span> <span class="o">*</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1"># Xn&#39;s</span>
<span class="n">xn_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeat</span><span class="p">)])</span>

<span class="c1"># Xn&#39;s centered and scaled</span>
<span class="n">xn_s_cs</span> <span class="o">=</span> <span class="p">(</span><span class="n">xn_s</span> <span class="o">-</span> <span class="n">n_sample</span> <span class="o">*</span> <span class="n">mu_unif</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_sample</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd_unif</span><span class="p">)</span>

<span class="n">h_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">xn_s_cs</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Sum(Unif.)&quot;</span><span class="p">)</span>

<span class="c1"># Normal distribution</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">prob_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">prob_x_range</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;N(0, 1)&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_43_0.png" src="../_images/stat_univ_43_0.png" />
<p><strong>Distribution of the sum of samples from the the exponential
distribution</strong></p>
<p>See <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.expon.html">Scipy Exponential
Distribution</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_repeat</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Distribution parameters, true mean and standard deviation</span>
<span class="n">lambda_</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">mu_exp</span><span class="p">,</span> <span class="n">sd_exp</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">lambda_</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>

<span class="c1"># Xn&#39;s</span>
<span class="n">xn_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_sample</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeat</span><span class="p">)])</span>

<span class="c1"># Xn&#39;s centered and scaled</span>
<span class="n">xn_s_cs</span> <span class="o">=</span> <span class="p">(</span><span class="n">xn_s</span> <span class="o">-</span> <span class="n">n_sample</span> <span class="o">*</span> <span class="n">mu_exp</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_sample</span><span class="p">)</span> <span class="o">*</span> <span class="n">sd_exp</span><span class="p">)</span>

<span class="n">h_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">xn_s_cs</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">43</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Sum(Exp.)&quot;</span><span class="p">)</span>

<span class="c1"># Normal distribution</span>
<span class="n">x_range</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">prob_x_range</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_range</span><span class="p">,</span> <span class="n">prob_x_range</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;N(0, 1)&quot;</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_45_0.png" src="../_images/stat_univ_45_0.png" />
<p><strong>Distribution of the mean from the Binomial distribution</strong></p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial
distribution</a>
with
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html">scipy</a>:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_sample</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">n_repeat</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># Binomial distribution parameters</span>
<span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">n_sample</span><span class="p">,</span> <span class="mf">0.5</span>

<span class="c1"># Distribution parameters, true mean and standard deviation</span>
<span class="n">mu</span><span class="p">,</span> <span class="n">sd</span> <span class="o">=</span> <span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">p</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">))</span>

<span class="c1"># Xbar&#39;s</span>
<span class="n">xbar_s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_sample</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_repeat</span><span class="p">)])</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;True stat.: mu=</span><span class="si">{:.01f}</span><span class="s2">, sd=</span><span class="si">{:.03f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sd</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n_sample</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Est. stat.: mu=</span><span class="si">{:.01f}</span><span class="s2">, sd=</span><span class="si">{:.03f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">xbar_s</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">xbar_s</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kc">True</span> <span class="n">stat</span><span class="o">.</span><span class="p">:</span> <span class="n">mu</span><span class="o">=</span><span class="mf">500.0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mf">0.500</span>
<span class="n">Est</span><span class="o">.</span> <span class="n">stat</span><span class="o">.</span><span class="p">:</span> <span class="n">mu</span><span class="o">=</span><span class="mf">500.0</span><span class="p">,</span> <span class="n">sd</span><span class="o">=</span><span class="mf">0.504</span>
</pre></div>
</div>
</section>
</section>
<section id="statistical-inference-and-decision-making-using-hypothesis-testing">
<h2>Statistical inference and Decision Making using Hypothesis Testing<a class="headerlink" href="#statistical-inference-and-decision-making-using-hypothesis-testing" title="Link to this heading">¶</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Statistical_inference">Inferential
statistics</a>
involves the use of a sample (1) to estimate some characteristic in a
large population; and (2) to test a research hypothesis about a given
population.</p>
<section id="typology-of-tests">
<h3>Typology of tests<a class="headerlink" href="#typology-of-tests" title="Link to this heading">¶</a></h3>
<p>Tests should be adapted to the type of variable:</p>
<ol class="arabic simple">
<li><p>For <strong>categorical variables</strong> tests use <strong>count</strong> of categories,
<strong>proportions, or frequencies</strong>. Examples:</p></li>
</ol>
<ul class="simple">
<li><p>Test a proportion: 200 heads have been found over 300 flips, is this
coin biased toward head or could it be observed by chance?</p></li>
<li><p>1,000 voters are questioned about their vote. 55% said they had voted
for candidate A and 45% for candidate B. Is this a significant
difference?</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>For <strong>numerical variables tests use means, standard-deviations or
medians</strong>. Examples:</p></li>
</ol>
<ul class="simple">
<li><p>Test the effect of some condition (treatment or some action):</p>
<ul>
<li><p>We observed an increase of monthly revenue of 100 stores after
marketing campaign. Could this increase be attributed to chance or
to the marketing campaign?</p></li>
<li><p>Arterial hypertension of 50 patients has been reduced by some
medication. Is it pure randomness?</p></li>
</ul>
</li>
<li><p>Test the association between two variables:</p>
<ul>
<li><p>Height and sex: In a sample of 25 individuals (15 females, 10
males), is female height is different from male height?</p></li>
<li><p>Age and arterial hypertension: In a sample of 25 individuals is age
height correlated with arterial hypertension ?</p></li>
</ul>
</li>
</ul>
<p>Tests can be grouped in two categories:</p>
<ol class="arabic simple">
<li><p><strong>Parametric tests</strong> assume that the data follow some distribution,
and can be summarized by a parameters: mean and standard-deviation
for quantitative variables; count proportion or frequencies for
categorical variables.</p></li>
<li><p><strong>Non-Parametric tests</strong>. Non-parametric tests are not based on a
model of the data and therefore do not make the assumption that they
follow a certain distribution. Non-Parametric tests are generally
based on ranking of values or medians.</p></li>
</ol>
</section>
<section id="general-testing-procedure">
<h3>General Testing Procedure<a class="headerlink" href="#general-testing-procedure" title="Link to this heading">¶</a></h3>
<section id="model-the-data-for-parametric-tests">
<h4>1. <strong>Model the data</strong> (for parametric tests).<a class="headerlink" href="#model-the-data-for-parametric-tests" title="Link to this heading">¶</a></h4>
<p>E.g., the height of males and females can be represented by their means,
i.e., assuming two normal distributions. Then fit the model to the data,
i.e., estimate the model parameters (frequency, mean, correlation,
regression coefficient). E.g., compute the means of females and males
height.</p>
</section>
<section id="calculate-a-decision-statistic-for-all-tests">
<h4>2. Calculate a <strong>decision statistic</strong> (for all tests)<a class="headerlink" href="#calculate-a-decision-statistic-for-all-tests" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>Formulate the null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>, i.e., what would be
situation under pure chance? E.g., if sex has no effect on
individuals’ height males and females means height will be equals.</p></li>
<li><p>Derive a test statistic on the data capturing deviation from null
hypothesis taking account the number of samples. For parametric
statistics, the test statistic is derived from model parameters, e.g.,
the differences of means of males and females height, taking account
the number of samples.</p></li>
</ul>
</section>
<section id="inference">
<h4>3. Inference<a class="headerlink" href="#inference" title="Link to this heading">¶</a></h4>
<p>Assess the deviation of the test statistic from its expected value under
<span class="math notranslate nohighlight">\(H_0\)</span> (pure chance). Two possibilities:</p>
<p><strong>P-value</strong> based on null hypothesis:</p>
<p>What is the probability that the computed test statistic <span class="math notranslate nohighlight">\(\bar{X}\)</span>
would be observed under pure chance? I.e., What is the probability that
the test statistics under <span class="math notranslate nohighlight">\(H_0\)</span> would be more extreme, i.e.,
“larger” or “smaller” than <span class="math notranslate nohighlight">\(\bar{X}\)</span>?</p>
<ul class="simple">
<li><p>Calculate the distribution of test statistic <span class="math notranslate nohighlight">\(X\)</span> under
<span class="math notranslate nohighlight">\(H_0\)</span>.</p></li>
<li><p>Compute the probability (P-value) to obtain a larger test statistic by
chance (under the null hypothesis).</p></li>
</ul>
<p>For a symmetric distribution the two sided p-value <span class="math notranslate nohighlight">\(P\)</span> is defined
as:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(\bar{X} \leq X | H_0) = P/2\)</span>, or</p></li>
<li><p><span class="math notranslate nohighlight">\(P(X \geq \bar{X}) = P/2\)</span></p></li>
</ul>
<p><span class="math notranslate nohighlight">\(\bar{X}\)</span> is declared to be <strong>significantly different to the null
hypothesis</strong> if the p-value is less than a <strong>significance level</strong>
<span class="math notranslate nohighlight">\(\alpha\)</span> generally considered as <span class="math notranslate nohighlight">\(5\%\)</span>.</p>
<p><strong>Confidence interval (CI)</strong></p>
<p>CI is a range of values <span class="math notranslate nohighlight">\(x_1, x_2\)</span> that is likely (given a
<strong>confidence level</strong>, e.g., <span class="math notranslate nohighlight">\(95\%\)</span>) to contain the true value of
the statistic <span class="math notranslate nohighlight">\(\bar{X}\)</span>. Outside this range the value is
considered to be unlikely. Note that the confidence level is
<span class="math notranslate nohighlight">\(1 - \alpha\)</span>, the significance level. See <a class="reference external" href="https://www.youtube.com/watch?v=ftYdEm6pEkE">Interpreting Confidence
Intervals</a></p>
<p>The 95% CI (Confidence Interval) is the range of values <span class="math notranslate nohighlight">\(x_1, x_2\)</span>
such <span class="math notranslate nohighlight">\(P(x_1 &lt; \bar{X} &lt; x_2) = 95\%\)</span>.</p>
<p>For a symmetric distribution the two sided <span class="math notranslate nohighlight">\(95\% (= 1 - 5\%)\)</span>
confidence interval, is defined as:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_1\)</span> such <span class="math notranslate nohighlight">\(P(\bar{X} \leq x_1) = 2.5\% =5\%/2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(x_2\)</span> such <span class="math notranslate nohighlight">\(P(x_2 \leq \bar{X}) = 2.5\%\)</span></p></li>
</ul>
<p>Terminology</p>
<ul class="simple">
<li><p>Margin of error = <span class="math notranslate nohighlight">\(\bar{X} - x_1\)</span> (for symmetric distribution).</p></li>
<li><p>Confidence Interval = <span class="math notranslate nohighlight">\([x_1, x_2]\)</span>.</p></li>
<li><p>Confidence level is 1 - significance level</p></li>
</ul>
</section>
</section>
<section id="categorical-variable-the-binomial-test">
<h3>Categorical variable: the Binomial Test<a class="headerlink" href="#categorical-variable-the-binomial-test" title="Link to this heading">¶</a></h3>
<p><strong>Simplified example (small sample)</strong> of the <a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_test">the binomial
test</a>: Three voters are
questioned about their vote. Two voted for candidate A and one for B.
How likely this difference Is this a significant difference,</p>
<p><strong>1. Model the data:</strong> Let <span class="math notranslate nohighlight">\(x\)</span> the number of vote for A. It
follows a <a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial
distribution</a>.
Compute the model parameters: <span class="math notranslate nohighlight">\(N=3\)</span>, and <span class="math notranslate nohighlight">\(\hat{p}=2/3\)</span> (the
frequency of number of vote A over the number of voters).</p>
<p><strong>2. Compute a test statistic</strong> measuring the deviation of the number of
vote for A (<span class="math notranslate nohighlight">\(x=2\)</span>) over three voters from the expected values
under the null hypothesis where <span class="math notranslate nohighlight">\(x\)</span> would be <span class="math notranslate nohighlight">\(1.5\)</span>.
Similarly, we could consider the deviation of the observed proportion
<span class="math notranslate nohighlight">\(\hat{p}=2/3\)</span> from <span class="math notranslate nohighlight">\(\pi_0=50\%\)</span>.</p>
<p><strong>3. To make inference</strong>, we have to compute the probability to obtain
more than two votes for A by chance. We need the distribution of
<span class="math notranslate nohighlight">\(x\)</span> under <span class="math notranslate nohighlight">\(H_0\)</span> (<span class="math notranslate nohighlight">\(P(x|H0)\)</span>) to sum all the
probabilities where <span class="math notranslate nohighlight">\(x\)</span> is larger or equal to 2, i.e.,
<span class="math notranslate nohighlight">\(P(x\geq 2| H_0)\)</span>. With such small sample size (<span class="math notranslate nohighlight">\(n=3\)</span>) this
distribution is obtained by enumerating all configurations that produce
a given number of heads <span class="math notranslate nohighlight">\(x\)</span>:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>1</p></th>
<th class="head"><p>2</p></th>
<th class="head"><p>3</p></th>
<th class="head"><p>count vote for A</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p></p></td>
<td></td>
<td></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>H</p></td>
<td></td>
<td></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>H</p></td>
<td></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td></td>
<td><p>H</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>H</p></td>
<td><p>H</p></td>
<td></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>H</p></td>
<td></td>
<td><p>H</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-even"><td><p></p></td>
<td><p>H</p></td>
<td><p>H</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>H</p></td>
<td><p>H</p></td>
<td><p>H</p></td>
<td><p>3</p></td>
</tr>
</tbody>
</table>
<p>Eight possibles configurations, probabilities of different values for
<span class="math notranslate nohighlight">\(x\)</span> are:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P(x=0) = 1/8\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=1) = 3/8\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=2) = 3/8\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(P(x=3) = 1/8\)</span></p></li>
</ul>
<p>Plot of the distribution of the number of <span class="math notranslate nohighlight">\(x\)</span> (A vote over 3
voters) under the null hypothesis:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="mi">1</span><span class="o">/</span><span class="mi">8</span><span class="p">],</span> <span class="n">width</span><span class="o">=</span><span class="mf">.95</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Dist. of the nb of head over 3 flip under the null hyp.&quot;</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_51_0.png" src="../_images/stat_univ_51_0.png" />
<p>Finally, we compute the probability (P-value) to observe a value larger
or equal that <span class="math notranslate nohighlight">\(x=2\)</span> (or <span class="math notranslate nohighlight">\(P=2/3\)</span>) under the null hypothesis?
This probability is the <span class="math notranslate nohighlight">\(p\)</span>-value:</p>
<div class="math notranslate nohighlight">
\[P(x\geq 2| H_0) = P(x=2| H_0) + P(x=3| H_0) = 3/8 + 1/8 = 1/2\]</div>
<p><strong>P-value = 0.5</strong>, meaning that there is 50% of chance to get
<span class="math notranslate nohighlight">\(x=2\)</span> or larger by chance.</p>
<p><strong>large sample example:</strong> 100 voters are questioned about their vote. 60
declared they voted for candidate A and 40 for candidate B. Is this a
significant difference?</p>
<p><strong>1. Model the data:</strong> Let <span class="math notranslate nohighlight">\(x\)</span> the number of vote for A. <span class="math notranslate nohighlight">\(x\)</span>
follows a binomial distribution. Compute model parameters:
<span class="math notranslate nohighlight">\(n=100, \hat{p}=60/100\)</span>. Where <span class="math notranslate nohighlight">\(\hat{p}\)</span> is the observed
proportion of A.</p>
<p><strong>2. Compute a test statistic</strong> that measure the deviation of
<span class="math notranslate nohighlight">\(x=60\)</span> (vote for A) from the expected value: <span class="math notranslate nohighlight">\(n\pi_0=50\)</span>
under the null hypothesis, i.e., where <span class="math notranslate nohighlight">\(\pi_0=50\%\)</span>. The
distribution of the number of vote for A (<span class="math notranslate nohighlight">\(x\)</span>) follow the
<a class="reference external" href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial
distribution</a> of
parameters <span class="math notranslate nohighlight">\(N=100, P=0.5\)</span> approximated with normal distribution
when <span class="math notranslate nohighlight">\(n\)</span> is large enough.</p>
<p>For large sample, the most usual (and easiest) approximation is through
the standard normal distribution, in which a z-test is performed of the
test statistic <span class="math notranslate nohighlight">\(Z\)</span>, given by:</p>
<div class="math notranslate nohighlight">
\[Z = \frac{x - n\pi_0}{\sqrt{n p_0 (1 - \pi_0)}}\]</div>
<p>one may rearrange and write the z-test above as deviation of
<span class="math notranslate nohighlight">\(\hat{p}\)</span> from <span class="math notranslate nohighlight">\(\pi_0=50\%\)</span></p>
<div class="math notranslate nohighlight">
\[Z = \frac{\hat{p} - \pi_0}{\sqrt{\pi_0 (1 - \pi_0)}}\sqrt{n}\]</div>
<p>Note that the statistic is the product of two parts:</p>
<ul class="simple">
<li><p>The <strong>effect size</strong>:
<span class="math notranslate nohighlight">\(\frac{\hat{p} - \pi_0}{\sqrt{\pi_0 (1 - \pi_0)}}\)</span> that measure
a standardized deviation.</p></li>
<li><p>The squared root of the sample size <span class="math notranslate nohighlight">\(\sqrt{n}\)</span>.</p></li>
</ul>
<p>Large statistic is obtained with large deviation with large sample size.</p>
<p><strong>5. Inference</strong></p>
<p>Compute the p-value using <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html">Scipy to compute the
CDF</a>
of the binomial distribution:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">pi0</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mf">0.5</span>
<span class="n">pval_greater</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">pi0</span><span class="p">)</span>
<span class="n">pval_greater</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">pi0</span><span class="p">)</span>

<span class="c1"># Two sidded pval = 2 * pval_greater</span>
<span class="n">pval</span> <span class="o">=</span> <span class="n">pval_greater</span> <span class="o">*</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;P-value (Two sided): P(X&lt;=</span><span class="si">{:0d}</span><span class="s2"> or X&gt;=</span><span class="si">{:0d}</span><span class="s2">|H0)=</span><span class="si">{:.4f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n</span><span class="o">-</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">P</span><span class="o">-</span><span class="n">value</span> <span class="p">(</span><span class="n">Two</span> <span class="n">sided</span><span class="p">):</span> <span class="n">P</span><span class="p">(</span><span class="n">X</span><span class="o">&lt;=</span><span class="mi">40</span> <span class="ow">or</span> <span class="n">X</span><span class="o">&gt;=</span><span class="mi">60</span><span class="o">|</span><span class="n">H0</span><span class="p">)</span><span class="o">=</span><span class="mf">0.0352</span>
</pre></div>
</div>
<p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html">Scipy normal
distribution</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.6</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">))</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="c1">#z = (60 - n * 0.5 + 1/2) / (n * 0.5 * (1 - 0.5)) * np.sqrt(n)</span>

<span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="mi">2</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">6.334248366623996e-05</span><span class="p">)</span>
</pre></div>
</div>
<p>Plot of the binomial distribution and the probability to observe more
than 60 vote for A by chance:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stat_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">41</span><span class="p">)</span>
<span class="n">stat_probs</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binom</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">stat_vals</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">pi0</span><span class="p">)</span> <span class="c1"># H0: 0.5</span>
<span class="n">stat_obs</span> <span class="o">=</span> <span class="n">k</span>

<span class="n">pystatsml</span><span class="o">.</span><span class="n">plot_utils</span><span class="o">.</span><span class="n">plot_pvalue_under_h0</span><span class="p">(</span><span class="n">stat_vals</span><span class="p">,</span> <span class="n">stat_probs</span><span class="p">,</span>
                                          <span class="n">stat_obs</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">stat_h0</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
                                          <span class="n">thresh_low</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span> <span class="n">thresh_high</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_58_0.png" src="../_images/stat_univ_58_0.png" />
<p>Simply use <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binomtest.html">Scipy binomial
test</a>
that the probability of success is p.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">binomtest</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pi0</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">)</span>
<span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">proportion_ci</span><span class="p">(</span><span class="n">confidence_level</span><span class="o">=</span><span class="mf">0.95</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;exact&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimate: </span><span class="si">{:.2f}</span><span class="s2">, p-val: </span><span class="si">{:e}</span><span class="s2">, CI: [</span><span class="si">{:.5f}</span><span class="s2">, </span><span class="si">{:.5f}</span><span class="s2">]&quot;</span><span class="o">.</span>\
    <span class="nb">format</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate</span><span class="p">:</span> <span class="mf">0.60</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">5.688793e-02</span><span class="p">,</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.49721</span><span class="p">,</span> <span class="mf">0.69671</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="quantitative-variable-one-sample-t-test">
<h3>Quantitative variable: One Sample T-test<a class="headerlink" href="#quantitative-variable-one-sample-t-test" title="Link to this heading">¶</a></h3>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-test#One-sample_t-test">one sample
t-test</a>
is used to determine whether a sample comes from a population with a
specific mean. For example you want to test if the average height of a
population is <span class="math notranslate nohighlight">\(1.75~m\)</span>.</p>
<p>This test is used when we have two measurements for each individual at
two different times or under two conditions: for each individual, we
calculate the difference between the two conditions and test the
positivity (increase) or negativity (decrease) of the mean of the
differences.</p>
<p>Example: is the arterial hypertension of 50 patients measured before and
after some medication has been reduced by the treatment?</p>
<p>Example: <a class="reference external" href="https://julius.ai/use-case/how-to-perform-a-paired-samples-t-test">Monthly revenue figures of for 100 stores before and after a
marketing
campaigns</a>.
We compute the difference
(<span class="math notranslate nohighlight">\(x_i = x_i^\text{after} - x_i^\text{before}\)</span>) for each store
<span class="math notranslate nohighlight">\(i\)</span>. If the average difference <span class="math notranslate nohighlight">\(\bar{x}=1/n \sum_i x_i\)</span> is
significantly positive (resp. negative), then the marketing campaigns
will be considered as efficient (resp. detrimental).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;../datasets/Monthly Revenue (in thousands).csv&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">pivot</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="s1">&#39;store_id&#39;</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="s1">&#39;time&#39;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="s1">&#39;revenue&#39;</span><span class="p">)</span>
<span class="c1"># Keep only the 30 first samples</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
<span class="n">df</span><span class="o">.</span><span class="n">after</span> <span class="o">-=</span> <span class="mi">3</span> <span class="c1"># force to smaller effect size</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">after</span> <span class="o">-</span> <span class="n">df</span><span class="o">.</span><span class="n">before</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>   <span class="n">store_id</span>    <span class="n">time</span>   <span class="n">revenue</span>
<span class="mi">0</span>         <span class="mi">1</span>  <span class="n">before</span>  <span class="mf">54.96714</span>
<span class="mi">1</span>         <span class="mi">2</span>  <span class="n">before</span>  <span class="mf">48.61736</span>
<span class="mi">2</span>         <span class="mi">3</span>  <span class="n">before</span>  <span class="mf">56.47689</span>
<span class="mi">3</span>         <span class="mi">4</span>  <span class="n">before</span>  <span class="mf">65.23030</span>
<span class="mi">4</span>         <span class="mi">5</span>  <span class="n">before</span>  <span class="mf">47.65847</span>
<span class="n">time</span>         <span class="n">after</span>    <span class="n">before</span>
<span class="n">store_id</span>
<span class="mi">1</span>         <span class="mf">49.89029</span>  <span class="mf">54.96714</span>
<span class="mi">2</span>         <span class="mf">48.51413</span>  <span class="mf">48.61736</span>
<span class="mi">3</span>         <span class="mf">56.76331</span>  <span class="mf">56.47689</span>
<span class="mi">4</span>         <span class="mf">63.21891</span>  <span class="mf">65.23030</span>
<span class="mi">5</span>         <span class="mf">48.85204</span>  <span class="mf">47.65847</span>
</pre></div>
</div>
<p><strong>1. Model the data (parametric test)</strong></p>
<p>We model the observation as the sample mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> plus some
error <span class="math notranslate nohighlight">\(\varepsilon_i\)</span>, i.e., <span class="math notranslate nohighlight">\(x_i = \bar{x} + \varepsilon_i\)</span>
The <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> are called the <strong>residuals</strong>.</p>
<p>Assumptions:</p>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(x_i\)</span>’s are not expected to follow a normal distribution.
But the <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> should be approximately normally
distributed.</p></li>
<li><p>The <span class="math notranslate nohighlight">\(\varepsilon_i\)</span> must be independent and identically
distributed <span class="math notranslate nohighlight">\(i.i.d.\)</span>.</p></li>
</ul>
<p>Indeed according to the central limit theorem, if the sampling of the
parent population <span class="math notranslate nohighlight">\(x\)</span> is independent then the sample mean
<span class="math notranslate nohighlight">\(\bar{x}\)</span> will be approximately normal.</p>
<p>Fit: estimate the model parameters, the mean
<span class="math notranslate nohighlight">\(\bar{x}=1/n \sum_i x_i=2.26\)</span> (thousands of dollars) and standard
deviation <span class="math notranslate nohighlight">\(s\)</span>. Warning, when computing the std or the variance,
set <code class="docutils literal notranslate"><span class="pre">ddof=1</span></code>. The default value, <code class="docutils literal notranslate"><span class="pre">ddof=0</span></code>, leads to the biased
estimator of the variance.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">xbar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>      <span class="c1"># sample mean</span>
<span class="n">mu0</span> <span class="o">=</span> <span class="mi">0</span>                <span class="c1"># mean under H0</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># sample standard deviation</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>             <span class="c1"># sample size</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">n</span> <span class="o">-</span> <span class="mi">1</span>
</pre></div>
</div>
<p><strong>2. Compute a test statistic</strong></p>
<ul>
<li><p>Formulate hypothesis:</p>
<ul class="simple">
<li><p>Null hypothesis: <span class="math notranslate nohighlight">\(H_0: \bar{x}=0\)</span>, i.e., the marketing
campaign had no effect on sales.</p></li>
<li><p>Alternative hypothesis: <span class="math notranslate nohighlight">\(H_0: \bar{x}\neq 0\)</span>, i.e., the
marketing campaign had positive (<span class="math notranslate nohighlight">\(\bar{x}&gt;0\)</span>) or negative
effect (<span class="math notranslate nohighlight">\(\bar{x}&lt;0\)</span>) on sales.</p></li>
</ul>
<p>Note that is is a <strong>two-sided test</strong> of effects on both ways.</p>
</li>
<li><p>Compute a test statistic that measure the deviation of
<span class="math notranslate nohighlight">\(\bar{x}=2.26\)</span> from the expected value under the null hypothesis
(no effect of the campaign) which is: <span class="math notranslate nohighlight">\(\mu_0=0\)</span>. The test
statistic <span class="math notranslate nohighlight">\(T\)</span>, is given by:</p>
<div class="math notranslate nohighlight">
\[T = \frac{\bar{x} - \mu_0}{s}\sqrt{n}\]</div>
</li>
</ul>
<p>Note that the statistic is the product of two parts:</p>
<ul class="simple">
<li><p>The <strong>effect size</strong>: <span class="math notranslate nohighlight">\(\frac{\bar{x} - \mu_0}{s}\)</span> that measure a
standardized deviation. It a “signal to noise ratio” of what is
explained by the model divided by the error.</p></li>
<li><p>The squared root of the sample size.</p></li>
</ul>
<p>Under the null hypothesis the distribution of T follow the <a class="reference external" href="https://en.wikipedia.org/wiki/Student%27s_t-distribution">Student
t-distribution</a>
of parameters df=<span class="math notranslate nohighlight">\(n-1\)</span>. Note that according the central limit
theorem, if the observations are independent, then <span class="math notranslate nohighlight">\(T\)</span> will be
approximately normal <span class="math notranslate nohighlight">\(\mathcal{N}(0,1)\)</span>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tval</span> <span class="o">=</span> <span class="p">(</span><span class="n">xbar</span> <span class="o">-</span> <span class="n">mu0</span><span class="p">)</span> <span class="o">/</span> <span class="n">s</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>3. Inference</strong></p>
<p><strong>P-value (null hypothesis)</strong> is computed using <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html">Scipy to compute the
CDF</a>
of the student distribution.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pval_greater</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">tval</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
<span class="n">pval_greater</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">tval</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span>
<span class="c1"># T distribution is symmetric</span>
<span class="c1"># =&gt; pval_lower = pval_greater</span>
<span class="c1"># =&gt; two-sided = pval_greater * 2</span>
<span class="n">pval</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">pval_greater</span>
</pre></div>
</div>
<p>Plot observed T value under null hypothesis</p>
<ul class="simple">
<li><p>the distribution of t-statistic under the null hypothesis
<span class="math notranslate nohighlight">\(P_{T}(X|H_0)\)</span>,</p></li>
<li><p>the two sided p-value, CDF of
<span class="math notranslate nohighlight">\(P_{T}(X\leq-T) + P_{T}(X\geq T|H_0)\)</span>, and</p></li>
<li><p>the observed <span class="math notranslate nohighlight">\(T\)</span> value</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">stat_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">stat_probs</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">stat_vals</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># H0 =&gt; loc=0</span>

<span class="n">pystatsml</span><span class="o">.</span><span class="n">plot_utils</span><span class="o">.</span><span class="n">plot_pvalue_under_h0</span><span class="p">(</span><span class="n">stat_vals</span><span class="p">,</span> <span class="n">stat_probs</span><span class="p">,</span>
                                          <span class="n">stat_obs</span><span class="o">=</span><span class="n">tval</span><span class="p">,</span> <span class="n">stat_h0</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                          <span class="n">thresh_low</span><span class="o">=-</span><span class="n">tval</span><span class="p">,</span> <span class="n">thresh_high</span><span class="o">=</span><span class="n">tval</span><span class="p">)</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_70_0.png" src="../_images/stat_univ_70_0.png" />
<p><strong>Confidence interval (alternative hypothesis)</strong> of the observed
estimate <span class="math notranslate nohighlight">\(\bar{x}\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\bar{x} \pm t_{\alpha/2}\frac{s}{\sqrt{n}}\]</div>
<p>Where <span class="math notranslate nohighlight">\(t_{\alpha/2}\)</span> is the statistic critical value, obtained by
the the CMF of the t-distribution with <span class="math notranslate nohighlight">\(n-1\)</span> degrees of freedom.</p>
<p>Use the Percent Point Function
<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.t.html#scipy.stats.t">PPF</a>
or quantile function of the to compute the critical value .</p>
<p>See <a class="reference external" href="https://www.youtube.com/watch?v=6r5IZCjvIHI">Confidence Interval for a population mean, t
distribution</a>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Critical value for t at alpha / 2:</span>
<span class="n">t_alpha2</span> <span class="o">=</span> <span class="o">-</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="mf">0.05</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">ci_low</span> <span class="o">=</span> <span class="n">xbar</span> <span class="o">-</span> <span class="n">t_alpha2</span> <span class="o">*</span> <span class="n">s</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
<span class="n">ci_high</span> <span class="o">=</span> <span class="n">xbar</span> <span class="o">+</span> <span class="n">t_alpha2</span> <span class="o">*</span> <span class="n">s</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimate: </span><span class="si">{:.2f}</span><span class="s2">, t-val: </span><span class="si">{:.2f}</span><span class="s2">, p-val: </span><span class="si">{:e}</span><span class="s2">, df: </span><span class="si">{}</span><span class="s2">, CI: [</span><span class="si">{:.5f}</span><span class="s2">, </span><span class="si">{:.5f}</span><span class="s2">]&quot;</span><span class="o">.</span>
      <span class="nb">format</span><span class="p">(</span><span class="n">xbar</span><span class="p">,</span> <span class="n">tval</span><span class="p">,</span> <span class="n">pval</span><span class="p">,</span> <span class="n">df</span><span class="p">,</span> <span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate</span><span class="p">:</span> <span class="mf">2.26</span><span class="p">,</span> <span class="n">t</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">2.36</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">2.500022e-02</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="mi">29</span><span class="p">,</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.30515</span><span class="p">,</span> <span class="mf">4.22272</span><span class="p">]</span>
</pre></div>
</div>
<p>Simply use <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html">Scipy one sample
t-test</a></p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ttest</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_1samp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">alternative</span><span class="o">=</span><span class="s1">&#39;two-sided&#39;</span><span class="p">)</span>
<span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span> <span class="o">=</span> <span class="n">ttest</span><span class="o">.</span><span class="n">confidence_interval</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimate: </span><span class="si">{:.2f}</span><span class="s2">, t-val: </span><span class="si">{:.2f}</span><span class="s2">, p-val: </span><span class="si">{:e}</span><span class="s2">, df: </span><span class="si">{}</span><span class="s2">, CI: [</span><span class="si">{:.5f}</span><span class="s2">, </span><span class="si">{:.5f}</span><span class="s2">]&quot;</span><span class="o">.</span>
      <span class="nb">format</span><span class="p">(</span><span class="n">ttest</span><span class="o">.</span><span class="n">_estimate</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">df</span><span class="p">,</span> <span class="n">ci_low</span><span class="p">,</span> <span class="n">ci_high</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate</span><span class="p">:</span> <span class="mf">2.26</span><span class="p">,</span> <span class="n">t</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">2.36</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">2.500022e-02</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="mi">29</span><span class="p">,</span> <span class="n">CI</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.30515</span><span class="p">,</span> <span class="mf">4.22272</span><span class="p">]</span>
</pre></div>
</div>
<p><a class="reference external" href="https://www.youtube.com/watch?v=TqOeMYtOc1w">Boostraping for Confidence
Intervals</a></p>
</section>
</section>
<section id="statistical-tests-of-pairwise-associations">
<h2>Statistical Tests of Pairwise Associations<a class="headerlink" href="#statistical-tests-of-pairwise-associations" title="Link to this heading">¶</a></h2>
<p>Univariate statistical analysis: explore association betweens pairs of
variables.</p>
<ul class="simple">
<li><p>In statistics, a <strong>categorical variable</strong> or <strong>factor</strong> is a variable
that can take on one of a limited, and usually fixed, number of
possible values, thus assigning each individual to a particular group
or “category”. The levels are the possibles values of the variable.
Number of levels = 2: binomial; Number of levels &gt; 2: multinomial.
There is no intrinsic ordering to the categories. For example, gender
is a categorical variable having two categories (male and female) and
there is no intrinsic ordering to the categories. For example, Sex
(Female, Male), Hair color (blonde, brown, etc.).</p></li>
<li><p>An <strong>ordinal variable</strong> is a categorical variable with a clear
ordering of the levels. For example: drinks per day (none, small,
medium and high).</p></li>
<li><p>A <strong>continuous</strong> or <strong>quantitative variable</strong> <span class="math notranslate nohighlight">\(x \in \mathbb{R}\)</span>
is one that can take any value in a range of possible values, possibly
infinite. E.g.: salary, experience in years, weight.</p></li>
</ul>
<p><a class="reference external" href="http://www.ats.ucla.edu/stat/mult_pkg/whatstat/">What statistical test should I
use?</a></p>
<figure class="align-default" id="id4">
<img alt="Statistical tests" src="../_images/stat_tests_flowchart.png" />
<figcaption>
<p><span class="caption-text">Statistical tests</span><a class="headerlink" href="#id4" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<section id="pearson-correlation-test-association-between-two-quantitative-variables">
<h3>Pearson Correlation: Test Association Between Two Quantitative Variables<a class="headerlink" href="#pearson-correlation-test-association-between-two-quantitative-variables" title="Link to this heading">¶</a></h3>
<p>Test the correlation coefficient of two quantitative variables. The test
calculates a Pearson correlation coefficient and the <span class="math notranslate nohighlight">\(p\)</span>-value for
testing non-correlation.</p>
<p>Let <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span> two quantitative variables, where <span class="math notranslate nohighlight">\(n\)</span>
samples were obeserved. The linear correlation coeficient is defined as
:</p>
<div class="math notranslate nohighlight">
\[r=\frac{\sum_{i=1}^n(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum_{i=1}^n(x_i-\bar x)^2}\sqrt{\sum_{i=1}^n(y_i-\bar y)^2}}.\]</div>
<p>Under <span class="math notranslate nohighlight">\(H_0\)</span>, the test statistic
<span class="math notranslate nohighlight">\(t=\sqrt{n-2}\frac{r}{\sqrt{1-r^2}}\)</span> follow Student distribution
with <span class="math notranslate nohighlight">\(n-2\)</span> degrees of freedom.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># Compute with scipy</span>
<span class="n">cor</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cor</span><span class="p">,</span> <span class="n">pval</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.8838265556020785</span> <span class="mf">1.8786054559764614e-17</span>
</pre></div>
</div>
</section>
<section id="two-sample-student-t-test-compare-two-means">
<h3>Two sample (Student) T-test: Compare Two Means<a class="headerlink" href="#two-sample-student-t-test-compare-two-means" title="Link to this heading">¶</a></h3>
<figure class="align-default" id="id5">
<a class="reference internal image-reference" href="../_images/model_two-sample.png"><img alt="Two-sample model" src="../_images/model_two-sample.png" style="width: 7cm;" />
</a>
<figcaption>
<p><span class="caption-text">Two-sample model</span><a class="headerlink" href="#id5" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>The two-sample <span class="math notranslate nohighlight">\(t\)</span>-test (Snedecor and Cochran, 1989) is used to
determine if two population means are equal. There are several
variations on this test. If data are paired (e.g. 2 measures, before and
after treatment for each individual) use the one-sample <span class="math notranslate nohighlight">\(t\)</span>-test
of the difference. The variances of the two samples may be assumed to be
equal (a.k.a. homoscedasticity) or unequal (a.k.a. heteroscedasticity).</p>
<ol class="arabic simple">
<li><p>Model the data</p></li>
</ol>
<p>Assumptions:</p>
<ul class="simple">
<li><p>Independence of <strong>residuals</strong> (<span class="math notranslate nohighlight">\(\varepsilon_i\)</span>). This
assumptions <strong>must</strong> be satisfied.</p></li>
<li><p>Normality of residuals. Approximately normally distributed can be
accepted.</p></li>
<li><p>Homosedasticity use T-test, Heterosedasticity use Welch t-test.</p></li>
</ul>
<p>Assume that the two random variables are normally distributed:
<span class="math notranslate nohighlight">\(y_1 \sim \mathcal{N}(\mu_{1}, \sigma_{1}), y_2 \sim \mathcal{N}(\mu_{2}, \sigma_2)\)</span>.</p>
<p>Fit: estimate the model parameters, means and variances:
<span class="math notranslate nohighlight">\(\bar{y_1}, s^2_{y_1}, \bar{y_2}, s^2_{y_2}\)</span>.</p>
<ol class="arabic simple" start="2">
<li><p>t-test</p></li>
</ol>
<p>The general principle is</p>
<div class="math notranslate nohighlight">
\[\begin{split}t &amp;= \frac{\text{difference of means}}{\text{standard dev of error}} = \frac{\bar{y_1}-\bar{y_2}}{s_{\bar{y_1}-\bar{y_2}}}\\
  &amp;= \frac{\bar{y_1}-\bar{y_2}}{\sqrt{\sum\varepsilon^2}}\sqrt{n-2}\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(y_1\)</span> and <span class="math notranslate nohighlight">\(y_2\)</span> are independent:</p>
<div class="math notranslate nohighlight">
\[\begin{split}s^2_{\bar{y_1}-\bar{y_2}} &amp;= s^2_{\bar{y_1}} + s^2_{\bar{y_2}} = \frac{s^2_{y_1}}{n_1} + \frac{s^2_{y_2}}{n_2},~\text{thus}\\
s_{\bar{y_1}-\bar{y_2}} &amp;= \sqrt{\frac{s^2_{y_1}}{n_1} + \frac{s^2_{y_2}}{n_2}}\end{split}\]</div>
<section id="equal-or-unequal-sample-sizes-unequal-variances-welchs-t-test">
<h4>Equal or unequal sample sizes, unequal variances (Welch’s <span class="math notranslate nohighlight">\(t\)</span>-test)<a class="headerlink" href="#equal-or-unequal-sample-sizes-unequal-variances-welchs-t-test" title="Link to this heading">¶</a></h4>
<p>Welch’s <span class="math notranslate nohighlight">\(t\)</span>-test defines the <span class="math notranslate nohighlight">\(t\)</span> statistic as</p>
<div class="math notranslate nohighlight">
\[t = \frac{\bar{y_1} - \bar{y_2}}{\sqrt{\frac{s^2_{y_1}}{n_1} + \frac{s^2_{y_2}}{n_2}}}.\]</div>
<p>To compute the <span class="math notranslate nohighlight">\(p\)</span>-value one needs the degrees of freedom
associated with this variance estimate. It is approximated using the
Welch–Satterthwaite equation:</p>
<div class="math notranslate nohighlight">
\[\nu \approx \frac{\left(\frac{s^2_{y_1}}{n_1} + \frac{s^2_{y_2}}{n_2}\right)^2}{\frac{s^4_{y_1}}{n_1^2(n_1-1)} + \frac{s^4_{y_2}}{n_2^2(n_2-1)}}.\]</div>
</section>
<section id="equal-or-unequal-sample-sizes-equal-variances">
<h4>Equal or unequal sample sizes, equal variances<a class="headerlink" href="#equal-or-unequal-sample-sizes-equal-variances" title="Link to this heading">¶</a></h4>
<p>If we assume equal variance (ie, <span class="math notranslate nohighlight">\(s^2_{y_1} = s^2_{y_1} = s^2\)</span>),
where <span class="math notranslate nohighlight">\(s^2\)</span> is an estimator of the common variance of the two
samples:</p>
<div class="math notranslate nohighlight">
\[\begin{split}s^2 &amp;= \frac{s_{y_1}^2(n_1-1)+s_{y_2}^2(n_2-1)}{n_1+n_2-2}\\
    &amp;= \frac{\sum_i^{n_1} (y_{1i} -\bar{y_1})^2 + \sum_j^{n_2} (y_{2j} -\bar{y_2})^2}{(n_1 - 1) + (n_2 - 1)}\end{split}\]</div>
<p>then</p>
<div class="math notranslate nohighlight">
\[s_{\bar{y_1}-\bar{y_2}} = \sqrt{\frac{s^2}{n_1} + \frac{s^2}{n_2}} = s \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}\]</div>
<p>Therefore, the <span class="math notranslate nohighlight">\(t\)</span> statistic, that is used to test whether the
means are different is:</p>
<div class="math notranslate nohighlight">
\[t = \frac{\bar{y_1} - \bar{y_2}}{s \cdot \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}},\]</div>
</section>
<section id="equal-sample-sizes-equal-variances">
<h4>Equal sample sizes, equal variances<a class="headerlink" href="#equal-sample-sizes-equal-variances" title="Link to this heading">¶</a></h4>
<p>If we simplify the problem assuming equal samples of size
<span class="math notranslate nohighlight">\(n_1 = n_2 = n/2\)</span> we get</p>
<div class="math notranslate nohighlight">
\[\begin{split}t &amp;= \frac{\bar{y_1} - \bar{y_2}}{s} \cdot \sqrt{n}\\
&amp;\approx \frac{\text{difference of means}}{\text{standard deviation of the noise}} \cdot \sqrt{n} = \approx \text{effect size} \cdot \sqrt{n}\end{split}\]</div>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Link to this heading">¶</a></h4>
<p>Given the following two samples, test whether their means are equal
using the <strong>standard t-test, assuming equal variance</strong>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">height</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.83</span><span class="p">,</span> <span class="mf">1.83</span><span class="p">,</span> <span class="mf">1.73</span><span class="p">,</span> <span class="mf">1.82</span><span class="p">,</span> <span class="mf">1.83</span><span class="p">,</span> <span class="mf">1.73</span><span class="p">,</span> <span class="mf">1.99</span><span class="p">,</span> <span class="mf">1.85</span><span class="p">,</span> <span class="mf">1.68</span><span class="p">,</span> <span class="mf">1.87</span><span class="p">,</span>
                   <span class="mf">1.66</span><span class="p">,</span> <span class="mf">1.71</span><span class="p">,</span> <span class="mf">1.73</span><span class="p">,</span> <span class="mf">1.64</span><span class="p">,</span> <span class="mf">1.70</span><span class="p">,</span> <span class="mf">1.60</span><span class="p">,</span> <span class="mf">1.79</span><span class="p">,</span> <span class="mf">1.73</span><span class="p">,</span> <span class="mf">1.62</span><span class="p">,</span> <span class="mf">1.77</span><span class="p">])</span>

<span class="n">grp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;M&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;F&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

<span class="c1"># Compute with scipy</span>
<span class="n">ttest</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">height</span><span class="p">[</span><span class="n">grp</span> <span class="o">==</span> <span class="s2">&quot;M&quot;</span><span class="p">],</span> <span class="n">height</span><span class="p">[</span><span class="n">grp</span> <span class="o">==</span> <span class="s2">&quot;F&quot;</span><span class="p">],</span> <span class="n">equal_var</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimate: </span><span class="si">{:.2f}</span><span class="s2">, t-val: </span><span class="si">{:.2f}</span><span class="s2">, p-val: </span><span class="si">{:e}</span><span class="s2">, df: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span>\
    <span class="nb">format</span><span class="p">(</span><span class="n">ttest</span><span class="o">.</span><span class="n">_estimate</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">statistic</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">ttest</span><span class="o">.</span><span class="n">df</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Estimate</span><span class="p">:</span> <span class="mf">0.12</span><span class="p">,</span> <span class="n">t</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">3.55</span><span class="p">,</span> <span class="n">p</span><span class="o">-</span><span class="n">val</span><span class="p">:</span> <span class="mf">2.282089e-03</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="mf">18.0</span>
</pre></div>
</div>
</section>
</section>
<section id="anova-f-test-quantitative-as-a-function-of-categorical-factor-with-three-levels-or-more">
<h3>ANOVA F-test: Quantitative as a function of Categorical Factor with Three Levels or More<a class="headerlink" href="#anova-f-test-quantitative-as-a-function-of-categorical-factor-with-three-levels-or-more" title="Link to this heading">¶</a></h3>
<p>Analysis of variance (ANOVA) provides a statistical test of whether or
not the means of several (k) groups are equal, and therefore generalizes
the <span class="math notranslate nohighlight">\(t\)</span>-test to more than two groups. ANOVAs are useful for
comparing (testing) three or more means (groups or variables) for
statistical significance. It is conceptually similar to multiple
two-sample <span class="math notranslate nohighlight">\(t\)</span>-tests, but is less conservative.</p>
<p>Here we will consider one-way ANOVA with one independent variable, ie
one-way ANOVA, <a class="reference external" href="https://en.wikipedia.org/wiki/F-test">see</a>:</p>
<ul class="simple">
<li><p>Test if any group is on average superior, or inferior, to the others
versus the null hypothesis that all four strategies yield the same
mean response</p></li>
<li><p>Detect any of several possible differences.</p></li>
<li><p>The advantage of the ANOVA <span class="math notranslate nohighlight">\(F\)</span>-test is that we do not need to
pre-specify which strategies are to be compared, and we do not need to
adjust for making multiple comparisons.</p></li>
<li><p>The disadvantage of the ANOVA <span class="math notranslate nohighlight">\(F\)</span>-test is that if we reject the
null hypothesis, we do not know which strategies can be said to be
significantly different from the others.</p></li>
</ul>
<ol class="arabic simple">
<li><p>Model the data</p></li>
</ol>
<p>Assumptions</p>
<ul class="simple">
<li><p>The samples are randomly selected in an independent manner from the k
populations.</p></li>
<li><p>All k populations have distributions that are approximately normal.
Check by plotting groups distribution.</p></li>
<li><p>The k population variances are equal. Check by plotting groups
distribution.</p></li>
</ul>
<p>The question is: Is there a difference in Petal Width in species from
iris dataset? Let <span class="math notranslate nohighlight">\(y_1, y_2\)</span> and <span class="math notranslate nohighlight">\(y_3\)</span> be Petal Width in
three species.</p>
<p>Here we assume (see assumptions) that the three populations were sampled
from three random variables that are normally distributed. I.e.,
<span class="math notranslate nohighlight">\(Y_1 \sim N(\mu_1, \sigma_1), Y_2 \sim N(\mu_2, \sigma_2)\)</span> and
<span class="math notranslate nohighlight">\(Y_3 \sim N(\mu_3, \sigma_3)\)</span>.</p>
<p><strong>2. Fit: estimate the model parameters</strong></p>
<p>Estimate means and variances:
<span class="math notranslate nohighlight">\(\bar{y}_i, \sigma_i,\;\; \forall i \in \{1, 2, 3\}\)</span>.</p>
<p><strong>3. :math:`F`-test</strong></p>
<p>The formula for the one-way ANOVA F-test statistic is</p>
<div class="math notranslate nohighlight">
\[\begin{split}F &amp;= \frac{\text{Explained variance}}{\text{Unexplained variance}}\\
&amp;=\frac{\text{Between-group variability}}{\text{Within-group variability}} = \frac{s^2_B}{s^2_W}.\end{split}\]</div>
<p>The “explained variance”, or “between-group variability” is</p>
<div class="math notranslate nohighlight">
\[s^2_B = \sum_i n_i(\bar{y}_{i\cdot} - \bar{y})^2/(K-1),\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{y}_{i\cdot}\)</span> denotes the sample mean in the
<span class="math notranslate nohighlight">\(i\)</span>th group, <span class="math notranslate nohighlight">\(n_i\)</span> is the number of observations in the
<span class="math notranslate nohighlight">\(i\)</span>th group, <span class="math notranslate nohighlight">\(\bar{y}\)</span> denotes the overall mean of the
data, and <span class="math notranslate nohighlight">\(K\)</span> denotes the number of groups.</p>
<p>The “unexplained variance”, or “within-group variability” is</p>
<div class="math notranslate nohighlight">
\[s^2_W = \sum_{ij} (y_{ij}-\bar{y}_{i\cdot})^2/(N-K),\]</div>
<p>where <span class="math notranslate nohighlight">\(y_{ij}\)</span> is the <span class="math notranslate nohighlight">\(j\)</span>th observation in the
<span class="math notranslate nohighlight">\(i\)</span>th out of <span class="math notranslate nohighlight">\(K\)</span> groups and <span class="math notranslate nohighlight">\(N\)</span> is the overall
sample size. This <span class="math notranslate nohighlight">\(F\)</span>-statistic follows the <span class="math notranslate nohighlight">\(F\)</span>-distribution
with <span class="math notranslate nohighlight">\(K-1\)</span> and <span class="math notranslate nohighlight">\(N-K\)</span> degrees of freedom under the null
hypothesis. The statistic will be large if the between-group variability
is large relative to the within-group variability, which is unlikely to
happen if the population means of the groups all have the same value.</p>
<p>Note that when there are only two groups for the one-way ANOVA F-test,
<span class="math notranslate nohighlight">\(F=t^2\)</span> where <span class="math notranslate nohighlight">\(t\)</span> is the Student’s <span class="math notranslate nohighlight">\(t\)</span> statistic.</p>
<section id="example-with-the-iris-dataset">
<h4>Example with the Iris Dataset:<a class="headerlink" href="#example-with-the-iris-dataset" title="Link to this heading">¶</a></h4>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Group means</span>
<span class="n">means</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">means</span><span class="p">)</span>

<span class="c1"># Group Stds (equal variances ?)</span>
<span class="n">stds</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s2">&quot;Species&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">stds</span><span class="p">)</span>

<span class="c1"># Plot groups</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">violinplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;SepalLength&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;SepalLength&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="p">,</span>
                   <span class="n">color</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">swarmplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s2">&quot;Species&quot;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s2">&quot;SepalLength&quot;</span><span class="p">,</span>  <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
                   <span class="n">data</span><span class="o">=</span><span class="n">means</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># ANOVA</span>
<span class="n">lm</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;SepalLength ~ Species&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">iris</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">lm</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># Type 2 ANOVA DataFrame</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>      <span class="n">Species</span>  <span class="n">SepalLength</span>  <span class="n">SepalWidth</span>  <span class="n">PetalLength</span>  <span class="n">PetalWidth</span>
<span class="mi">0</span>      <span class="n">setosa</span>        <span class="mf">5.006</span>       <span class="mf">3.428</span>        <span class="mf">1.462</span>       <span class="mf">0.246</span>
<span class="mi">1</span>  <span class="n">versicolor</span>        <span class="mf">5.936</span>       <span class="mf">2.770</span>        <span class="mf">4.260</span>       <span class="mf">1.326</span>
<span class="mi">2</span>   <span class="n">virginica</span>        <span class="mf">6.588</span>       <span class="mf">2.974</span>        <span class="mf">5.552</span>       <span class="mf">2.026</span>
      <span class="n">Species</span>  <span class="n">SepalLength</span>  <span class="n">SepalWidth</span>  <span class="n">PetalLength</span>  <span class="n">PetalWidth</span>
<span class="mi">0</span>      <span class="n">setosa</span>     <span class="mf">0.352490</span>    <span class="mf">0.379064</span>     <span class="mf">0.173664</span>    <span class="mf">0.105386</span>
<span class="mi">1</span>  <span class="n">versicolor</span>     <span class="mf">0.516171</span>    <span class="mf">0.313798</span>     <span class="mf">0.469911</span>    <span class="mf">0.197753</span>
<span class="mi">2</span>   <span class="n">virginica</span>     <span class="mf">0.635880</span>    <span class="mf">0.322497</span>     <span class="mf">0.551895</span>    <span class="mf">0.274650</span>
</pre></div>
</div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Species</th>
      <td>63.212133</td>
      <td>2.0</td>
      <td>119.264502</td>
      <td>1.669669e-31</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>38.956200</td>
      <td>147.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div><img alt="../_images/stat_univ_82_2.png" src="../_images/stat_univ_82_2.png" />
</section>
</section>
<section id="chi-square-chi-2-categorical-v-s-categorical-factors">
<h3>Chi-square, <span class="math notranslate nohighlight">\(\chi^2\)</span>: Categorical v.s. Categorical Factors<a class="headerlink" href="#chi-square-chi-2-categorical-v-s-categorical-factors" title="Link to this heading">¶</a></h3>
<p>Computes the chi-square, <span class="math notranslate nohighlight">\(\chi^2\)</span>, statistic and <span class="math notranslate nohighlight">\(p\)</span>-value
for the hypothesis test of independence of frequencies in the observed
contingency table (cross-table). The observed frequencies are tested
against an expected contingency table obtained by computing expected
frequencies based on the marginal sums under the assumption of
independence.</p>
<section id="id1">
<h4>Example<a class="headerlink" href="#id1" title="Link to this heading">¶</a></h4>
<p>20 participants: 10 exposed to some chemical product and 10 non exposed
(exposed = 1 or 0). Among the 20 participants 10 had cancer 10 not
(cancer = 1 or 0). <span class="math notranslate nohighlight">\(\chi^2\)</span> tests the association between those
two variables.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset:</span>
<span class="c1"># 15 samples:</span>
<span class="c1"># 10 first exposed</span>
<span class="n">exposed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1"># 8 first with cancer, 10 without, the last two with.</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">10</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">crosstab</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">crosstab</span><span class="p">(</span><span class="n">exposed</span><span class="p">,</span> <span class="n">cancer</span><span class="p">,</span> <span class="n">rownames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;exposed&#39;</span><span class="p">],</span>
                       <span class="n">colnames</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;cancer&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Observed table:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">crosstab</span><span class="p">)</span>

<span class="n">chi2</span><span class="p">,</span> <span class="n">pval</span><span class="p">,</span> <span class="n">dof</span><span class="p">,</span> <span class="n">expected</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">chi2_contingency</span><span class="p">(</span><span class="n">crosstab</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Statistics:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-----------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Chi2 = </span><span class="si">%f</span><span class="s2">, pval = </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Expected table:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;---------------&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">expected</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Observed</span> <span class="n">table</span><span class="p">:</span>
<span class="o">---------------</span>
<span class="n">cancer</span>   <span class="mi">0</span>  <span class="mi">1</span>
<span class="n">exposed</span>
<span class="mi">0</span>        <span class="mi">8</span>  <span class="mi">2</span>
<span class="mi">1</span>        <span class="mi">2</span>  <span class="mi">8</span>
<span class="n">Statistics</span><span class="p">:</span>
<span class="o">-----------</span>
<span class="n">Chi2</span> <span class="o">=</span> <span class="mf">5.000000</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="mf">0.025347</span>
<span class="n">Expected</span> <span class="n">table</span><span class="p">:</span>
<span class="o">---------------</span>
<span class="p">[[</span><span class="mf">5.</span> <span class="mf">5.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">5.</span> <span class="mf">5.</span><span class="p">]]</span>
</pre></div>
</div>
<p>Computing expected cross-table</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compute expected cross-table based on proportion</span>
<span class="n">exposed_marg</span> <span class="o">=</span> <span class="n">crosstab</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">exposed_freq</span> <span class="o">=</span> <span class="n">exposed_marg</span> <span class="o">/</span> <span class="n">exposed_marg</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="n">cancer_marg</span> <span class="o">=</span> <span class="n">crosstab</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">cancer_freq</span> <span class="o">=</span> <span class="n">cancer_marg</span> <span class="o">/</span> <span class="n">cancer_marg</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Exposed frequency? Yes: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">exposed_freq</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
      <span class="s1">&#39;No: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">exposed_freq</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cancer frequency? Yes: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">cancer_freq</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
      <span class="s1">&#39;No: </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">cancer_freq</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Expected frequencies:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">exposed_freq</span><span class="p">,</span> <span class="n">cancer_freq</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Expected cross-table (frequencies * N): &#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">exposed_freq</span><span class="p">,</span> <span class="n">cancer_freq</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">exposed</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>Exposed frequency? Yes: 0.50 No: 0.50
Cancer frequency? Yes: 0.50 No: 0.50
Expected frequencies:
[[0.25 0.25]
 [0.25 0.25]]
Expected cross-table (frequencies * N):
[[5. 5.]
 [5. 5.]]
</pre></div>
</div>
</section>
</section>
<section id="non-parametric-tests-of-pairwise-associations">
<h3>Non-parametric Tests of Pairwise Associations<a class="headerlink" href="#non-parametric-tests-of-pairwise-associations" title="Link to this heading">¶</a></h3>
<section id="spearman-rank-order-correlation-quantitative-vs-quantitative">
<h4>Spearman Rank-Order Correlation (Quantitative vs Quantitative)<a class="headerlink" href="#spearman-rank-order-correlation-quantitative-vs-quantitative" title="Link to this heading">¶</a></h4>
<p>The Spearman correlation is a non-parametric measure of the monotonicity
of the relationship between two datasets.</p>
<p>When to use it? Observe the data distribution: - presence of
<strong>outliers</strong> - the distribution of the residuals is not Gaussian.</p>
<p>Like other correlation coefficients, this one varies between -1 and +1
with 0 implying no correlation. Correlations of -1 or +1 imply an exact
monotonic relationship. Positive correlations imply that as <span class="math notranslate nohighlight">\(x\)</span>
increases, so does <span class="math notranslate nohighlight">\(y\)</span>. Negative correlations imply that as
<span class="math notranslate nohighlight">\(x\)</span> increases, <span class="math notranslate nohighlight">\(y\)</span> decreases.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Age uniform distribution between 20 and 40</span>
<span class="n">age</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>

<span class="c1"># Systolic blood presure, 2 groups:</span>
<span class="c1"># - 15 subjects at 0.05 * age + 6</span>
<span class="c1"># - 25 subjects at 0.15 * age + 10</span>
<span class="n">sbp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="mf">0.05</span> <span class="o">*</span> <span class="n">age</span><span class="p">[:</span><span class="mi">15</span><span class="p">]</span> <span class="o">+</span> <span class="mi">6</span><span class="p">,</span> <span class="mf">0.15</span> <span class="o">*</span> <span class="n">age</span><span class="p">[</span><span class="mi">15</span><span class="p">:]</span> <span class="o">+</span> <span class="mi">10</span><span class="p">))</span> <span class="o">+</span> \
    <span class="mf">.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">age</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">sbp</span><span class="p">)</span>

<span class="c1"># Non-Parametric Spearman</span>
<span class="n">cor</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">spearmanr</span><span class="p">(</span><span class="n">age</span><span class="p">,</span> <span class="n">sbp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Non-Parametric Spearman cor test, cor: </span><span class="si">%.4f</span><span class="s2">, pval: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cor</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>

<span class="c1"># &quot;Parametric Pearson cor test</span>
<span class="n">cor</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">pearsonr</span><span class="p">(</span><span class="n">age</span><span class="p">,</span> <span class="n">sbp</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Parametric Pearson cor test: cor: </span><span class="si">%.4f</span><span class="s2">, pval: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cor</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Non</span><span class="o">-</span><span class="n">Parametric</span> <span class="n">Spearman</span> <span class="n">cor</span> <span class="n">test</span><span class="p">,</span> <span class="n">cor</span><span class="p">:</span> <span class="mf">0.5122</span><span class="p">,</span> <span class="n">pval</span><span class="p">:</span> <span class="mf">0.0007</span>
<span class="n">Parametric</span> <span class="n">Pearson</span> <span class="n">cor</span> <span class="n">test</span><span class="p">:</span> <span class="n">cor</span><span class="p">:</span> <span class="mf">0.3085</span><span class="p">,</span> <span class="n">pval</span><span class="p">:</span> <span class="mf">0.0528</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_88_1.png" src="../_images/stat_univ_88_1.png" />
</section>
<section id="wilcoxon-signed-rank-rest-quantitative-vs-cte">
<h4>Wilcoxon Signed-Rank Rest (Quantitative vs Cte)<a class="headerlink" href="#wilcoxon-signed-rank-rest-quantitative-vs-cte" title="Link to this heading">¶</a></h4>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test">Wikipedia</a>:
The Wilcoxon signed-rank test is a non-parametric statistical hypothesis
test used when comparing two related samples, matched samples, or
repeated measurements on a single sample to assess whether their
population mean ranks differ (i.e. it is a paired difference test). It
is equivalent to one-sample test of the difference of paired samples.</p>
<p>It can be used as an alternative to the paired Student’s <span class="math notranslate nohighlight">\(t\)</span>-test,
<span class="math notranslate nohighlight">\(t\)</span>-test for matched pairs, or the <span class="math notranslate nohighlight">\(t\)</span>-test for dependent
samples when the population cannot be assumed to be normally
distributed.</p>
<p>When to use it? Observe the data distribution: - presence of outliers -
the distribution of the residuals is not Gaussian</p>
<p>It has a lower sensitivity compared to <span class="math notranslate nohighlight">\(t\)</span>-test. May be
problematic to use when the sample size is small.</p>
<p>Null hypothesis <span class="math notranslate nohighlight">\(H_0\)</span>: difference between the pairs follows a
symmetric distribution around zero.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># Buisness Volume time 0</span>
<span class="n">bv0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="c1"># Buisness Volume time 1</span>
<span class="n">bv1</span> <span class="o">=</span> <span class="n">bv0</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># create an outlier</span>
<span class="n">bv1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">10</span>

<span class="c1"># Paired t-test</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_rel</span><span class="p">(</span><span class="n">bv0</span><span class="p">,</span> <span class="n">bv1</span><span class="p">))</span>

<span class="c1"># Wilcoxon</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">wilcoxon</span><span class="p">(</span><span class="n">bv0</span><span class="p">,</span> <span class="n">bv1</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TtestResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.7766377807752968</span><span class="p">),</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.44693401731548044</span><span class="p">),</span> <span class="n">df</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">(</span><span class="mi">19</span><span class="p">))</span>
<span class="n">WilcoxonResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">23.0</span><span class="p">),</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.001209259033203125</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="mannwhitney-u-test-quantitative-vs-categorical-factor-with-two-levels">
<h4>Mann–Whitney <span class="math notranslate nohighlight">\(U\)</span> test (Quantitative vs Categorical Factor with Two Levels)<a class="headerlink" href="#mannwhitney-u-test-quantitative-vs-categorical-factor-with-two-levels" title="Link to this heading">¶</a></h4>
<p>In statistics, the Mann–Whitney <span class="math notranslate nohighlight">\(U\)</span> test (also called the
Mann–Whitney–Wilcoxon, Wilcoxon rank-sum test or Wilcoxon–Mann–Whitney
test) is a nonparametric test of the null hypothesis that two samples
come from the same population against an alternative hypothesis,
especially that a particular population tends to have larger values than
the other.</p>
<p>It can be applied on unknown distributions contrary to e.g. a
<span class="math notranslate nohighlight">\(t\)</span>-test that has to be applied only on normal distributions, and
it is nearly as efficient as the <span class="math notranslate nohighlight">\(t\)</span>-test on normal distributions.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="c1"># Buismess Volume group 0</span>
<span class="n">bv0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># Buismess Volume group 1</span>
<span class="n">bv1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>

<span class="c1"># create an outlier</span>
<span class="n">bv1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-=</span> <span class="mi">10</span>

<span class="c1"># Two-samples t-test</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">bv0</span><span class="p">,</span> <span class="n">bv1</span><span class="p">))</span>

<span class="c1"># Wilcoxon</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">mannwhitneyu</span><span class="p">(</span><span class="n">bv0</span><span class="p">,</span> <span class="n">bv1</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">TtestResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.6104564820307219</span><span class="p">),</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">0.5451934484051324</span><span class="p">),</span> <span class="n">df</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">38.0</span><span class="p">))</span>
<span class="n">MannwhitneyuResult</span><span class="p">(</span><span class="n">statistic</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">41.0</span><span class="p">),</span> <span class="n">pvalue</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">1.8074477738835562e-05</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="linear-model">
<h2>Linear Model<a class="headerlink" href="#linear-model" title="Link to this heading">¶</a></h2>
<figure class="align-default" id="id6">
<a class="reference internal image-reference" href="../_images/model_lm.png"><img alt="Linear model" src="../_images/model_lm.png" style="width: 5cm;" />
</a>
<figcaption>
<p><span class="caption-text">Linear model</span><a class="headerlink" href="#id6" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Given <span class="math notranslate nohighlight">\(n\)</span> random samples
<span class="math notranslate nohighlight">\((y_i, x_{1i}, \ldots, x_{pi}), \, i = 1, \ldots, n\)</span>, the linear
regression models the relation between the observations <span class="math notranslate nohighlight">\(y_i\)</span> and
the independent variables <span class="math notranslate nohighlight">\(x_i^p\)</span> is formulated as</p>
<div class="math notranslate nohighlight">
\[y_i = \beta_0 + \beta_1 x_{1i} + \cdots + \beta_p x_{pi} + \varepsilon_i \qquad i = 1, \ldots, n\]</div>
<ul class="simple">
<li><p>The <span class="math notranslate nohighlight">\(\beta\)</span>’s are the model parameters, ie, the regression
coeficients.</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span> is the intercept or the bias.</p></li>
<li><p><span class="math notranslate nohighlight">\(\varepsilon_i\)</span> are the <strong>residuals</strong>.</p></li>
<li><p><strong>An independent variable (IV)</strong>. It is a variable that stands alone
and isn’t changed by the other variables you are trying to measure.
For example, someone’s age might be an independent variable. Other
factors (such as what they eat, how much they go to school, how much
television they watch) aren’t going to change a person’s age. In fact,
when you are looking for some kind of relationship between variables
you are trying to see if the independent variable causes some kind of
change in the other variables, or dependent variables. In Machine
Learning, these variables are also called the <strong>predictors</strong>.</p></li>
<li><p>A <strong>dependent variable</strong>. It is something that depends on other
factors. For example, a test score could be a dependent variable
because it could change depending on several factors such as how much
you studied, how much sleep you got the night before you took the
test, or even how hungry you were when you took it. Usually when you
are looking for a relationship between two things you are trying to
find out what makes the dependent variable change the way it does. In
Machine Learning this variable is called a <strong>target variable</strong>.</p></li>
</ul>
<section id="assumptions">
<h3>Assumptions<a class="headerlink" href="#assumptions" title="Link to this heading">¶</a></h3>
<ol class="arabic simple">
<li><p>Independence of residuals (<span class="math notranslate nohighlight">\(\varepsilon_i\)</span>). This assumptions
<strong>must</strong> be satisfied</p></li>
<li><p>Normality of residuals (<span class="math notranslate nohighlight">\(\varepsilon_i\)</span>). Approximately
normally distributed can be accepted.</p></li>
</ol>
<p><a class="reference external" href="http://people.duke.edu/~rnau/testing.htm">Regression diagnostics: testing the assumptions of linear
regression</a></p>
</section>
<section id="simple-regression-test-association-between-two-quantitative-variables">
<h3>Simple Regression: Test Association Between Two Quantitative Variables<a class="headerlink" href="#simple-regression-test-association-between-two-quantitative-variables" title="Link to this heading">¶</a></h3>
<p>Using the dataset “salary”, explore the association between the
dependant variable (e.g. Salary) and the independent variable (e.g.:
Experience is quantitative), considering only non-managers.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">salary</span><span class="p">[</span><span class="n">salary</span><span class="o">.</span><span class="n">management</span> <span class="o">==</span> <span class="s1">&#39;N&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>1. Model the data</strong></p>
<p>Model the data on some <strong>hypothesis</strong> e.g.: salary is a linear function
of the experience.</p>
<div class="math notranslate nohighlight">
\[\text{salary}_i = \beta_0 + \beta~\text{experience}_i + \epsilon_i,\]</div>
<p>more generally</p>
<div class="math notranslate nohighlight">
\[y_i = \beta_0 + \beta~x_i + \epsilon_i\]</div>
<p>This can be rewritten in the matrix form using the design matrix made of
values of independant variable and the intercept:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}\begin{bmatrix}y_1 \\ y_2 \\ y_3 \\ y_4 \\ y_5  \end{bmatrix}
  =
  \begin{bmatrix}1 &amp; x_1  \\1 &amp; x_2  \\1 &amp; x_3  \\1 &amp; x_4  \\1 &amp; x_5    \end{bmatrix}
  \begin{bmatrix} \beta_0 \\ \beta_1  \end{bmatrix}
  +
  \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \epsilon_4 \\ \epsilon_5 \end{bmatrix}\end{split}\end{split}\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\beta\)</span>: the slope or coefficient or parameter of the model,</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta_0\)</span>: the <strong>intercept</strong> or <strong>bias</strong> is the second parameter
of the model,</p></li>
<li><p><span class="math notranslate nohighlight">\(\epsilon_i\)</span>: is the <span class="math notranslate nohighlight">\(i\)</span>th error, or residual with
<span class="math notranslate nohighlight">\(\epsilon \sim \mathcal{N}(0, \sigma^2)\)</span>.</p></li>
</ul>
<p>The simple regression is equivalent to the Pearson correlation.</p>
<p><strong>2. Fit: estimate the model parameters</strong></p>
<p>The goal it so estimate <span class="math notranslate nohighlight">\(\beta\)</span>, <span class="math notranslate nohighlight">\(\beta_0\)</span> and
<span class="math notranslate nohighlight">\(\sigma^2\)</span>.</p>
<p>Minimizes the <strong>mean squared error (MSE)</strong> or the <strong>Sum squared error
(SSE)</strong>. The so-called <strong>Ordinary Least Squares (OLS)</strong> finds
<span class="math notranslate nohighlight">\(\beta, \beta_0\)</span> that minimizes the
<span class="math notranslate nohighlight">\(SSE = \sum_i \epsilon_i^2\)</span></p>
<div class="math notranslate nohighlight">
\[SSE = \sum_i(y_i - \beta~x_i - \beta_0)^2\]</div>
<p>Recall from calculus that an extreme point can be found by computing
where the derivative is zero, i.e. to find the intercept, we perform the
steps:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{\partial SSE}{\partial \beta_0} = \sum_i(y_i - \beta~x_i - \beta_0) = 0\\
\sum_i y_i = \beta~\sum_i x_i + n~\beta_0\\
n~\bar{y} = n~\beta~\bar{x} + n~\beta_0\\
\beta_0 = \bar{y} - \beta~\bar{x}\end{split}\]</div>
<p>To find the regression coefficient, we perform the steps:</p>
<div class="math notranslate nohighlight">
\[\frac{\partial SSE}{\partial \beta} = \sum_i x_i(y_i - \beta~x_i - \beta_0) = 0\]</div>
<p>Plug in <span class="math notranslate nohighlight">\(\beta_0\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\sum_i x_i(y_i - \beta~x_i - \bar{y} + \beta \bar{x}) = 0\\
\sum_i x_i y_i - \bar{y}\sum_i x_i = \beta \sum_i(x_i - \bar{x})\end{split}\]</div>
<p>Divide both sides by <span class="math notranslate nohighlight">\(n\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\frac{1}{n}\sum_i x_i y_i  - \bar{y}\bar{x} = \frac{1}{n}\beta \sum_i(x_i - \bar{x})\\
\beta = \frac{\frac{1}{n}\sum_i x_i y_i  - \bar{y}\bar{x}}{\frac{1}{n}\sum_i(x_i - \bar{x})} = \frac{Cov(x, y)}{Var(x)}.\end{split}\]</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">salary</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">experience</span>
<span class="n">beta</span><span class="p">,</span> <span class="n">beta0</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span> <span class="o">=</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">linregress</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y = </span><span class="si">%f</span><span class="s2"> x + </span><span class="si">%f</span><span class="s2">,  r: </span><span class="si">%f</span><span class="s2">, r-squared: </span><span class="si">%f</span><span class="s2">,</span><span class="se">\n</span><span class="s2">p-value: </span><span class="si">%f</span><span class="s2">, std_err: </span><span class="si">%f</span><span class="s2">&quot;</span>
      <span class="o">%</span> <span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">beta0</span><span class="p">,</span> <span class="n">r_value</span><span class="p">,</span> <span class="n">r_value</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">p_value</span><span class="p">,</span> <span class="n">std_err</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Regression line with the scatterplot&quot;</span><span class="p">)</span>
<span class="n">yhat</span> <span class="o">=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span>  <span class="o">+</span>  <span class="n">beta0</span> <span class="c1"># regression line</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">yhat</span><span class="p">,</span> <span class="s1">&#39;r-&#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Experience (years)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Salary&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="mf">452.658228</span> <span class="n">x</span> <span class="o">+</span> <span class="mf">10785.911392</span><span class="p">,</span>  <span class="n">r</span><span class="p">:</span> <span class="mf">0.965370</span><span class="p">,</span> <span class="n">r</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span> <span class="mf">0.931939</span><span class="p">,</span>
<span class="n">p</span><span class="o">-</span><span class="n">value</span><span class="p">:</span> <span class="mf">0.000000</span><span class="p">,</span> <span class="n">std_err</span><span class="p">:</span> <span class="mf">24.970021</span>
<span class="n">Regression</span> <span class="n">line</span> <span class="k">with</span> <span class="n">the</span> <span class="n">scatterplot</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_97_1.png" src="../_images/stat_univ_97_1.png" />
</section>
<section id="multiple-regression">
<h3>Multiple Regression<a class="headerlink" href="#multiple-regression" title="Link to this heading">¶</a></h3>
<p><strong>Theory</strong></p>
<p>Multiple Linear Regression is the most basic supervised learning
algorithm.</p>
<p>Given: a set of training data <span class="math notranslate nohighlight">\(\{x_1, ... , x_N\}\)</span> with
corresponding targets <span class="math notranslate nohighlight">\(\{y_1, . . . , y_N\}\)</span>.</p>
<p>In linear regression, we assume that the model that generates the data
involves only a linear combination of the input variables, i.e.</p>
<div class="math notranslate nohighlight">
\[y_i = \beta_0 + \beta_1 x_{i1} + ... + \beta_P x_{iP} + \varepsilon_i,\]</div>
<p>or, simplified</p>
<div class="math notranslate nohighlight">
\[y_i  = \beta_0 + \sum_{j=1}^{P-1} \beta_j x_i^j + \varepsilon_i.\]</div>
<p>Extending each sample with an intercept,
<span class="math notranslate nohighlight">\(x_i := [1, x_i] \in R^{P+1}\)</span> allows us to use a more general
notation based on linear algebra and write it as a simple dot product:</p>
<div class="math notranslate nohighlight">
\[y_i = \mathbf{x}_i^T\mathbf{\beta} + \varepsilon_i,\]</div>
<p>where <span class="math notranslate nohighlight">\(\beta \in R^{P+1}\)</span> is a vector of weights that define the
<span class="math notranslate nohighlight">\(P+1\)</span> parameters of the model. From now we have <span class="math notranslate nohighlight">\(P\)</span>
regressors + the intercept.</p>
<p>Using the matrix notation:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}\begin{bmatrix}y_1 \\ y_2 \\ y_3 \\ y_4 \\ y_5  \end{bmatrix}
  =
  \begin{bmatrix}1 &amp; x_{11}  &amp; \ldots &amp; x_{1P}\\1 &amp; x_{21} &amp; \ldots &amp; x_{2P}  \\1 &amp; x_{31} &amp; \ldots &amp; x_{3P}  \\1 &amp; x_{41} &amp; \ldots &amp; x_{4P}  \\1 &amp; x_5 &amp; \ldots &amp; x_5    \end{bmatrix}
  \begin{bmatrix} \beta_0 \\ \beta_1 \\ \vdots \\ \beta_P \end{bmatrix}
  +
  \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \epsilon_4 \\ \epsilon_5 \end{bmatrix}\end{split}\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(X = [x_0^T, ... , x_N^T]\)</span> be the (<span class="math notranslate nohighlight">\(N \times P+1\)</span>)
<strong>design matrix</strong> of <span class="math notranslate nohighlight">\(N\)</span> samples of <span class="math notranslate nohighlight">\(P\)</span> input features with
one column of one and let be <span class="math notranslate nohighlight">\(y = [y_1, ... , y_N]\)</span> be a vector of
the <span class="math notranslate nohighlight">\(N\)</span> targets.</p>
<div class="math notranslate nohighlight">
\[y = X \beta + \varepsilon\]</div>
<p>Minimize the Mean Squared Error MSE loss:</p>
<div class="math notranslate nohighlight">
\[MSE(\beta) = \frac{1}{N}\sum_{i=1}^{N}(y_i - \mathbf{x}_i^T\beta)^2\]</div>
<p>Using the matrix notation, the <strong>mean squared error (MSE) loss can be
rewritten</strong>:</p>
<div class="math notranslate nohighlight">
\[MSE(\beta) = \frac{1}{N}||y - X\beta||_2^2.\]</div>
<p>The <span class="math notranslate nohighlight">\(\beta\)</span> that minimizes the MSE can be found by:</p>
<p>:raw-latex:<a href="#id2"><span class="problematic" id="id3">`</span></a>begin{align}
nabla_beta left(frac{1}{N} ||y - Xbeta||_2^2right) &amp;= 0\
frac{1}{N}nabla_beta (y - Xbeta)^T (y - Xbeta) &amp;= 0\
frac{1}{N}nabla_beta (y^Ty - 2 beta^TX^Ty + beta^T X^TXbeta) &amp;= 0\</p>
<blockquote>
<div><p>-2X^Ty + 2 X^TXbeta &amp;= 0\
X^TXbeta &amp;= X^Ty\
beta &amp;= (X^TX)^{-1} X^Ty,</p>
</div></blockquote>
<p>end{align}`</p>
<p>where <span class="math notranslate nohighlight">\((X^TX)^{-1} X^T\)</span> is a pseudo inverse of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>Simulated dataset where:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{split}\begin{bmatrix}y_1 \\ \vdots \\ y_{50}  \end{bmatrix}
  =
  \begin{bmatrix}
  1 &amp; x_{1,1}  &amp; x_{1,2} &amp; x_{1,3} \\
  \vdots &amp; \vdots  &amp; \vdots &amp; \vdots \\
  1 &amp; x_{50,1}  &amp; x_{50,2} &amp; x_{50,3} \\
  \end{bmatrix}
  \begin{bmatrix} 10 \\ 1 \\ 0.5 \\ 0.1 \end{bmatrix}
  +
  \begin{bmatrix} \epsilon_1 \\ \vdots \\ \epsilon_{50} \end{bmatrix}\end{split}\end{split}\]</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">scipy</span><span class="w"> </span><span class="kn">import</span> <span class="n">linalg</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># make the example reproducible</span>

<span class="c1"># Dataset</span>
<span class="n">N</span><span class="p">,</span> <span class="n">P</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span> <span class="n">N</span> <span class="o">*</span> <span class="n">P</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">P</span><span class="p">))</span>
<span class="c1">## Our model needs an intercept so we add a column of 1s:</span>
<span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:])</span>

<span class="n">betastar</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">.5</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">])</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">betastar</span><span class="p">)</span> <span class="o">+</span> <span class="n">e</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[[</span> <span class="mf">1.</span>         <span class="o">-</span><span class="mf">0.1382643</span>   <span class="mf">0.64768854</span>  <span class="mf">1.52302986</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">1.</span>         <span class="o">-</span><span class="mf">0.23413696</span>  <span class="mf">1.57921282</span>  <span class="mf">0.76743473</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">1.</span>          <span class="mf">0.54256004</span> <span class="o">-</span><span class="mf">0.46341769</span> <span class="o">-</span><span class="mf">0.46572975</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">1.</span>         <span class="o">-</span><span class="mf">1.91328024</span> <span class="o">-</span><span class="mf">1.72491783</span> <span class="o">-</span><span class="mf">0.56228753</span><span class="p">]</span>
 <span class="p">[</span> <span class="mf">1.</span>          <span class="mf">0.31424733</span> <span class="o">-</span><span class="mf">0.90802408</span> <span class="o">-</span><span class="mf">1.4123037</span> <span class="p">]]</span>
</pre></div>
</div>
<p><strong>Fit with ``numpy``</strong></p>
<p>Estimate the parameters</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Xpinv</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">betahat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">Xpinv</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Estimated beta:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">betahat</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Estimated</span> <span class="n">beta</span><span class="p">:</span>
 <span class="p">[</span><span class="mf">10.14742501</span>  <span class="mf">0.57938106</span>  <span class="mf">0.51654653</span>  <span class="mf">0.17862194</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="linear-model-with-statsmodels">
<h3>Linear Model with Statsmodels<a class="headerlink" href="#linear-model-with-statsmodels" title="Link to this heading">¶</a></h3>
<p><a class="reference external" href="http://statsmodels.sourceforge.net/devel/examples/">Statmodels
examples</a></p>
<section id="multiple-regression-using-numpy-array">
<h4>Multiple Regression Using Numpy Array<a class="headerlink" href="#multiple-regression-using-numpy-array" title="Link to this heading">¶</a></h4>
<p>Interface with statsmodels without formulae (<code class="docutils literal notranslate"><span class="pre">sm</span></code>)</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Fit and summary:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>

<span class="c1"># prediction of new values</span>
<span class="n">ypred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># residuals + prediction == true values</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">ypred</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">resid</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                            <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                      <span class="n">y</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.363</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.322</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">8.748</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Wed</span><span class="p">,</span> <span class="mi">14</span> <span class="n">May</span> <span class="mi">2025</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">0.000106</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">23</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">21</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                <span class="o">-</span><span class="mf">71.271</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">50</span>   <span class="n">AIC</span><span class="p">:</span>                             <span class="mf">150.5</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">46</span>   <span class="n">BIC</span><span class="p">:</span>                             <span class="mf">158.2</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">3</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">const</span>         <span class="mf">10.1474</span>      <span class="mf">0.150</span>     <span class="mf">67.520</span>      <span class="mf">0.000</span>       <span class="mf">9.845</span>      <span class="mf">10.450</span>
<span class="n">x1</span>             <span class="mf">0.5794</span>      <span class="mf">0.160</span>      <span class="mf">3.623</span>      <span class="mf">0.001</span>       <span class="mf">0.258</span>       <span class="mf">0.901</span>
<span class="n">x2</span>             <span class="mf">0.5165</span>      <span class="mf">0.151</span>      <span class="mf">3.425</span>      <span class="mf">0.001</span>       <span class="mf">0.213</span>       <span class="mf">0.820</span>
<span class="n">x3</span>             <span class="mf">0.1786</span>      <span class="mf">0.144</span>      <span class="mf">1.240</span>      <span class="mf">0.221</span>      <span class="o">-</span><span class="mf">0.111</span>       <span class="mf">0.469</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">2.493</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">2.369</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.288</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">1.544</span>
<span class="n">Skew</span><span class="p">:</span>                           <span class="mf">0.330</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.462</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.554</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                         <span class="mf">1.27</span>
<span class="o">==============================================================================</span>

<span class="n">Notes</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
</pre></div>
</div>
</section>
<section id="multiple-regression-pandas-using-formulae-smf">
<h4>Multiple Regression Pandas using formulae (<code class="docutils literal notranslate"><span class="pre">smf</span></code>)<a class="headerlink" href="#multiple-regression-pandas-using-formulae-smf" title="Link to this heading">¶</a></h4>
<p>Use <code class="docutils literal notranslate"><span class="pre">R</span></code> language syntax for data.frame. For an additive model:</p>
<p><span class="math notranslate nohighlight">\(y_i = \beta^0 + x_i^1 \beta^1 + x_i^2 \beta^2 + \epsilon_i \equiv\)</span>
<code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">~</span> <span class="pre">x1</span> <span class="pre">+</span> <span class="pre">x2</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">]),</span>
                  <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;inter&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span><span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">columns</span><span class="p">,</span> <span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># Build a model excluding the intercept, it is implicit</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s2">&quot;y~x1 + x2 + x3&quot;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Index</span><span class="p">([</span><span class="s1">&#39;inter&#39;</span><span class="p">,</span> <span class="s1">&#39;x1&#39;</span><span class="p">,</span> <span class="s1">&#39;x2&#39;</span><span class="p">,</span> <span class="s1">&#39;x3&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span> <span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
                            <span class="n">OLS</span> <span class="n">Regression</span> <span class="n">Results</span>
<span class="o">==============================================================================</span>
<span class="n">Dep</span><span class="o">.</span> <span class="n">Variable</span><span class="p">:</span>                      <span class="n">y</span>   <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                       <span class="mf">0.363</span>
<span class="n">Model</span><span class="p">:</span>                            <span class="n">OLS</span>   <span class="n">Adj</span><span class="o">.</span> <span class="n">R</span><span class="o">-</span><span class="n">squared</span><span class="p">:</span>                  <span class="mf">0.322</span>
<span class="n">Method</span><span class="p">:</span>                 <span class="n">Least</span> <span class="n">Squares</span>   <span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">:</span>                     <span class="mf">8.748</span>
<span class="n">Date</span><span class="p">:</span>                <span class="n">Wed</span><span class="p">,</span> <span class="mi">14</span> <span class="n">May</span> <span class="mi">2025</span>   <span class="n">Prob</span> <span class="p">(</span><span class="n">F</span><span class="o">-</span><span class="n">statistic</span><span class="p">):</span>           <span class="mf">0.000106</span>
<span class="n">Time</span><span class="p">:</span>                        <span class="mi">23</span><span class="p">:</span><span class="mi">26</span><span class="p">:</span><span class="mi">21</span>   <span class="n">Log</span><span class="o">-</span><span class="n">Likelihood</span><span class="p">:</span>                <span class="o">-</span><span class="mf">71.271</span>
<span class="n">No</span><span class="o">.</span> <span class="n">Observations</span><span class="p">:</span>                  <span class="mi">50</span>   <span class="n">AIC</span><span class="p">:</span>                             <span class="mf">150.5</span>
<span class="n">Df</span> <span class="n">Residuals</span><span class="p">:</span>                      <span class="mi">46</span>   <span class="n">BIC</span><span class="p">:</span>                             <span class="mf">158.2</span>
<span class="n">Df</span> <span class="n">Model</span><span class="p">:</span>                           <span class="mi">3</span>
<span class="n">Covariance</span> <span class="n">Type</span><span class="p">:</span>            <span class="n">nonrobust</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">Intercept</span>     <span class="mf">10.1474</span>      <span class="mf">0.150</span>     <span class="mf">67.520</span>      <span class="mf">0.000</span>       <span class="mf">9.845</span>      <span class="mf">10.450</span>
<span class="n">x1</span>             <span class="mf">0.5794</span>      <span class="mf">0.160</span>      <span class="mf">3.623</span>      <span class="mf">0.001</span>       <span class="mf">0.258</span>       <span class="mf">0.901</span>
<span class="n">x2</span>             <span class="mf">0.5165</span>      <span class="mf">0.151</span>      <span class="mf">3.425</span>      <span class="mf">0.001</span>       <span class="mf">0.213</span>       <span class="mf">0.820</span>
<span class="n">x3</span>             <span class="mf">0.1786</span>      <span class="mf">0.144</span>      <span class="mf">1.240</span>      <span class="mf">0.221</span>      <span class="o">-</span><span class="mf">0.111</span>       <span class="mf">0.469</span>
<span class="o">==============================================================================</span>
<span class="n">Omnibus</span><span class="p">:</span>                        <span class="mf">2.493</span>   <span class="n">Durbin</span><span class="o">-</span><span class="n">Watson</span><span class="p">:</span>                   <span class="mf">2.369</span>
<span class="n">Prob</span><span class="p">(</span><span class="n">Omnibus</span><span class="p">):</span>                  <span class="mf">0.288</span>   <span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="p">(</span><span class="n">JB</span><span class="p">):</span>                <span class="mf">1.544</span>
<span class="n">Skew</span><span class="p">:</span>                           <span class="mf">0.330</span>   <span class="n">Prob</span><span class="p">(</span><span class="n">JB</span><span class="p">):</span>                        <span class="mf">0.462</span>
<span class="n">Kurtosis</span><span class="p">:</span>                       <span class="mf">3.554</span>   <span class="n">Cond</span><span class="o">.</span> <span class="n">No</span><span class="o">.</span>                         <span class="mf">1.27</span>
<span class="o">==============================================================================</span>

<span class="n">Notes</span><span class="p">:</span>
<span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">Standard</span> <span class="n">Errors</span> <span class="n">assume</span> <span class="n">that</span> <span class="n">the</span> <span class="n">covariance</span> <span class="n">matrix</span> <span class="n">of</span> <span class="n">the</span> <span class="n">errors</span> <span class="ow">is</span> <span class="n">correctly</span> <span class="n">specified</span><span class="o">.</span>
</pre></div>
</div>
</section>
</section>
<section id="multiple-regression-mixing-covariates-and-factors-ancova">
<h3>Multiple Regression Mixing Covariates and Factors (ANCOVA)<a class="headerlink" href="#multiple-regression-mixing-covariates-and-factors-ancova" title="Link to this heading">¶</a></h3>
<p>Analysis of covariance (ANCOVA) is a linear model that blends ANOVA and
linear regression. ANCOVA evaluates whether population means of a
dependent variable (DV) are equal across levels of a categorical
independent variable (IV) often called a treatment, while statistically
controlling for the effects of other quantitative or continuous
variables that are not of primary interest, known as covariates (CV).</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">salary</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">lm</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;salary ~ experience&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;residuals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">lm</span><span class="o">.</span><span class="n">resid</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera normality test p-value </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span> \
      <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">jarque_bera</span><span class="p">(</span><span class="n">lm</span><span class="o">.</span><span class="n">resid</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">fig_h</span><span class="o">*</span><span class="mf">0.7</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;management&#39;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">aspect</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">fig_h</span><span class="o">*</span><span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="n">normality</span> <span class="n">test</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span> <span class="mf">0.04374</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_109_1.png" src="../_images/stat_univ_109_1.png" />
<img alt="../_images/stat_univ_109_2.png" src="../_images/stat_univ_109_2.png" />
<p>Normality assumption of the residuals can be rejected (p-value &lt; 0.05).
There is an efect of the “management” factor, take it into account.</p>
<section id="one-way-an-c-ova">
<h4>One-way AN(C)OVA<a class="headerlink" href="#one-way-an-c-ova" title="Link to this heading">¶</a></h4>
<ul class="simple">
<li><p>ANOVA: one categorical independent variable, i.e. one factor.</p></li>
<li><p>ANCOVA: ANOVA with some covariates.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">oneway</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;salary ~ management + experience&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;residuals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">oneway</span><span class="o">.</span><span class="n">resid</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">aspect</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">fig_h</span><span class="o">*</span><span class="mf">0.7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">oneway</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera normality test p-value </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span>  \
      <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">jarque_bera</span><span class="p">(</span><span class="n">oneway</span><span class="o">.</span><span class="n">resid</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                  <span class="n">sum_sq</span>    <span class="n">df</span>           <span class="n">F</span>        <span class="n">PR</span><span class="p">(</span><span class="o">&gt;</span><span class="n">F</span><span class="p">)</span>
<span class="n">management</span>  <span class="mf">5.755739e+08</span>   <span class="mf">1.0</span>  <span class="mf">183.593466</span>  <span class="mf">4.054116e-17</span>
<span class="n">experience</span>  <span class="mf">3.334992e+08</span>   <span class="mf">1.0</span>  <span class="mf">106.377768</span>  <span class="mf">3.349662e-13</span>
<span class="n">Residual</span>    <span class="mf">1.348070e+08</span>  <span class="mf">43.0</span>         <span class="n">NaN</span>           <span class="n">NaN</span>
<span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="n">normality</span> <span class="n">test</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span> <span class="mf">0.004</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_112_1.png" src="../_images/stat_univ_112_1.png" />
<p>Distribution of residuals is still not normal but closer to normality.
Both management and experience are significantly associated with salary.</p>
</section>
<section id="two-way-an-c-ova">
<h4>Two-way AN(C)OVA<a class="headerlink" href="#two-way-an-c-ova" title="Link to this heading">¶</a></h4>
<p>Ancova with two categorical independent variables, i.e. two factors.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">twoway</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;salary ~ education + management + experience&#39;</span><span class="p">,</span> <span class="n">df</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="n">df</span><span class="p">[</span><span class="s2">&quot;residuals&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">twoway</span><span class="o">.</span><span class="n">resid</span>
<span class="n">sns</span><span class="o">.</span><span class="n">displot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;kde&quot;</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">aspect</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="n">fig_h</span><span class="o">*</span><span class="mf">0.7</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">anova_lm</span><span class="p">(</span><span class="n">twoway</span><span class="p">,</span> <span class="n">typ</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jarque-Bera normality test p-value </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span>  \
      <span class="n">sm</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">jarque_bera</span><span class="p">(</span><span class="n">twoway</span><span class="o">.</span><span class="n">resid</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                  <span class="n">sum_sq</span>    <span class="n">df</span>           <span class="n">F</span>        <span class="n">PR</span><span class="p">(</span><span class="o">&gt;</span><span class="n">F</span><span class="p">)</span>
<span class="n">education</span>   <span class="mf">9.152624e+07</span>   <span class="mf">2.0</span>   <span class="mf">43.351589</span>  <span class="mf">7.672450e-11</span>
<span class="n">management</span>  <span class="mf">5.075724e+08</span>   <span class="mf">1.0</span>  <span class="mf">480.825394</span>  <span class="mf">2.901444e-24</span>
<span class="n">experience</span>  <span class="mf">3.380979e+08</span>   <span class="mf">1.0</span>  <span class="mf">320.281524</span>  <span class="mf">5.546313e-21</span>
<span class="n">Residual</span>    <span class="mf">4.328072e+07</span>  <span class="mf">41.0</span>         <span class="n">NaN</span>           <span class="n">NaN</span>
<span class="n">Jarque</span><span class="o">-</span><span class="n">Bera</span> <span class="n">normality</span> <span class="n">test</span> <span class="n">p</span><span class="o">-</span><span class="n">value</span> <span class="mf">0.506</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_115_1.png" src="../_images/stat_univ_115_1.png" />
<p>Normality assumtion cannot be rejected. Assume it. Education, management
and experience are significantly associated with salary.</p>
</section>
<section id="comparing-two-nested-models">
<h4>Comparing Two Nested Models<a class="headerlink" href="#comparing-two-nested-models" title="Link to this heading">¶</a></h4>
<p><code class="docutils literal notranslate"><span class="pre">oneway</span></code> is nested within <code class="docutils literal notranslate"><span class="pre">twoway</span></code>. Comparing two nested models
tells us if the additional predictors (i.e. <code class="docutils literal notranslate"><span class="pre">education</span></code>) of the full
model significantly decrease the residuals. Such comparison can be done
using an <span class="math notranslate nohighlight">\(F\)</span>-test on residuals:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">twoway</span><span class="o">.</span><span class="n">compare_f_test</span><span class="p">(</span><span class="n">oneway</span><span class="p">))</span>  <span class="c1"># return F, pval, df</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">43.35158945918104</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">7.6724495704955e-11</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">(</span><span class="mf">2.0</span><span class="p">))</span>
</pre></div>
</div>
<p>twoway is significantly better than one way</p>
</section>
<section id="factor-coding">
<h4>Factor Coding<a class="headerlink" href="#factor-coding" title="Link to this heading">¶</a></h4>
<p><a class="reference external" href="http://statsmodels.sourceforge.net/devel/contrasts.html">Statsmodels
contrasts</a>.
By default Pandas use “dummy coding”. Explore:</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">twoway</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">param_names</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">twoway</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">exog</span><span class="p">[:</span><span class="mi">10</span><span class="p">,</span> <span class="p">:])</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="s1">&#39;Intercept&#39;</span><span class="p">,</span> <span class="s1">&#39;education[T.Master]&#39;</span><span class="p">,</span> <span class="s1">&#39;education[T.Ph.D]&#39;</span><span class="p">,</span> <span class="s1">&#39;management[T.Y]&#39;</span><span class="p">,</span> <span class="s1">&#39;experience&#39;</span><span class="p">]</span>
<span class="p">[[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">2.</span><span class="p">]</span>
 <span class="p">[</span><span class="mf">1.</span> <span class="mf">1.</span> <span class="mf">0.</span> <span class="mf">0.</span> <span class="mf">3.</span><span class="p">]]</span>
</pre></div>
</div>
</section>
<section id="contrasts-and-post-hoc-tests">
<h4>Contrasts and Post-hoc Tests<a class="headerlink" href="#contrasts-and-post-hoc-tests" title="Link to this heading">¶</a></h4>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># t-test of the specific contribution of experience:</span>
<span class="n">ttest_exp</span> <span class="o">=</span> <span class="n">twoway</span><span class="o">.</span><span class="n">t_test</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ttest_exp</span><span class="o">.</span><span class="n">pvalue</span><span class="p">,</span> <span class="n">ttest_exp</span><span class="o">.</span><span class="n">tvalue</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ttest_exp</span><span class="p">)</span>

<span class="c1"># Alternatively, you can specify the hypothesis tests using a string</span>
<span class="n">twoway</span><span class="o">.</span><span class="n">t_test</span><span class="p">(</span><span class="s1">&#39;experience&#39;</span><span class="p">)</span>

<span class="c1"># Post-hoc is salary of Master different salary of Ph.D?</span>
<span class="c1"># ie. t-test salary of Master = salary of Ph.D.</span>
<span class="nb">print</span><span class="p">(</span><span class="n">twoway</span><span class="o">.</span><span class="n">t_test</span><span class="p">(</span><span class="s1">&#39;education[T.Master] = education[T.Ph.D]&#39;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>                             <span class="n">Test</span> <span class="k">for</span> <span class="n">Constraints</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">c0</span>           <span class="mf">546.1840</span>     <span class="mf">30.519</span>     <span class="mf">17.896</span>      <span class="mf">0.000</span>     <span class="mf">484.549</span>     <span class="mf">607.819</span>
<span class="o">==============================================================================</span>
                             <span class="n">Test</span> <span class="k">for</span> <span class="n">Constraints</span>
<span class="o">==============================================================================</span>
                 <span class="n">coef</span>    <span class="n">std</span> <span class="n">err</span>          <span class="n">t</span>      <span class="n">P</span><span class="o">&gt;|</span><span class="n">t</span><span class="o">|</span>      <span class="p">[</span><span class="mf">0.025</span>      <span class="mf">0.975</span><span class="p">]</span>
<span class="o">------------------------------------------------------------------------------</span>
<span class="n">c0</span>           <span class="mf">147.8249</span>    <span class="mf">387.659</span>      <span class="mf">0.381</span>      <span class="mf">0.705</span>    <span class="o">-</span><span class="mf">635.069</span>     <span class="mf">930.719</span>
<span class="o">==============================================================================</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="multiple-comparisons">
<h2>Multiple Comparisons<a class="headerlink" href="#multiple-comparisons" title="Link to this heading">¶</a></h2>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">pystatsml</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>

<span class="n">n_features</span><span class="p">,</span> <span class="n">n_informative</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">100</span>
<span class="n">Y</span><span class="p">,</span> <span class="n">grp</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_twosamples</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                  <span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="n">n_informative</span><span class="p">,</span>
                         <span class="n">group_scale</span><span class="o">=</span><span class="mf">.5</span><span class="p">,</span> <span class="n">noise_scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">shared_scale</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                         <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="c1">#import matplotlib.pyplot as plt</span>
<span class="n">tvals</span><span class="p">,</span> <span class="n">pvals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_features</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">):</span>
    <span class="n">tvals</span><span class="p">[</span><span class="n">j</span><span class="p">],</span> <span class="n">pvals</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">stats</span><span class="o">.</span><span class="n">ttest_ind</span><span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="n">grp</span><span class="o">==</span><span class="mi">0</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">Y</span><span class="p">[</span><span class="n">grp</span><span class="o">==</span><span class="mi">1</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span>
                                         <span class="n">equal_var</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span><span class="c1">#, sharex=&#39;col&#39;)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">tvals</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;t-value&quot;</span><span class="p">)</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">pvals</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;p-value=0.05&quot;</span><span class="p">)</span>
<span class="c1">#axis[1].axhline(y=0.05, label=&quot;toto&quot;, color=&#39;red&#39;)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;p-value&quot;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">axis</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">([</span><span class="n">pvals</span><span class="p">[</span><span class="n">n_informative</span><span class="p">:],</span> <span class="n">pvals</span><span class="p">[:</span><span class="n">n_informative</span><span class="p">]],</span>
    <span class="n">stacked</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Negatives&quot;</span><span class="p">,</span> <span class="s2">&quot;Positives&quot;</span><span class="p">])</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;p-value histogram&quot;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;density&quot;</span><span class="p">)</span>
<span class="n">axis</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
<img alt="../_images/stat_univ_125_0.png" src="../_images/stat_univ_125_0.png" />
<p>Note that under the null hypothesis the distribution of the <em>p</em>-values
is uniform.</p>
<p>Statistical measures:</p>
<ul class="simple">
<li><p><strong>True Positive (TP)</strong> equivalent to a hit. The test correctly
concludes the presence of an effect.</p></li>
<li><p>True Negative (TN). The test correctly concludes the absence of an
effect.</p></li>
<li><p><strong>False Positive (FP)</strong> equivalent to a false alarm, <strong>Type I error</strong>.
The test improperly concludes the presence of an effect. Thresholding
at <span class="math notranslate nohighlight">\(p\text{-value} &lt; 0.05\)</span> leads to 47 FP.</p></li>
<li><p>False Negative (FN) equivalent to a miss, Type II error. The test
improperly concludes the absence of an effect.</p></li>
</ul>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">n_info</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">-</span> <span class="n">n_info</span>  <span class="c1"># Positives, Negatives</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals</span><span class="p">[:</span><span class="n">n_info</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># True Positives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals</span><span class="p">[</span><span class="n">n_info</span><span class="p">:</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># False Positives</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No correction, FP: </span><span class="si">%i</span><span class="s2"> (expected: </span><span class="si">%.2f</span><span class="s2">), TP: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">FP</span><span class="p">,</span> <span class="n">N</span> <span class="o">*</span> <span class="mf">0.05</span><span class="p">,</span> <span class="n">TP</span><span class="p">))</span>
</pre></div>
</div>
<section id="bonferroni-correction-for-multiple-comparisons">
<h3>Bonferroni Correction for Multiple Comparisons<a class="headerlink" href="#bonferroni-correction-for-multiple-comparisons" title="Link to this heading">¶</a></h3>
<p>The Bonferroni correction is based on the idea that if an experimenter
is testing <span class="math notranslate nohighlight">\(P\)</span> hypotheses, then one way of maintaining the
<strong>Family-wise error rate</strong>
<a class="reference external" href="https://en.wikipedia.org/wiki/Family-wise_error_rate">FWER</a> is to
test each individual hypothesis at a statistical significance level of
<span class="math notranslate nohighlight">\(1/P\)</span> times the desired maximum overall level.</p>
<p>So, if the desired significance level for the whole family of tests is
<span class="math notranslate nohighlight">\(\alpha\)</span> (usually 0.05), then the Bonferroni correction would test
each individual hypothesis at a significance level of <span class="math notranslate nohighlight">\(\alpha/P\)</span>.
For example, if a trial is testing <span class="math notranslate nohighlight">\(P = 8\)</span> hypotheses with a
desired <span class="math notranslate nohighlight">\(\alpha = 0.05\)</span>, then the Bonferroni correction would test
each individual hypothesis at <span class="math notranslate nohighlight">\(\alpha = 0.05/8 = 0.00625\)</span>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">statsmodels.sandbox.stats.multicomp</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">multicomp</span>

<span class="n">_</span><span class="p">,</span> <span class="n">pvals_fwer</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span>  <span class="o">=</span> <span class="n">multicomp</span><span class="o">.</span><span class="n">multipletests</span><span class="p">(</span><span class="n">pvals</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                               <span class="n">method</span><span class="o">=</span><span class="s1">&#39;bonferroni&#39;</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals_fwer</span><span class="p">[:</span><span class="n">n_info</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># True Positives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals_fwer</span><span class="p">[</span><span class="n">n_info</span><span class="p">:</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># False Positives</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FWER correction, FP: </span><span class="si">%i</span><span class="s2">, TP: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">FP</span><span class="p">,</span> <span class="n">TP</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="the-false-discovery-rate-fdr-correction-for-multiple-comparisons">
<h3>The False Discovery Rate (FDR) Correction for Multiple Comparisons<a class="headerlink" href="#the-false-discovery-rate-fdr-correction-for-multiple-comparisons" title="Link to this heading">¶</a></h3>
<p>FDR-controlling procedures are designed to control the expected
proportion of rejected null hypotheses that were incorrect rejections
(“false discoveries”). FDR-controlling procedures provide less stringent
control of Type I errors compared to the familywise error rate (FWER)
controlling procedures (such as the Bonferroni correction), which
control the probability of at least one Type I error. Thus,
FDR-controlling procedures have greater power, at the cost of increased
rates of Type I errors.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">pvals_fdr</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span>  <span class="o">=</span> <span class="n">multicomp</span><span class="o">.</span><span class="n">multipletests</span><span class="p">(</span><span class="n">pvals</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
                                               <span class="n">method</span><span class="o">=</span><span class="s1">&#39;fdr_bh&#39;</span><span class="p">)</span>
<span class="n">TP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals_fdr</span><span class="p">[:</span><span class="n">n_info</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># True Positives</span>
<span class="n">FP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pvals_fdr</span><span class="p">[</span><span class="n">n_info</span><span class="p">:</span> <span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.05</span><span class="p">)</span>  <span class="c1"># False Positives</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FDR correction, FP: </span><span class="si">%i</span><span class="s2">, TP: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">FP</span><span class="p">,</span> <span class="n">TP</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="../index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Univariate Statistics</a><ul>
<li><a class="reference internal" href="#libraries">Libraries</a></li>
<li><a class="reference internal" href="#descriptive-statistics">Descriptive Statistics</a><ul>
<li><a class="reference internal" href="#mean">Mean</a></li>
<li><a class="reference internal" href="#variance">Variance</a></li>
<li><a class="reference internal" href="#standard-deviation">Standard deviation</a></li>
<li><a class="reference internal" href="#covariance">Covariance</a></li>
<li><a class="reference internal" href="#correlation">Correlation</a></li>
<li><a class="reference internal" href="#standard-error-se">Standard Error (SE)</a></li>
<li><a class="reference internal" href="#descriptive-statistics-with-numpy">Descriptive statistics with Numpy</a></li>
<li><a class="reference internal" href="#descriptives-statistics-on-iris-dataset">Descriptives Statistics on Iris Dataset</a></li>
</ul>
</li>
<li><a class="reference internal" href="#probability-distributions">Probability Distributions</a><ul>
<li><a class="reference internal" href="#histogram-as-probability-density-function-estimator">Histogram as probability density function estimator</a></li>
<li><a class="reference internal" href="#kernel-density-estimation-kde">Kernel Density Estimation (KDE)</a></li>
<li><a class="reference internal" href="#normal-distribution">Normal distribution</a></li>
<li><a class="reference internal" href="#the-chi-square-distribution">The Chi-Square Distribution</a></li>
<li><a class="reference internal" href="#the-fishers-f-distribution">The Fisher’s F-Distribution</a></li>
<li><a class="reference internal" href="#the-students-t-distribution">The Student’s <span class="math notranslate nohighlight">\(t\)</span>-Distribution</a></li>
</ul>
</li>
<li><a class="reference internal" href="#central-limit-theorem-clt">Central Limit Theorem (CLT)</a><ul>
<li><a class="reference internal" href="#distribution-of-the-sum-of-samples">Distribution of the Sum of Samples</a></li>
<li><a class="reference internal" href="#the-distribution-of-the-sample-mean">The Distribution of the Sample Mean</a></li>
<li><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#statistical-inference-and-decision-making-using-hypothesis-testing">Statistical inference and Decision Making using Hypothesis Testing</a><ul>
<li><a class="reference internal" href="#typology-of-tests">Typology of tests</a></li>
<li><a class="reference internal" href="#general-testing-procedure">General Testing Procedure</a><ul>
<li><a class="reference internal" href="#model-the-data-for-parametric-tests">1. <strong>Model the data</strong> (for parametric tests).</a></li>
<li><a class="reference internal" href="#calculate-a-decision-statistic-for-all-tests">2. Calculate a <strong>decision statistic</strong> (for all tests)</a></li>
<li><a class="reference internal" href="#inference">3. Inference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#categorical-variable-the-binomial-test">Categorical variable: the Binomial Test</a></li>
<li><a class="reference internal" href="#quantitative-variable-one-sample-t-test">Quantitative variable: One Sample T-test</a></li>
</ul>
</li>
<li><a class="reference internal" href="#statistical-tests-of-pairwise-associations">Statistical Tests of Pairwise Associations</a><ul>
<li><a class="reference internal" href="#pearson-correlation-test-association-between-two-quantitative-variables">Pearson Correlation: Test Association Between Two Quantitative Variables</a></li>
<li><a class="reference internal" href="#two-sample-student-t-test-compare-two-means">Two sample (Student) T-test: Compare Two Means</a><ul>
<li><a class="reference internal" href="#equal-or-unequal-sample-sizes-unequal-variances-welchs-t-test">Equal or unequal sample sizes, unequal variances (Welch’s <span class="math notranslate nohighlight">\(t\)</span>-test)</a></li>
<li><a class="reference internal" href="#equal-or-unequal-sample-sizes-equal-variances">Equal or unequal sample sizes, equal variances</a></li>
<li><a class="reference internal" href="#equal-sample-sizes-equal-variances">Equal sample sizes, equal variances</a></li>
<li><a class="reference internal" href="#example">Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#anova-f-test-quantitative-as-a-function-of-categorical-factor-with-three-levels-or-more">ANOVA F-test: Quantitative as a function of Categorical Factor with Three Levels or More</a><ul>
<li><a class="reference internal" href="#example-with-the-iris-dataset">Example with the Iris Dataset:</a></li>
</ul>
</li>
<li><a class="reference internal" href="#chi-square-chi-2-categorical-v-s-categorical-factors">Chi-square, <span class="math notranslate nohighlight">\(\chi^2\)</span>: Categorical v.s. Categorical Factors</a><ul>
<li><a class="reference internal" href="#id1">Example</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-parametric-tests-of-pairwise-associations">Non-parametric Tests of Pairwise Associations</a><ul>
<li><a class="reference internal" href="#spearman-rank-order-correlation-quantitative-vs-quantitative">Spearman Rank-Order Correlation (Quantitative vs Quantitative)</a></li>
<li><a class="reference internal" href="#wilcoxon-signed-rank-rest-quantitative-vs-cte">Wilcoxon Signed-Rank Rest (Quantitative vs Cte)</a></li>
<li><a class="reference internal" href="#mannwhitney-u-test-quantitative-vs-categorical-factor-with-two-levels">Mann–Whitney <span class="math notranslate nohighlight">\(U\)</span> test (Quantitative vs Categorical Factor with Two Levels)</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#linear-model">Linear Model</a><ul>
<li><a class="reference internal" href="#assumptions">Assumptions</a></li>
<li><a class="reference internal" href="#simple-regression-test-association-between-two-quantitative-variables">Simple Regression: Test Association Between Two Quantitative Variables</a></li>
<li><a class="reference internal" href="#multiple-regression">Multiple Regression</a></li>
<li><a class="reference internal" href="#linear-model-with-statsmodels">Linear Model with Statsmodels</a><ul>
<li><a class="reference internal" href="#multiple-regression-using-numpy-array">Multiple Regression Using Numpy Array</a></li>
<li><a class="reference internal" href="#multiple-regression-pandas-using-formulae-smf">Multiple Regression Pandas using formulae (<code class="docutils literal notranslate"><span class="pre">smf</span></code>)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multiple-regression-mixing-covariates-and-factors-ancova">Multiple Regression Mixing Covariates and Factors (ANCOVA)</a><ul>
<li><a class="reference internal" href="#one-way-an-c-ova">One-way AN(C)OVA</a></li>
<li><a class="reference internal" href="#two-way-an-c-ova">Two-way AN(C)OVA</a></li>
<li><a class="reference internal" href="#comparing-two-nested-models">Comparing Two Nested Models</a></li>
<li><a class="reference internal" href="#factor-coding">Factor Coding</a></li>
<li><a class="reference internal" href="#contrasts-and-post-hoc-tests">Contrasts and Post-hoc Tests</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#multiple-comparisons">Multiple Comparisons</a><ul>
<li><a class="reference internal" href="#bonferroni-correction-for-multiple-comparisons">Bonferroni Correction for Multiple Comparisons</a></li>
<li><a class="reference internal" href="#the-false-discovery-rate-fdr-correction-for-multiple-comparisons">The False Discovery Rate (FDR) Correction for Multiple Comparisons</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/statistics/stat_univ.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2020, Edouard Duchesnay, NeuroSpin CEA Université Paris-Saclay, France.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.2.3</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
      |
      <a href="../_sources/statistics/stat_univ.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>